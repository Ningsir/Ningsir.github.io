<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="华中科技大学17级本科生">
  <meta name="author" content="XIN">
  <meta name="keywords" content="">
  <title>softmax回归实现手写数字识别 - XIN&#39;S BLOG</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->
<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">

<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>XIN'S BLOG</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-07-02 20:34">
      2020年7月2日 晚上
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.3k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      32
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>如下图所示，构建了一个3层的神经网络（不包括输入层），第一个隐藏层包括128个神经元，第二个隐藏层包括64个神经元，输出层包括10个神经元。隐藏层中每个神经元进行两项运算：先进行线性运算，然后使用<code>tanh</code>激励函数；输出层也是先进行线性运算，但激励函数使用的是<code>softmax</code>。</p>
<p><img src="http://image.ningxin.site/神经网络模型图.png" srcset="/img/loading.gif" alt="网络结构图" style="zoom: 67%;"></p>
<h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><p>使用MNIST数据集，都是<code>28 x 28</code>大小的图片，一共有60000个训练样本和10000个测试样本。</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> struct

<span class="hljs-comment"># 训练集文件</span>
train_images_idx3_ubyte_file = <span class="hljs-string">'data/MNIST/raw/train-images-idx3-ubyte'</span>
<span class="hljs-comment"># 训练集标签文件</span>
train_labels_idx1_ubyte_file = <span class="hljs-string">'data/MNIST/raw/train-labels-idx1-ubyte'</span>
<span class="hljs-comment"># 测试集文件</span>
test_images_idx3_ubyte_file = <span class="hljs-string">'data/MNIST/raw/t10k-images-idx3-ubyte'</span>
<span class="hljs-comment"># 测试集标签文件</span>
test_labels_idx1_ubyte_file = <span class="hljs-string">'data/MNIST/raw/t10k-labels-idx1-ubyte'</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decode_idx3_ubyte</span><span class="hljs-params">(idx3_ubyte_file)</span>:</span>
    <span class="hljs-string">"""
    解析idx3文件的通用函数
    :param idx3_ubyte_file: idx3文件路径
    :return: 数据集
    """</span>
    <span class="hljs-comment"># 读取二进制数据</span>
    bin_data = open(idx3_ubyte_file, <span class="hljs-string">'rb'</span>).read()

    <span class="hljs-comment"># 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽</span>
    offset = <span class="hljs-number">0</span>
    fmt_header = <span class="hljs-string">'&gt;iiii'</span>  <span class="hljs-comment"># 因为数据结构中前4行的数据类型都是32位整型，所以采用i格式，但我们需要读取前4行数据，所以需要4个i。我们后面会看到标签集中，只使用2个ii。</span>
    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)
    <span class="hljs-comment"># print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))</span>
    <span class="hljs-comment"># 解析数据集</span>
    image_size = num_rows * num_cols
    offset += struct.calcsize(fmt_header)  <span class="hljs-comment"># 获得数据在缓存中的指针位置，从前面介绍的数据结构可以看出，读取了前4行之后，指针位置（即偏移位置offset）指向0016。</span>
    print(offset)
    fmt_image = <span class="hljs-string">'&gt;'</span> + str(
        image_size) + <span class="hljs-string">'B'</span>  <span class="hljs-comment"># 图像数据像素值的类型为unsigned char型，对应的format格式为B。这里还有加上图像大小784，是为了读取784个B格式数据，如果没有则只会读取一个值（即一副图像中的一个像素值）</span>
    print(fmt_image, offset, struct.calcsize(fmt_image))
    images = np.empty((num_images, num_rows, num_cols))
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_images):
        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))
        offset += struct.calcsize(fmt_image)
    <span class="hljs-keyword">return</span> images


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decode_idx1_ubyte</span><span class="hljs-params">(idx1_ubyte_file)</span>:</span>
    <span class="hljs-string">"""
    解析idx1文件的通用函数
    :param idx1_ubyte_file: idx1文件路径
    :return: 数据集
    """</span>
    <span class="hljs-comment"># 读取二进制数据</span>
    bin_data = open(idx1_ubyte_file, <span class="hljs-string">'rb'</span>).read()
    <span class="hljs-comment"># 解析文件头信息，依次为魔数和标签数</span>
    offset = <span class="hljs-number">0</span>
    fmt_header = <span class="hljs-string">'&gt;ii'</span>
    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)
    <span class="hljs-comment"># print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))</span>
    <span class="hljs-comment"># 解析数据集</span>
    offset += struct.calcsize(fmt_header)
    fmt_image = <span class="hljs-string">'&gt;B'</span>
    labels = np.empty(num_images, dtype=np.int64)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_images):
        <span class="hljs-comment"># if (i + 1) % 10000 == 0:</span>
        <span class="hljs-comment">#     print('已解析 %d' % (i + 1) + '张')</span>
        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[<span class="hljs-number">0</span>]
        offset += struct.calcsize(fmt_image)
    <span class="hljs-keyword">return</span> labels


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_train_images</span><span class="hljs-params">(idx_ubyte_file=train_images_idx3_ubyte_file)</span>:</span>
    <span class="hljs-keyword">return</span> decode_idx3_ubyte(idx_ubyte_file)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_train_labels</span><span class="hljs-params">(idx_ubyte_file=train_labels_idx1_ubyte_file)</span>:</span>
    <span class="hljs-keyword">return</span> decode_idx1_ubyte(idx_ubyte_file)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_test_images</span><span class="hljs-params">(idx_ubyte_file=test_images_idx3_ubyte_file)</span>:</span>
    <span class="hljs-keyword">return</span> decode_idx3_ubyte(idx_ubyte_file)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_test_labels</span><span class="hljs-params">(idx_ubyte_file=test_labels_idx1_ubyte_file)</span>:</span>
    <span class="hljs-keyword">return</span> decode_idx1_ubyte(idx_ubyte_file)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_data</span><span class="hljs-params">()</span>:</span>
    train_img = load_train_images()
    train_img = train_img.reshape(train_img.shape[<span class="hljs-number">0</span>], train_img.shape[<span class="hljs-number">1</span>] * train_img.shape[<span class="hljs-number">2</span>]).T / <span class="hljs-number">255</span>
    test_img = load_test_images()
    test_img = test_img.reshape(test_img.shape[<span class="hljs-number">0</span>], test_img.shape[<span class="hljs-number">1</span>] * test_img.shape[<span class="hljs-number">2</span>]).T / <span class="hljs-number">255</span>
    train_label = load_train_labels()
    test_label = load_test_labels()
    <span class="hljs-keyword">return</span> train_img, train_label, test_img, test_label</code></pre>
<p>数据处理后训练样本和测试样本的维度：<br><pre><code class="hljs undefined"><span class="hljs-attribute">train_img</span>: (784, 60000)
<span class="hljs-attribute">train_label</span>: (60000, )

<span class="avrasm"><span class="hljs-symbol">test_img:</span> (<span class="hljs-number">784</span>, <span class="hljs-number">10000</span>)
<span class="hljs-symbol">test_label:</span> (<span class="hljs-number">10000</span>, )</span></code></pre></p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>在读取数据之后，为了程序能够正常运行，需要对数据进行预处理。</p>
<ul>
<li>对图像数据进行归一化操作，因为每个像素点的值是在0-255范围内，进行归一化可以减少运算量，同时避免运算结果溢出；</li>
<li>对labels进行one-hot编码，这一步骤主要是为了计算交叉熵损失函数时能够正常运行。one-hot编码指的是正确解的标签为1，其余为0，比如3表示为”0010000000“。</li>
</ul>
<p>one-hot编码的python实现如下：</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dense_to_one_hot</span><span class="hljs-params">(labels_dense, num_classes)</span>:</span>
    <span class="hljs-string">"""
    Convert class labels from scalars to one-hot vectors.
    num_classes: 总共的类别数
    """</span>
    num_labels = labels_dense.shape[<span class="hljs-number">0</span>]
    <span class="hljs-comment"># 偏移量，arange函数产生0，1，num_labels-1之间的数</span>
    index_offset = np.arange(num_labels) * num_classes
    labels_one_hot = np.zeros((num_labels, num_classes))
    <span class="hljs-comment"># flat返回一个一维迭代器，ravel()函数将多维数组转化为一维数组</span>
    labels_one_hot.flat[index_offset + labels_dense.ravel()] = <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> labels_one_hot</code></pre>
<h1 id="初始化参数"><a href="#初始化参数" class="headerlink" title="初始化参数"></a>初始化参数</h1><p>首先需要初始化参数，b直接全部初始化为0，W使用<code>randn</code>生成随机数，注意b和W不能全部都一样，否则任意一层中的每个神经元输出都一样，最后反向传播也一样，就没有任何意义了。</p>
<pre><code class="hljs python"><span class="hljs-comment"># x: 784*60000, 784*1000</span>
<span class="hljs-comment"># # y: 10*60000, 10*1000</span>
<span class="hljs-comment"># # W1: 128*784</span>
<span class="hljs-comment"># # b1: 128*1</span>
<span class="hljs-comment"># # W2: 64*128</span>
<span class="hljs-comment"># # b2: 64*1</span>
<span class="hljs-comment"># # W3: 10*64</span>
<span class="hljs-comment"># # b3: 10*1</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_parameters</span><span class="hljs-params">(layers_dim=<span class="hljs-params">(<span class="hljs-number">784</span>, <span class="hljs-number">25</span>, <span class="hljs-number">12</span>, <span class="hljs-number">10</span>)</span>)</span>:</span>
    <span class="hljs-string">"""
    初始化参数
    :return:
    """</span>
    m = len(layers_dim)
    parameters = &#123;&#125;
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m - <span class="hljs-number">1</span>):
        <span class="hljs-comment"># randn生成的随机数符合标准高斯分布，期望为0，方差为1</span>
        parameters[<span class="hljs-string">'W'</span> + str(i + <span class="hljs-number">1</span>)] = np.random.randn(layers_dim[i + <span class="hljs-number">1</span>], layers_dim[i]) * <span class="hljs-number">0.001</span>
        parameters[<span class="hljs-string">'b'</span> + str(i + <span class="hljs-number">1</span>)] = np.zeros((layers_dim[i + <span class="hljs-number">1</span>], <span class="hljs-number">1</span>))

    <span class="hljs-keyword">return</span> parameters</code></pre>
<h1 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h1><p>前向传播的基本步骤是先使用一个线性函数，然后使用激励函数将结果非线性化。可以如下表示：</p>
<pre><code class="hljs python">y = Wx + b
a = activation(y) <span class="hljs-comment"># 使用时用具体的激励函数替换</span></code></pre>
<p>实验中主要使用了<code>tanh</code>和<code>softmax</code>这两个激励函数。<code>tanh</code>函数公式及python实现如下：</p>
<script type="math/tex; mode=display">
y = \frac{e^x - e^{-x}}{e^x + e^{-x}} \tag{1}</script><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tanh</span><span class="hljs-params">(x)</span>:</span>
    <span class="hljs-keyword">return</span> (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))</code></pre>
<p><code>softmax</code>函数公式及python实现如下, </p>
<script type="math/tex; mode=display">
\operatorname{Softmax}\left(x_{i}\right)=\frac{e^{x_i}}{\sum_{j} e^{x_{j}}} \tag{2}</script><p>需要注意的是，在python实现<code>softmax</code>时，为了避免计算溢出，可以减去一个最大值之后，再进行指数运算。</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax</span><span class="hljs-params">(z)</span>:</span>
    <span class="hljs-comment"># 实现softmax分类器输出转化</span>
    c = np.max(z)
    z_exp = np.exp(z - c) <span class="hljs-comment"># 避免指数运算产生溢出</span>
    z_sum_column = z_exp.sum(axis=<span class="hljs-number">0</span>).T
    <span class="hljs-keyword">return</span> z_exp / z_sum_column</code></pre>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p>反向传播过程主要根据链式规则求解各个参数的关于损失函数的梯度，以便对参数进行优化，从而使损失值减小。实验中损失函数使用的是交叉熵损失函数，可以表示为：</p>
<script type="math/tex; mode=display">
L = -{\sum_{i} {y_i \log{a_i}}} \tag{3}</script><p>其中 $y_i$ 表示实际值，$a_i$ 表示预测值, 而 $a_i$ 是经过softmax函数得到的结果，即 $a_i$ 可以表示为：</p>
<script type="math/tex; mode=display">
a_i = \frac{e^{z_i}}{\sum_{j} e^{z_{j}}} \tag{4}</script><p>则 $a_j$ 对 $z_i$ 求偏导数，可得：</p>
<script type="math/tex; mode=display">
\frac{\partial a_{j}}{\partial z_{i}}=\left\{\begin{array}{ll}
a_{i}\left(1-a_{i}\right), & i=j \\
-a_{i} a_{j} & i \neq j
\end{array}\right. \tag{5}</script><p>使用上式，L 对 $z_i$ 求偏导数得： </p>
<script type="math/tex; mode=display">
\begin{array}{l}
\quad \frac{\partial L}{\partial z_{i}}
=\frac{\partial L}{\partial a_j} \frac{\partial a_j}{\partial z_i}
=\sum_{j}-\frac{y i}{a_{j}} \frac{\partial a_{j}}{\partial z_{i}} \\
=\frac{-y_{i}}{a_{i}} a_{i}\left(1-a_{i}\right)+\sum_{j}^{j \neq i}-\frac{y_{i}}{a_{j}}\left(-a_{i} a_{j}\right) \\
=-y_{i}\left(1 - a_{i}\right)+\sum_{j=1}^{j \neq i} a_{i} y_{j} \\
=a_{i} y_{i}-y_{i}+a_{i} \sum_{i \neq j} y_{j} \\
=a_{i} \sum_{j} y_{j}-y_{i}=a_{i}-y_{i}
\end{array}</script><p>记上式为$dZ$ , 然后计算 $\frac{\partial L}{\partial W}$，其中X为上一层传进来的数据。:</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial W} = \frac{\partial L}{\partial Z} \frac{\partial Z}{\partial W} \\
= dZX</script><p>实验中还是用了<code>tanh</code>函数，其导数为：</p>
<script type="math/tex; mode=display">
f(x)^{\prime}=1-(\tanh (x))^{2} \tag{6}</script><p>反向传播各个过程的偏导数都求出来之后，就可以编码实现了，具体代码如下：</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward_propagation</span><span class="hljs-params">(x, y, cache, parameters)</span>:</span>
    <span class="hljs-string">"""
    x: 网络中的输入数据
    y: 网络的输出数据
    cache：缓存各阶段计算的结果
    """</span>
    W2 = parameters[<span class="hljs-string">'W2'</span>]
    W3 = parameters[<span class="hljs-string">'W3'</span>]

    m = y.shape[<span class="hljs-number">0</span>]

    (Z1, A1, Z2, A2, Z3, A3) = cache

    dz3 = A3 - y
    dW3 = np.dot(dz3, A2.T) / m
    db3 = np.mean(dz3, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)

    da2 = np.dot(W3.T, dz3)
    dz2 = np.multiply(da2, <span class="hljs-number">1</span> - np.multiply(A2, A2))
    dW2 = np.dot(dz2, A1.T) / m
    db2 = np.mean(dz2, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)

    da1 = np.dot(W2.T, dz2)
    dz1 = np.multiply(da1, <span class="hljs-number">1</span> - np.multiply(A1, A1))
    dW1 = np.dot(dz1, x.T) / m
    db1 = np.mean(dz1, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)

    gradients = &#123;<span class="hljs-string">"dz3"</span>: dz3, <span class="hljs-string">"dW3"</span>: dW3, <span class="hljs-string">"db3"</span>: db3,
                 <span class="hljs-string">"da2"</span>: da2, <span class="hljs-string">"dz2"</span>: dz2, <span class="hljs-string">"dW2"</span>: dW2, <span class="hljs-string">"db2"</span>: db2,
                 <span class="hljs-string">"da1"</span>: da1, <span class="hljs-string">"dz1"</span>: dz1, <span class="hljs-string">"dW1"</span>: dW1, <span class="hljs-string">"db1"</span>: db1&#125;

    <span class="hljs-keyword">return</span> gradients</code></pre>
<h1 id="损失函数和优化器"><a href="#损失函数和优化器" class="headerlink" title="损失函数和优化器"></a>损失函数和优化器</h1><p>损失函数使用的是交叉熵损失函数，交叉熵函数的公式见公式(3), 具体实现如下：</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cross_entropy_loss</span><span class="hljs-params">(a, y)</span>:</span>
    <span class="hljs-string">"""
    交叉熵损失函数
    :param a: 预测值
    :param y: 实际值
    :return:
    """</span>
    m = a.shape[<span class="hljs-number">1</span>]
    <span class="hljs-comment"># 对数操作加1e-7防止出现0</span>
    loss = -np.multiply(np.log(a + <span class="hljs-number">1e-7</span>), y).sum(axis=<span class="hljs-number">0</span>)
    cost = loss.sum() / m
    <span class="hljs-keyword">return</span> cost</code></pre>
<p>使用上述的实现需要注意两点：对实际的label值需要使用<code>one-hot</code>编码；实现中使用了对数运算，为了防止出现0，需要加上一个偏置值。</p>
<p>梯度下降法根据计算得到的梯度更新参数，从而达到减小损失值的效果，可以表示成如下形式为：</p>
<script type="math/tex; mode=display">
x_{n}^{(i+1)}=x_{n}^{(i)}-\eta \cdot \frac{\partial f}{\partial x_{n}}\left(\mathbf{x}^{(i)}\right)</script><p>其中$\eta$ 指的就是学习率，python实现如下：</p>
<pre><code class="hljs python">ef gradient_descent(parameters, grads, learning_rate):
    <span class="hljs-string">"""
    使用梯度下降法更新参数
    :param parameters:
    :param grads:
    :param learning_rate:
    :return:
    """</span>
    length = len(parameters) // <span class="hljs-number">2</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(length):
        parameters[<span class="hljs-string">"W"</span> + str(i + <span class="hljs-number">1</span>)] = parameters[<span class="hljs-string">"W"</span> + str(i + <span class="hljs-number">1</span>)] - learning_rate * grads[<span class="hljs-string">"dW"</span> + str(i + <span class="hljs-number">1</span>)]
        parameters[<span class="hljs-string">"b"</span> + str(i + <span class="hljs-number">1</span>)] = parameters[<span class="hljs-string">"b"</span> + str(i + <span class="hljs-number">1</span>)] - learning_rate * grads[<span class="hljs-string">"db"</span> + str(i + <span class="hljs-number">1</span>)]
    <span class="hljs-keyword">return</span> parameters</code></pre>
<h1 id="训练及预测"><a href="#训练及预测" class="headerlink" title="训练及预测"></a>训练及预测</h1><p>训练过程：初始化参数—&gt;前向传播—&gt;反向传播—&gt;参数优化。</p>
<p>训练过程的参数设置如下：</p>
<pre><code class="hljs undefined"><span class="hljs-attr">epochs</span> = <span class="hljs-number">100</span>
<span class="hljs-attr">BATCH_SIZE</span> = <span class="hljs-number">100</span>
<span class="hljs-attr">learning_rate</span> = <span class="hljs-number">0.005</span></code></pre>
<p>实验时，把训练和预测两部分放到了一起运行，执行过程如下，其中正确率达到了97.83%</p>
<p><img src="http://image.ningxin.site/20200615153942.png" srcset="/img/loading.gif" alt=""></p>
<p>loss值下降过程如下： </p>
<p><img src="http://image.ningxin.site/20200615161053.png" srcset="/img/loading.gif" alt=""></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/机器学习/">机器学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/机器学习/">机器学习</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/07/03/LaTeX数学公式/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">LaTeX数学公式</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/07/01/机器学习基础/">
                        <span class="hidden-mobile">机器学习基础</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "RIPrHIBMNeTH5hqWK3v3S3tY-gzGzoHsz",
          app_key: "v3JUvWKIM4IppVhBGgMhs66O",
          placeholder: "说点什么",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "https://riprhibm.lc-cn-n1-shared.com",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" rel="nofollow noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    
  <!-- 备案信息 -->
  <div class="beian">
    <a href="http://beian.miit.gov.cn/" target="_blank"
       rel="nofollow noopener">湘ICP证20011128号</a>
    
      <a
        href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=20011128"
        rel="nofollow noopener"
        class="beian-police"
        target="_blank"
      >
        <span class="beian-police-sep">&nbsp;|&nbsp;</span>
        
          <img src="/img/police_beian.png" srcset="/img/loading.gif" alt="police-icon" />
        
        <span>湘ICP备20011128号</span>
      </a>
     
  </div>


    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "softmax回归实现手写数字识别&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
