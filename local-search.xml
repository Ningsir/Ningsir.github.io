<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>心弦</title>
    <link href="/2020/08/27/%E5%BF%83%E5%BC%A6/"/>
    <url>/2020/08/27/%E5%BF%83%E5%BC%A6/</url>
    
    <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容."><div class="hbe-input-container"><input type="password" id="hbePass" placeholder="您好, 这里需要密码." /><label>您好, 这里需要密码.</label><div class="bottom-line"></div></div><script id="hbeData" type="hbeData" data-hmacdigest="abe5c07e9556fc3f8ad8d79c8c7037fcd0efc61488d80a6b904ca2ddec2fec0e">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</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    
    
    <tags>
      
      <tag>悄悄话</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mask R-CNN论文笔记</title>
    <link href="/2020/08/26/Mask-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/08/26/Mask-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>未完。。。。。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>Mask R-CNN是一个实例分割模型，实例分割不仅要实现目标检测，还需要对目标进行精确的分割，即实例分割可以看成目标检测和语义分割的结合。</p><p>Mask R-CNN是Faster R-CNN的扩展，在Faster R-CNN的基础上添加一个用于预测<code>object mask</code>的并行分支，该分支是一个小型的FCN。</p><p>Mask R-CNN引入了RoIAlign用来替换RoIPool层，因为RoIPool不是按照像素一一对齐的，使用RoIAlign后mask的精度从10%提高到50%。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200826170930.png" srcset="/img/loading.gif" alt=""></p><h1 id="2-Mask-R-CNN"><a href="#2-Mask-R-CNN" class="headerlink" title="2. Mask R-CNN"></a>2. Mask R-CNN</h1><p>Mask R-CNN采样了 two-stage 过程，第一步是一个 RPN，第二步预测 bounding box 的类别和 box offset，同时对每个 RoI 输出一个<code>binary mask</code>。</p><h2 id="2-1-RoIAlign"><a href="#2-1-RoIAlign" class="headerlink" title="2.1 RoIAlign"></a>2.1 RoIAlign</h2><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200826175336.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLO V1,V2,V3</title>
    <link href="/2020/08/22/YOLO-V1-V2-V3/"/>
    <url>/2020/08/22/YOLO-V1-V2-V3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-YOLO-V1"><a href="#1-YOLO-V1" class="headerlink" title="1. YOLO V1"></a>1. YOLO V1</h1><h2 id="1-1-Introduction"><a href="#1-1-Introduction" class="headerlink" title="1.1 Introduction"></a>1.1 Introduction</h2><p>传统的目标检测模型，一般分为两个部分，即先进行区域提取，然后进行目标分类，但YOLO模型是一步到位，即同时产生多个bounding boxes和每个box的类别概率。YOLO有如下优点：</p><ul><li>YOLO非常快；</li><li>YOLO对图像整体进行分析；</li></ul><p>YOLO缺点：</p><ul><li>YOLO在准确度上落后当前目标检测系统；</li><li>容易产生定位错误；</li><li>网络中使用了全连接层，输入数据大小固定；</li><li>对小物体的检测效果不好。</li></ul><h2 id="1-2-Unified-Detection"><a href="#1-2-Unified-Detection" class="headerlink" title="1.2 Unified Detection"></a>1.2 Unified Detection</h2><p>YOLO将目标检测的各个部分整合成一个单一的神经网络。</p><p>YOLO将一幅图分成<code>S x S</code>个网格（也就是经过一系列卷积层之后feature map 的大小为<code>S x S</code>），如果某个object的中心落在这个网格中，则这个网格就负责预测这个object。<br>每个网格预测B个bounding boxes 和 confidence scores，<code>confidence</code>可以表示为：</p><script type="math/tex; mode=display">Pr(Object)*IOU_{pred}^{truth}</script><p>如果网格中不存在目标，则 confidence 为0。每个bounding box包含5个预测：x, y, w, h, confidence，其中<code>(x, y)</code>表示b<strong>相当于网格单元格边界的偏移</strong>，<code>(w, h)</code>是相对于整幅图像的宽度和高度。<br>每个网格还要预测C个条件类别概率（<strong>不管bounding boxes有多少个</strong>），其实C就是需要检测的类别数量，条件类别概率可以表示为$Pr(Class_i | Object)$。<br>最后输出的预测值可以编码成<code>S x S x (5B + C)</code>大小的tensor。YOLO运用在 PASCAL VOC数据集上时，参数设置如下, 即输出为<code>7 x 7 x 30</code>的tensor：</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attr">S</span> = <span class="hljs-number">7</span><span class="hljs-attr">B</span> = <span class="hljs-number">2</span><span class="hljs-attr">C</span> = <span class="hljs-number">20</span></code></pre></div><p>下图为YOLO模型结构图。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200823203247.png" srcset="/img/loading.gif" alt=""></p><h3 id="1-2-1-Network-Design"><a href="#1-2-1-Network-Design" class="headerlink" title="1.2.1 Network Design"></a>1.2.1 Network Design</h3><p>网络使用24个卷积层，然后连接2个全连接层。具体网络结构如下：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200823224222.png" srcset="/img/loading.gif" alt=""></p><h3 id="1-2-2-Training"><a href="#1-2-2-Training" class="headerlink" title="1.2.2 Training"></a>1.2.2 Training</h3><p><code>(x, y, w, h)</code>都被归一化到0-1，激活函数使用leaky ReLU：</p><script type="math/tex; mode=display">f(x) = \left\{\begin{array}{1}x, if\ x > 0 \\0.1x,otherwise\end{array}\right.</script><p>损失函数如下：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200824170239.png" srcset="/img/loading.gif" alt=""></p><p>为了避免过拟合，使用了dropout 和数据增广。在第一个全连接使用dropout，设置比率为 0.5。</p><h1 id="2-YOLO-V2"><a href="#2-YOLO-V2" class="headerlink" title="2. YOLO V2"></a>2. YOLO V2</h1><h2 id="2-1-Introduction"><a href="#2-1-Introduction" class="headerlink" title="2.1 Introduction"></a>2.1 Introduction</h2><p>YOLO V2在YOLO的基础上进行改进，有着更准，更快，更强的优点。YOLO V2引入了anchor，使用K-Means的方法，去掉了全连接层。</p><h2 id="2-2-Better"><a href="#2-2-Better" class="headerlink" title="2.2 Better"></a>2.2 Better</h2><p>YOLO有许多定位错误，召回率也较低，所以YOLO V2主要集中于提高召回率和定位能力。下面是YOLO V2使用的一些技术：</p><h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>使用BN提高了收敛速度，并且帮助正则化模型，还可以去除模型的Dropout而不会产生过拟合。</p><h3 id="High-Resolution-Classifier"><a href="#High-Resolution-Classifier" class="headerlink" title="High Resolution Classifier"></a>High Resolution Classifier</h3><p>初始YOLO以224x224的输入分辨率训练分类网络，现在增加到<code>448 x 448</code>，为了适应新的分辨率，YOLO v2 的分类网络以 <code>448 x 448</code>的分辨率先在 ImageNet上进行微调。</p><h3 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h3><p>YOLO V1使用全连接层直接预测 bounding boxes 的坐标值，为 Faster R-CNN是预测anchor boxes 的偏移量和置信度。预测偏移量而不是直接预测坐标值能够简化问题。</p><p>所以作者移除全连接层并且使用 anchor boxes 来预测 bounding boxes。</p><p>收缩网络让其运行在<code>416 x 416</code>而不是<code>448 x 448</code>的输入数据上，因为YOLO下采样因子为32，使用<code>416 x 416</code>的图像，那么输出的feature map为<code>13 x 13</code>。</p><p>YOLO仅仅预测98个 boxes 但使用 anchor boxes 能够预测上千个 boxes。使用 anchor boxes 降低了精度，但增加了 recall（达到了88%）。</p><p>使用anchor boxes有以下两个问题：</p><ul><li>box的维度是手工挑选的；</li><li>模型不稳定。</li></ul><h3 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h3><p>Anchor boxes的维度一般是手工挑选的，在训练过程网络会修改框的宽高，最终得到准确的boxes。如果一开始能够选择更好的anchor boxes，那么网络学习更加容易。所以在训练集上运行k-means 算法，来获得更好的 boxes。任意一个 box 到聚类中心 centroid 的距离表示为：</p><script type="math/tex; mode=display">d(box, centriod) = 1 - IOU(box, centroid)</script><p>作者选择k=5，即选择5个聚类中心。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200824204429.png" srcset="/img/loading.gif" alt=""></p><h3 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a>Direct location prediction</h3><p>采用Faster R-CNN的方法预测偏移量，然后计算 predicted box 的坐标，会使模型不稳定，尤其在最开始的几次迭代。如下是 Faster R-CNN的计算方法：</p><script type="math/tex; mode=display">x = (t_x * w_a) + x_a\\y = (t_y * h_a) + y_a</script><p>例如，如果$t_x$ 等于 1 或者 -1 ，那么anchor box的移动距离就会很大，从而导致模型不稳定。</p><p>作者没有直接预测偏移量，而是根据网格单元的位置来预测坐标。</p><p>feature map中的每个网格预测5个bounding box，对于每个bounding box需要预测5个坐标值 $t_x, t_y, t_w, t_h, t_o$。</p><script type="math/tex; mode=display">Pr(object) * IOU(box, object) = \sigma(t_o)</script><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200824222128.png" srcset="/img/loading.gif" alt=""></p><h3 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a>Fine-Grained Features</h3><p>YOLO V2会获得一个<code>13 x 13</code>的 feature map，作者增加了一个<code>passthrough</code>层，将前面<code>26 x 26 x 512</code>的feature map转换成<code>13 x 13 x 1024</code> 的feature map 然后与当前的feature map执行concat操作。</p><h3 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h3><p>因为模型中去掉了全连接层，所以原则上可以使用任意尺度的输入数据。为了提高模型的鲁棒性，采用多尺度训练。因为模型下采样因子为32，所以不同的尺度也选择为32的倍数：{320， 352，….，608}。</p><h2 id="2-3-Faster"><a href="#2-3-Faster" class="headerlink" title="2.3 Faster"></a>2.3 Faster</h2><p>论文提出了Darknet-19，类似于VGG网络，大量使用<code>3 x 3</code>卷积。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200824234207.png" srcset="/img/loading.gif" alt=""></p><p><strong>Training for detection</strong>。需要修改分类网络来适应检测问题：移除最后的卷积层并使用3个<code>3 x 3</code>卷积层进行替换，每个卷积层有1024个<code>3 x 3</code>的卷积核，<code>3 x 3</code>卷积之后接一个<code>1 x 1</code>卷积，卷积核的数量为用于检测需要的输出数量，比如对于VOC需要预测5个boxes的5个坐标值和每个box的20个类别概率，则卷积核的数量为<code>5*5+5*20=125</code>。</p><h2 id="2-4-Stronger"><a href="#2-4-Stronger" class="headerlink" title="2.4 Stronger"></a>2.4 Stronger</h2><h1 id="3-YOLO-V3"><a href="#3-YOLO-V3" class="headerlink" title="3. YOLO V3"></a>3. YOLO V3</h1><p>YOVO v3 feature map中的每个方格预测3个预测框，每个预测框包含<code>(4 + 1 + 80)</code>个数据信息，即4个坐标，1个objectness score，80个类别概率，objectness score是用来判断预测框中是否包含目标。</p><h2 id="3-1-Bounding-Box-Prediction"><a href="#3-1-Bounding-Box-Prediction" class="headerlink" title="3.1 Bounding Box Prediction"></a>3.1 Bounding Box Prediction</h2><p>bounding box预测与YOLO v2一样，预测四个坐标。训练时采用<code>sum of squared</code>损失函数。</p><p>YOLOv3为每个bounding box 预测一个 objectness score，使用 logistic regression 进行预测。</p><h2 id="3-2-Class-Prediction"><a href="#3-2-Class-Prediction" class="headerlink" title="3.2 Class Prediction"></a>3.2 Class Prediction</h2><p>因为一个 bounding box 可能包含多个类别，所以没有使用 softmax 对类别进行预测，而是使用 logistic classifiers，即对每一个类别训练一个逻辑回归分类器。</p><h2 id="3-3-Prediction-Across-Scales"><a href="#3-3-Prediction-Across-Scales" class="headerlink" title="3.3 Prediction Across Scales"></a>3.3 Prediction Across Scales</h2><p>YOLOv3从不同尺度提取特征，最后提供3个不同尺度的feature map，分别为<code>13 x 13</code>、<code>26 x 26</code>、<code>52 x 52</code>。比如要得到<code>26 x 26</code>的feature map，需要将<code>13 x 13</code>的 feature map进行两倍上采样，然后与前面的<code>26 x 26</code>的feature map进行<code>concat</code>操作。不同尺度的feature map最后产生的输出大小为<code>N x N x [3*(4+1+80)]</code>，那么3个尺度最后的输出为<code>(10647, 85)</code>。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/v2-6467358da558bcb282b9204cf1e601cf_r.jpg" srcset="/img/loading.gif" alt=""></p><h2 id="3-4-Feature-extractor"><a href="#3-4-Feature-extractor" class="headerlink" title="3.4 Feature extractor"></a>3.4 Feature extractor</h2><p>设计了Darknet-53网络，借鉴Resnet中特征融合的思想，运行效果与ResNet-152差不多，但速度是其两倍。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200825225006.png" srcset="/img/loading.gif" alt=""></p><h2 id="3-5-标注-anchor-box"><a href="#3-5-标注-anchor-box" class="headerlink" title="3.5 标注 anchor box"></a>3.5 标注 anchor box</h2><p>训练提供的数据集只是包含图片数据和ground truth的坐标数据，需要在原始数据基础上生成anchor box，然后进行相应标注，生成与网络输出格式一样的数据，再直接用到损失函数中。</p><h3 id="1-objectness-score"><a href="#1-objectness-score" class="headerlink" title="1. objectness score"></a>1. objectness score</h3><p>当锚框包含了物体时，objectness=1，表示预测框属于正类；当锚框不包含物体时，设置objectness=0，表示锚框属于负类；</p><h3 id="2-location"><a href="#2-location" class="headerlink" title="2. location"></a>2. location</h3><p>对于objectness为1的anchor box生成位置信息$(t_x^<em>, t_y^</em>, t_w^<em>, t_h^</em>)$，但因为sigmoid的反函数不好求，$(t_x<em>, t_y^</em>)$使用的是$(dx^<em>, dy^</em>)$.</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200831103708.png" srcset="/img/loading.gif" alt=""></p><h3 id="3-class"><a href="#3-class" class="headerlink" title="3. class"></a>3. class</h3><p>类别采用one-hot编码，例如某个anchor box 的类别信息为<code>[0, 0, 0, 1, 0, 0, 0]</code>，1表示anchor box中的物体属于该类别。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 标注预测框的objectness</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_objectness_label</span><span class="hljs-params">(img, gt_boxes, gt_labels, iou_threshold = <span class="hljs-number">0.7</span>,                         anchors = [<span class="hljs-number">116</span>, <span class="hljs-number">90</span>, <span class="hljs-number">156</span>, <span class="hljs-number">198</span>, <span class="hljs-number">373</span>, <span class="hljs-number">326</span>],                         num_classes=<span class="hljs-number">7</span>, downsample=<span class="hljs-number">32</span>)</span>:</span>    <span class="hljs-string">"""    img 是输入的图像数据，形状是[N, C, H, W]    gt_boxes，真实框，维度是[N, 50, 4]，其中50是真实框数目的上限，当图片中真实框不足50个时，不足部分的坐标全为0              真实框坐标格式是xywh，这里使用相对值    gt_labels，真实框所属类别，维度是[N, 50]    iou_threshold，当预测框与真实框的iou大于iou_threshold时不将其看作是负样本    anchors，锚框可选的尺寸    anchor_masks，通过与anchors一起确定本层级的特征图应该选用多大尺寸的锚框    num_classes，类别数目    downsample，特征图相对于输入网络的图片尺寸变化的比例    """</span>    img_shape = img.shape    batchsize = img_shape[<span class="hljs-number">0</span>]    num_anchors = len(anchors) // <span class="hljs-number">2</span>    input_h = img_shape[<span class="hljs-number">2</span>]    input_w = img_shape[<span class="hljs-number">3</span>]    <span class="hljs-comment"># 将输入图片划分成num_rows x num_cols个小方块区域，每个小方块的边长是 downsample</span>    <span class="hljs-comment"># 计算一共有多少行小方块</span>    num_rows = input_h // downsample    <span class="hljs-comment"># 计算一共有多少列小方块</span>    num_cols = input_w // downsample    label_objectness = np.zeros([batchsize, num_anchors, num_rows, num_cols])    label_classification = np.zeros([batchsize, num_anchors, num_classes, num_rows, num_cols])    label_location = np.zeros([batchsize, num_anchors, <span class="hljs-number">4</span>, num_rows, num_cols])    scale_location = np.ones([batchsize, num_anchors, num_rows, num_cols])    <span class="hljs-comment"># 对batchsize进行循环，依次处理每张图片</span>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> range(batchsize):        <span class="hljs-comment"># 对图片上的真实框进行循环，依次找出跟真实框形状最匹配的锚框</span>        <span class="hljs-keyword">for</span> n_gt <span class="hljs-keyword">in</span> range(len(gt_boxes[n])):            gt = gt_boxes[n][n_gt]            gt_cls = gt_labels[n][n_gt]            gt_center_x = gt[<span class="hljs-number">0</span>]            gt_center_y = gt[<span class="hljs-number">1</span>]            gt_width = gt[<span class="hljs-number">2</span>]            gt_height = gt[<span class="hljs-number">3</span>]            <span class="hljs-keyword">if</span> (gt_height &lt; <span class="hljs-number">1e-3</span>) <span class="hljs-keyword">or</span> (gt_height &lt; <span class="hljs-number">1e-3</span>):                <span class="hljs-keyword">continue</span>            i = int(gt_center_y * num_rows)            j = int(gt_center_x * num_cols)            ious = []            <span class="hljs-keyword">for</span> ka <span class="hljs-keyword">in</span> range(num_anchors):                bbox1 = [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, float(gt_width), float(gt_height)]                anchor_w = anchors[ka * <span class="hljs-number">2</span>]                anchor_h = anchors[ka * <span class="hljs-number">2</span> + <span class="hljs-number">1</span>]                bbox2 = [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, anchor_w/float(input_w), anchor_h/float(input_h)]                <span class="hljs-comment"># 计算iou</span>                iou = box_iou_xywh(bbox1, bbox2)                ious.append(iou)            ious = np.array(ious)            inds = np.argsort(ious)            k = inds[<span class="hljs-number">-1</span>]            label_objectness[n, k, i, j] = <span class="hljs-number">1</span>            c = gt_cls            label_classification[n, k, c, i, j] = <span class="hljs-number">1.</span>            <span class="hljs-comment"># for those prediction bbox with objectness =1, set label of location</span>            dx_label = gt_center_x * num_cols - j            dy_label = gt_center_y * num_rows - i            dw_label = np.log(gt_width * input_w / anchors[k*<span class="hljs-number">2</span>])            dh_label = np.log(gt_height * input_h / anchors[k*<span class="hljs-number">2</span> + <span class="hljs-number">1</span>])            label_location[n, k, <span class="hljs-number">0</span>, i, j] = dx_label            label_location[n, k, <span class="hljs-number">1</span>, i, j] = dy_label            label_location[n, k, <span class="hljs-number">2</span>, i, j] = dw_label            label_location[n, k, <span class="hljs-number">3</span>, i, j] = dh_label            <span class="hljs-comment"># scale_location用来调节不同尺寸的锚框对损失函数的贡献，作为加权系数和位置损失函数相乘</span>            scale_location[n, k, i, j] = <span class="hljs-number">2.0</span> - gt_width * gt_height    <span class="hljs-comment"># 目前根据每张图片上所有出现过的gt box，都标注出了objectness为正的预测框，剩下的预测框则默认objectness为0</span>    <span class="hljs-comment"># 对于objectness为1的预测框，标出了他们所包含的物体类别，以及位置回归的目标</span>    <span class="hljs-keyword">return</span> label_objectness.astype(<span class="hljs-string">'float32'</span>), label_location.astype(<span class="hljs-string">'float32'</span>), label_classification.astype(<span class="hljs-string">'float32'</span>), \             scale_location.astype(<span class="hljs-string">'float32'</span>)</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Faster R-CNN论文笔记</title>
    <link href="/2020/08/19/Faster-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/08/19/Faster-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>对于目标检测，获取候选框的位置成为发展的瓶颈，因为一般获取候选框的方法都比较耗时。<code>Selective Search</code>是其中最流行的一个方法，但在CPU上运行时，对于每张图片需要消耗2秒时间，这是不能用于实时处理的。论文中，提出了<code>Region Proposal Network</code>(RPN)网络，用来生成<code>region proposals</code>(候选区域)，RPN是一个全卷积网络。</p><h1 id="2-Faster-R-CNN"><a href="#2-Faster-R-CNN" class="headerlink" title="2. Faster R-CNN"></a>2. Faster R-CNN</h1><p>Faster R-CNN由两个模块组成：第一个模块是一个深层全卷积网络，用来生成候选区域；第二个模块是Faster R-CNN检测器。Faster R-CNN的网络结构如下：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200820211707.png" srcset="/img/loading.gif" alt=""></p><p>主要由四个部分组成：</p><ul><li>conv layers：卷积层，用来提取特征；</li><li>Region Proposal Network：生成候选区域；</li><li>RoI pooling：输入为RPN生成的各个候选框和卷积层生成的基本特征；</li><li>classifier：分类器，通过fully connect 和 softmax计算每个proposal的类别。</li></ul><h2 id="2-1-Region-Proposal-Networks"><a href="#2-1-Region-Proposal-Networks" class="headerlink" title="2.1 Region Proposal Networks"></a>2.1 Region Proposal Networks</h2><ul><li>RPN接受任意尺寸的输入并输出一系列候选框和<code>objectness score</code>（用来判断候选框是背景还是物体）；</li><li>RPN是一个全卷积神经网络；</li></ul><p>如下图是RPN的结构。首先将feature map输入到中间层，即一个<code>3 x 3</code>的卷积层，生成256维的feature map，该特征输入到<code>cls layer</code>(分类层)和<code>reg layer</code>(回归层)。对于图像上的每一个位置，都有256个特征，该特征在分类层生成<code>2k</code>个分数（2k个分数是因为：使用的是softmax回归，然后又有前景和背景两个分类），在回归层生成<code>4k</code>个偏移量（用于修正候选框），其中k指某一位置处anchors的数量。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200821164533.png" srcset="/img/loading.gif" alt=""></p><h3 id="2-1-1-Anchors"><a href="#2-1-1-Anchors" class="headerlink" title="2.1.1 Anchors"></a>2.1.1 Anchors</h3><p>在feature map的每个位置上，都设置k个候选框，这些候选框就叫做<code>anchor</code>。论文中默认使用3 scales 和 3 aspect ratios，将产生k=9个anchors。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200822111443.png" srcset="/img/loading.gif" alt=""></p><p>Anchors就是一些矩形框，可以如下表示，四个坐标为<code>[x1, y1, x2, y2]</code>，代表左上角和右下角两个坐标。<br><div class="hljs"><pre><code class="hljs undefined">[[ <span class="hljs-number">-84.</span>  <span class="hljs-number">-40.</span>   <span class="hljs-number">99.</span>   <span class="hljs-number">55.</span>] [<span class="hljs-number">-176.</span>  <span class="hljs-number">-88.</span>  <span class="hljs-number">191.</span>  <span class="hljs-number">103.</span>] [<span class="hljs-number">-360.</span> <span class="hljs-number">-184.</span>  <span class="hljs-number">375.</span>  <span class="hljs-number">199.</span>] [ <span class="hljs-number">-56.</span>  <span class="hljs-number">-56.</span>   <span class="hljs-number">71.</span>   <span class="hljs-number">71.</span>] [<span class="hljs-number">-120.</span> <span class="hljs-number">-120.</span>  <span class="hljs-number">135.</span>  <span class="hljs-number">135.</span>] [<span class="hljs-number">-248.</span> <span class="hljs-number">-248.</span>  <span class="hljs-number">263.</span>  <span class="hljs-number">263.</span>] [ <span class="hljs-number">-36.</span>  <span class="hljs-number">-80.</span>   <span class="hljs-number">51.</span>   <span class="hljs-number">95.</span>] [ <span class="hljs-number">-80.</span> <span class="hljs-number">-168.</span>   <span class="hljs-number">95.</span>  <span class="hljs-number">183.</span>] [<span class="hljs-number">-168.</span> <span class="hljs-number">-344.</span>  <span class="hljs-number">183.</span>  <span class="hljs-number">359.</span>]]</code></pre></div></p><h3 id="2-1-2-非极大值抑制（Non-Maximum-Suppression）"><a href="#2-1-2-非极大值抑制（Non-Maximum-Suppression）" class="headerlink" title="2.1.2 非极大值抑制（Non-Maximum Suppression）"></a>2.1.2 非极大值抑制（Non-Maximum Suppression）</h3><p>目标检测的过程中在同一目标的位置上会产生大量的候选框，这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框。</p><p>非极大值抑制的流程如下：</p><ul><li>根据置信度得分进行排序</li><li>选择置信度最高的边界框添加到最终输出列表中，将其从边界框列表中删除</li><li>计算所有边界框的面积</li><li>计算置信度最高的边界框与其它候选框的IoU。</li><li>删除IoU大于阈值的边界框</li><li>重复上述过程，直至边界框列表为空。</li></ul><h3 id="2-1-3-Loss-function"><a href="#2-1-3-Loss-function" class="headerlink" title="2.1.3 Loss function"></a>2.1.3 Loss function</h3><p>损失函数如下：</p><script type="math/tex; mode=display">\begin{array}{c}L\left(\left\{p_{i}\right\},\left\{t_{i}\right\}\right)=\frac{1}{N_{c l s}} \sum_{i} L_{c l s}\left(p_{i}, p_{i}^{*}\right) \\+\lambda \frac{1}{N_{r e g}} \sum_{i} p_{i}^{*} L_{r e g}\left(t_{i}, t_{i}^{*}\right)\end{array}</script><p>$p_i^<em>$ 是 ground-truth label，如果anchor box是正样本，则为1，反之为0。$L_{cls}$是两个类别（目标和非目标）的 log loss 函数；$L_{reg}(t_i, t^</em>_i) = R(t_i-t_i^*)$，其中R()函数是<code>smooth L1</code>损失函数：</p><script type="math/tex; mode=display">smooth_{L_1}(x) = \left\{\begin{array}{1}0.5x^2, if\  |x| < 1 \\|x|-0.5, otherwise\end{array}\right.</script><p>$t_i$ 是关于anchor box坐标偏移量的预测值，即 $t_i$ 都是 reg layer 生成的数据。</p><script type="math/tex; mode=display">\begin{aligned}t_{\mathrm{x}} &=\left(x-x_{\mathrm{a}}\right) / w_{\mathrm{a}}, \quad t_{\mathrm{y}}=\left(y-y_{\mathrm{a}}\right) / h_{\mathrm{a}} \\t_{\mathrm{w}} &=\log \left(w / w_{\mathrm{a}}\right), \quad t_{\mathrm{h}}=\log \left(h / h_{\mathrm{a}}\right) \\t_{\mathrm{x}}^{*} &=\left(x^{*}-x_{\mathrm{a}}\right) / w_{\mathrm{a}}, \quad t_{\mathrm{y}}^{*}=\left(y^{*}-y_{\mathrm{a}}\right) / h_{\mathrm{a}} \\t_{\mathrm{w}}^{*} &=\log \left(w^{*} / w_{\mathrm{a}}\right), \quad t_{\mathrm{h}}^{*}=\log \left(h^{*} / h_{\mathrm{a}}\right)\end{aligned}</script><p>其中$x,x_a,x^*$ 分别表示 predicted box，anchor box 和 ground-truth box 的坐标值。</p><h2 id="2-2-RoI-pooling"><a href="#2-2-RoI-pooling" class="headerlink" title="2.2 RoI pooling"></a>2.2 RoI pooling</h2><p>RoI pooling层的输入是RPN网络生成的一系列候选框和conv layer 生成的feature map，然后将每个feature map划分为<code>7 x 7</code>的子窗口，再然后对每个子窗口使用max pool，那么最后的输出大小为<code>7 x 7</code>。使用 RoI pooling能够固定输出的大小，从而能够处理多尺度的候选框。</p><h2 id="2-3-Sharing-Features-for-RPN-and-Fast-R-CNN"><a href="#2-3-Sharing-Features-for-RPN-and-Fast-R-CNN" class="headerlink" title="2.3 Sharing Features for RPN and Fast R-CNN"></a>2.3 Sharing Features for RPN and Fast R-CNN</h2><p>论文中采用<code>4-Step Alternating Training</code>方法来训练RPN和Fast R-CNN，前两步没有共享卷积层。</p><ol><li>训练RPN；</li><li>使用第一步训练的RPN产生的候选框来训练Fast R-CNN；</li><li>固定共享的卷积层，对RPN网络进行微调；</li><li>固定共享的卷积层，对Fast R-CNN进行微调。</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FCN论文笔记</title>
    <link href="/2020/08/19/FCN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/08/19/FCN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1、Introduction"><a href="#1、Introduction" class="headerlink" title="1、Introduction"></a>1、Introduction</h1><p>论文地址：<a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a></p><p>FCN使用全卷积神经网络用于语义分割，网络能够接受任意大小的输入数据，并产生相应大小的输出结果。FCN是对图像进行像素级的分类，即对图像中的每个像素点进行分类。FCN定义了一个创新的<code>skip architecture</code>，该结构将深层的粗糙的语义信息与浅层的细微的信息进行特征融合。</p><ul><li>全卷积神经网络，可以接受任意大小的输入；</li><li>最后输出使用上采样的方法，从而对图像每个像素点进行分类；</li><li>skip architecture进行特征融合。</li></ul><h1 id="2-Fully-convolutional-networks"><a href="#2-Fully-convolutional-networks" class="headerlink" title="2. Fully convolutional networks"></a>2. Fully convolutional networks</h1><h2 id="2-1-Adapting-classifiers-for-dense-prediction"><a href="#2-1-Adapting-classifiers-for-dense-prediction" class="headerlink" title="2.1 Adapting classifiers for dense prediction"></a>2.1 Adapting classifiers for dense prediction</h2><p>普通的神经网络采用固定大小的输入并产生固定大小的输出，因为这些神经网络在最后都使用了全连接层。所以可以将全连接层转换成全卷积层，从而可以使用任意大小的输入。</p><blockquote><p>为什么全连接层需要使用固定大小的输入？</p><p>因为全连接层的神经元数量是固定的，参数数量也是固定的，比如某一全连接层神经元数量为1000，输入数据的维度为4096，则参数的规模为<code>1000 x 4096</code>，则对于一个样本而言其大小只能为<code>4096 x 1</code>, 而卷积运算使用的是滑动窗口的方式，其输入大小不需要固定。</p></blockquote><p>将全连接层转换成全卷积层之后，再添加一个上采样层，使输出与输入大小一样，从而实现对每个像素点的预测。</p><h2 id="2-2-Upsampling-is-backwards-strided-convolution"><a href="#2-2-Upsampling-is-backwards-strided-convolution" class="headerlink" title="2.2 Upsampling is backwards strided convolution"></a>2.2 Upsampling is backwards strided convolution</h2><p>为了实现<code>dense prediction</code>，使用上采样将输出结果的大小变换成输入大小，上采样主要有插值法和反卷积（deconvolution）两种方式, 其实反卷积更加合适的叫法是<code>transposed convolution</code>(转置卷积)。</p><h3 id="2-2-1-反卷积（转置卷积）"><a href="#2-2-1-反卷积（转置卷积）" class="headerlink" title="2.2.1 反卷积（转置卷积）"></a>2.2.1 反卷积（转置卷积）</h3><p>如下是卷积的运算过程，数据大小为<code>4 x 4</code>, 卷积核大小为<code>3 x 3</code>，输出大小为<code>2 x 2</code></p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/479ce3311c7f4d12be27353ab7087f7e.gif" srcset="/img/loading.gif" alt=""></p><p>将卷积核展开成如下系数矩阵C，将输入数据展开成<code>16 x 1</code>的矩阵X，则输出Y可以表示为$Y = CX$。那么X可以表示为$X = C^TY$，所以反卷积将卷积核的转置矩阵与输入进行相乘。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200820164326.png" srcset="/img/loading.gif" alt=""></p><h1 id="3-Segmentation-Architecture"><a href="#3-Segmentation-Architecture" class="headerlink" title="3. Segmentation Architecture"></a>3. Segmentation Architecture</h1><h2 id="3-1-Combining-what-and-where"><a href="#3-1-Combining-what-and-where" class="headerlink" title="3.1 Combining what and where"></a>3.1 Combining what and where</h2><p>使用<code>skip architecture</code>, 将低层的特征与最后的特征进行特征融合，如下图所示，最后就有三种不同类型的网络，分别为<code>FCN32s</code>、<code>FCN16</code>s、<code>FCN8s</code>。</p><ul><li>FCN32s：直接将pool5的特征进行32倍上采用得到最终结果；</li><li>FCN16s：将pool4的特征与pool5进行2倍上采用的数据进行特征融合，然后进行16倍上采样。</li></ul><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200820154634.png" srcset="/img/loading.gif" alt=""></p><p>下面是三种网络的结果对比，可见8倍上采样的结果最好，因为其融入了更多细微的特征。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200820170828.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>语义分割</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fast R-CNN论文笔记</title>
    <link href="/2020/07/25/Fast-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/25/Fast-R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><h2 id="1-1-R-CNN-and-SPPnet"><a href="#1-1-R-CNN-and-SPPnet" class="headerlink" title="1.1 R-CNN and SPPnet"></a>1.1 R-CNN and SPPnet</h2><p>R-CNN有如下几个缺点：</p><ul><li>训练要经过多个步骤。首先需要训练一个CNN用来提取特征，然后根据提取的特征训练多个SVM分类器，最后训练bounding-box回归器来优化bounding-box的位置。</li><li>训练非常消耗空间和时间。为了训练SVM分类器和bounding-box回归器，需要将提取的特征保存到磁盘中，这将占用较大存储资源，同时读取这些数据时，也要消耗一定时间。</li><li>目标检测非常缓慢。测试时，需要在每个候选框中提取特征，即对每个候选框进行卷积运算，这将带来大量的重复运算。</li></ul><p>SPPnet通过共享计算的方式提高速度。SPPnet对整个图片进行计算从而获得feature map，然后从该feature map中提取某个候选区域的特征。</p><h2 id="1-2-Contributions"><a href="#1-2-Contributions" class="headerlink" title="1.2 Contributions"></a>1.2 Contributions</h2><p>为了解决R-CNN和SPPnet中的缺点，论文中提出了<code>Fast R-CNN</code>, Fast R-CNN有如下优点：</p><ul><li>更高的mAP；</li><li>训练是单步骤的；</li><li>训练能更新所有网络层；</li><li>不需要缓存特征。</li></ul><h1 id="2-Fast-R-CNN-architecture"><a href="#2-Fast-R-CNN-architecture" class="headerlink" title="2. Fast R-CNN architecture"></a>2. Fast R-CNN architecture</h1><p>Fast R-CNN的整体结构如下图所示：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200725114510.png" srcset="/img/loading.gif" alt=""></p><p>网络将整幅图片和一系列<strong>候选区域</strong>作为输入（所以需要预先获取候选区域），首先经过几个卷积层和最大池化层得到feature map，然后对于每个候选区域在整个feature map中都有一个对应的区域，经过<code>RoI pooling layer</code>之后获得一个对应的固定长度的特征向量。然后将每个特征向量输入到全连接层，最后分支成两个输出层：一个softmax用于判断候选区域的类别，一个bbox regressor用于改善边界框的位置。</p><h2 id="2-1-The-RoI-pooling-layer"><a href="#2-1-The-RoI-pooling-layer" class="headerlink" title="2.1 The RoI pooling layer"></a>2.1 The RoI pooling layer</h2><p>RoI(region of interest)：感兴趣区域，也就是原始图像中的候选区域，经过Conv之后，感兴趣区域也要映射到feature map中的对应位置。论文中，RoI是feature map中的一个长方形窗口。</p><p>对于不同的候选区域，它们的大小都不一样，在R-CNN中会使用一些变形操作将其转换到需要的尺寸，但使用变形之后，会造成部分特征损失。Fast R-CNN使用<code>spatial pyramid pooling layer</code>（空间金字塔池化）,对于任意尺寸的RoI，都会产生固定大小为<code>H x W</code>的特征向量(论文中采用7x7的大小)。</p><p>RoI定义为四元组<code>(r, c, h, w)</code>，其中<code>(r, c)</code>表示左上角的位置，<code>(h, w)</code>表示窗口的高度和宽度。在进行RoI max pooling时，先将RoI划分为<code>H x W</code>个大小为<code>h/H x w/W</code>的子窗口，然后对子窗口使用最大池化操作，那么最后输出大小为<code>H x W</code>。</p><h2 id="2-2-Initializing-from-pre-trained-networks"><a href="#2-2-Initializing-from-pre-trained-networks" class="headerlink" title="2.2 Initializing from pre-trained networks"></a>2.2 Initializing from pre-trained networks</h2><p>先使用ImageNet数据集对CNN网络进行预训练（论文中使用的VGG），然后用预训练的网络来初始化Fast R-CNN，初始化前需要进行3项转换。</p><ul><li>最后一个的最大池化层用RoI pooling layer替换；</li><li>输出层使用softmax和bounding-box regressors替换；</li><li>将图片数据和对应的RoI作为输入。</li></ul><h2 id="2-3-Fine-tuning"><a href="#2-3-Fine-tuning" class="headerlink" title="2.3 Fine-tuning"></a>2.3 Fine-tuning</h2><p>微调主要是用来优化softmax分类器和bounding-box回归器。</p><h3 id="1-Multi-task-loss"><a href="#1-Multi-task-loss" class="headerlink" title="1. Multi-task loss"></a>1. Multi-task loss</h3><p>优化过程的损失函数使用多任务损失。</p><script type="math/tex; mode=display">L(p, u, t^u, v) = L_{cls}(p, u) + \lambda[u \ge 1] L_{loc}(t^u, v)</script><p>其中u表示真实类别，v 表示bounding-box的真实位置，那么对于类别u其bounding-box的位置 $v = (v_x, v_y, v_w, v_h)$；p表示预测类别的概率，$t_u$为预测的位置, 并且$t_u=(t^u_x, t^u_y, t^u_w, t^u_h)$。</p><p>$[u \ge 1]$等于0时，即物体的类别为背景，背景没有边界框。</p><script type="math/tex; mode=display">[u \ge 1] = \left \{ \begin{array}{}1, u \ge 1 \\0, otherwise\end{array}\right.</script><p>其中$L_{cls}$是softmax分类器的损失值：</p><script type="math/tex; mode=display">L_{cls}(p, u) = -\log(p_u)</script><p>$L_{loc}$是bounding-box回归器的损失值：</p><script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{i \in \{x, y, w, h\}}smooth_{L_1}(t^u_i-v_i)</script><p>其中</p><script type="math/tex; mode=display">smooth_{L_1}(x) = \left \{\begin{array}{}0.5x^2, |x| \lt 1 \\|x| - 0.5, otherwise\end{array}\right.</script><h2 id="3-Fast-R-CNN-detection"><a href="#3-Fast-R-CNN-detection" class="headerlink" title="3. Fast R-CNN detection"></a>3. Fast R-CNN detection</h2><h2 id="3-1-SVD"><a href="#3-1-SVD" class="headerlink" title="3.1 SVD"></a>3.1 SVD</h2><p>网络中的全连接层参数非常多，导致计算缓慢，可以使用奇异值分解（SVD）的方法加速计算。假设权重W的大小为<code>u x v</code>,使用SVD：</p><script type="math/tex; mode=display">W \approx U \Sigma_tV^T</script><p>其中U是<code>u x t</code>的矩阵，$\Sigma_t$大小为<code>t x t</code>， $V^T$大小为<code>t x v</code>。</p><p>然后将一个全连接层转换成两个全连接层，第一个全连接层权重矩阵为$\Sigma_t V^T$，第二个全连接层的权重矩阵为 U。那么参数数量由<code>u x v</code>变成了<code>t(u + v)</code>，只要 t 远小于 u 和 v，参数数量就会大大减少。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R-CNN论文笔记</title>
    <link href="/2020/07/22/R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/22/R-CNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>R-CNN主要是用于目标检测，目标检测包括两个方面：localization和recognition，即定位目标位置和识别目标。R-CNN在VOC2012数据集上mAP（mean average precision）达到了53.3%。</p><p>在面临数据比较少的问题时，首先对CNN进行预训练然后进行微调以优化网络。</p><p>R-CNN用于目标检测时需要经过多个步骤：首先输入图像，然后在原始图像上提取出候选区域，然后将候选区域输入到CNN中提取特征，最后将提取的特征输入到分类器中判断目标类别。其中R-CNN的整体架构如下图所示。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200723103516.png" srcset="/img/loading.gif" alt=""></p><h1 id="2-Object-detection-with-R-CNN"><a href="#2-Object-detection-with-R-CNN" class="headerlink" title="2. Object detection with R-CNN"></a>2. Object detection with R-CNN</h1><p>R-CNN主要包括三个模块：</p><ol><li>第一个模块用于生成与类别无关的候选区域；</li><li>第二个模块是用于提取特征的大型卷积神经网络；</li><li>第三个模块是多个SVM分类器，使用多个分类器是因为每个类别对应一个分类器；</li></ol><p><strong>Region proposals</strong>：在图像中提取候选区域，论文中采用<code>selective search</code>的方法，大约提取2000个区域。</p><p><strong>Feature extraction</strong>：使用AlexNet网络（5个卷积层和2个全连接层，最后的输出层没有使用）提取一个4096维的特征，网络的输入是<code>227 x 227</code>的RGB图像。为了使候选区域与CNN的输入数据兼容，需要对候选区域进行转换。转换时，先将候选的边界框扩大p个像素点（论文中使用p=16）,然后将其转换到指定尺寸。</p><p><strong>Supervised pre-training</strong>：在辅助数据集（ILSVRC 2012）上训练CNN网络。主要是为了解决用于目标检测的数据比较少的问题。</p><p><strong>fine-tuning</strong>：将最后输出层的1000个神经元替换成<code>N + 1</code>个神经元，N表示目标的类别数，+1是因为多了一个类别：背景。然后使用候选区域对CNN进行训练。</p><p><strong>Object category classifiers</strong>：对每个类别训练一个SVM分类器，这些分类器将CNN产生的f7特征（即第二个全连接层）作为输入。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mAP(mean average precision)</title>
    <link href="/2020/07/22/mAP-mean-average-precision/"/>
    <url>/2020/07/22/mAP-mean-average-precision/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h1><p>mAP是用于目标检测的一项比较流行的评价指标。下面介绍一些比较重要的定义。</p><h2 id="IoU-Intersection-over-Union"><a href="#IoU-Intersection-over-Union" class="headerlink" title="IoU(Intersection over Union)"></a>IoU(Intersection over Union)</h2><p>IoU：交并比，用于评估两个边界之间的重叠比例。记<code>ground truth</code>边界框为$B_{gt}$, 预测的边界框为$B_p$, 则IoU计算的是ground truth边界框与预测边界框相交的面积占两者相并的面积的比例，</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200722230951.png" srcset="/img/loading.gif" alt=""></p><p>那么IoU的计算公式为：</p><script type="math/tex; mode=display">IoU = \frac{B_{gt} \cap B_p }{B_{gt} \cup B_{p}}</script><h2 id="TP-TN-FP-FN"><a href="#TP-TN-FP-FN" class="headerlink" title="TP, TN, FP, FN"></a>TP, TN, FP, FN</h2><ul><li>TP: True Positive, 正确划分为正例的个数，A correct detection. Detection with IOU ≥ <em>threshold</em>；</li><li>TN: True Nagative, 正确划分为负例的个数；</li><li>FP: False Positive, 错误划分为正例的个数，A wrong detection. Detection with IOU &lt; <em>threshold</em>；</li><li>FN: False Negative, 错误划分为负例的个数，A ground truth not detected。</li></ul><p>其中<code>threshold</code>一般取 $[0.5, 0.75, 0.95]$</p><h2 id="Precision-amp-Recall"><a href="#Precision-amp-Recall" class="headerlink" title="Precision &amp; Recall"></a>Precision &amp; Recall</h2><p><strong>precision</strong>：</p><script type="math/tex; mode=display">precision = \frac{TP}{TP + FP} = \frac{TP}{all\ detections}</script><p><strong>recall</strong>：</p><script type="math/tex; mode=display">racall = \frac{TP}{TP + FN} = \frac{TP}{all\ ground\ truths}</script><p>下图也可以说明precision和recall的计算：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200722225059.png" srcset="/img/loading.gif" alt=""></p><h1 id="2-计算"><a href="#2-计算" class="headerlink" title="2. 计算"></a>2. 计算</h1><h2 id="2-1-precision和recall的计算"><a href="#2-1-precision和recall的计算" class="headerlink" title="2.1 precision和recall的计算"></a>2.1 precision和recall的计算</h2><p>首先获取了多个样本置信度，按照置信度递减的顺序排序，然后分别计算其precision和recall，计算时，注意对TP等值进行累加。</p><h2 id="2-2-AP的计算"><a href="#2-2-AP的计算" class="headerlink" title="2.2 AP的计算"></a>2.2 AP的计算</h2><p>通常AP（average precision）的定义为<code>precision-recall</code>曲线的面积。</p><p>首先绘制precision-recall曲线，然后对其平滑变成<code>zigzag pattern</code>。</p><h3 id="1-11-point-interpolation"><a href="#1-11-point-interpolation" class="headerlink" title="1. 11-point interpolation"></a>1. 11-point interpolation</h3><p>在曲线上取$[0, 0.1, 0.2, \ldots, 1.0]$这11个点，然后对其求平均值。</p><h3 id="2-Interpolating-all-points"><a href="#2-Interpolating-all-points" class="headerlink" title="2. Interpolating all points"></a>2. Interpolating all points</h3><p>其实就是求曲线在recall轴上的面积。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><p><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics#precision-x-recall-curve" target="_blank" rel="noopener">https://github.com/rafaelpadilla/Object-Detection-Metrics#precision-x-recall-curve</a></p></li><li><p><a href="https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173" target="_blank" rel="noopener">https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DenseNet论文笔记</title>
    <link href="/2020/07/21/DenseNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/21/DenseNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>论文地址：<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">Densely Connected Convolutional Networks</a></p><p>论文中提出了Dense Convolutional Network(DenseNet), 传统的L层神经网络有L个连接，但DenseNet有$\frac{L(L + 1)}{2}$个连接。DenseNet中对于每一层而言，前面所有层的feature map作为该层的输入，该层输出的feature map又作为后面所有层的输入。DenseNet与ResNet的一个不同是：特征融合时，ResNet使用像素相加，而DenseNet使用的是concat操作。DenseNet有许多引人注目的优点：</p><ul><li>减轻梯度消失问题；</li><li>加强特征传递；</li><li>促进特征的复用；</li><li>大大地减少参数的数量，因此需要更少的计算。</li><li>有一定的正则化效果，减轻了过拟合。</li></ul><p>下图所示是一个dense block：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200721121532.png" srcset="/img/loading.gif" alt=""></p><h1 id="2-DenseNet"><a href="#2-DenseNet" class="headerlink" title="2. DenseNet"></a>2. DenseNet</h1><p>DenseNet中的每一层使用一个非线性转换$H_l(·)$，其中$l$表示第$l$层，$H_l(·)$由一系列操作组成：BN，ReLU，Pooling，或者Convolution。那么第$l$层将完成如下操作：</p><script type="math/tex; mode=display">x_l = H_l([x_0, x_1, \ldots, x_{l - 1}])</script><p>其中$[x_0, x_1, \ldots, x_{l - 1}]$表示$0, 1, \ldots,l-1$层的feature map执行concat操作之后的结果。其中$H_l(·)$函数包含以下三个连续的操作：BN，然后ReLU，然后是<code>3 x 3</code>Convolution。</p><p><strong>池化层</strong>。当feature map的尺寸改变时，就无法使用concat操作，但是使用下采样改变feature map的尺寸是必要的。因此为了使用下采用，将网络划分为多个dense block，每个block中使用dense connect。在两个block之间引入一个<code>transition layer</code>，该层包含三个操作：BN，<code>1 x 1</code>卷积，<code>2 x 2</code>平均池化。</p><p><strong>Growth rate</strong>。假设每个$H_l(·)$函数产生<code>k</code>个feature map（<strong>feature map的数量也就是通道数</strong>），那么第$l$层的输入有$k_0 + k (l - 1)$个feature map，其中$k_0$指最开始的输入的通道数。参数<code>k</code>就是growth rate。</p><p><strong>Bottleneck layers</strong>。在<code>3 x 3</code>卷积层之前引入<code>1 x 1</code>卷积来减少feature map的数量，那么$H_l(·)$函数将完成如下操作<code>BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)</code>, 然后将该网络称为<code>DenseNet-B</code>.实验中，<code>1 x 1</code>卷积产生<code>4k</code>个feature map。</p><p><strong>Compression</strong>。在<code>transition layer</code>减少feature map的数量。假设一个dense block有m个feature map，接下来的<code>transition layer</code>产生$\theta m$个输出feature map，其中$0&lt;\theta&lt;1$，该种网络称为<code>DenseNet-C</code>。实验中，将$\theta$设置为0.5。</p><p><strong>实现细节</strong>。所有的<code>3 x 3</code>卷积padding=1，以保证feature map尺寸不变。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Residual Net论文笔记</title>
    <link href="/2020/07/18/Residual-Net%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/18/Residual-Net%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>论文地址：<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>深层神经网络在图像分类方面带来了一系列突破，有许多证据表明网络的深度是非常重要的。但是不断增加网络深度会带来许多问题。</p><ul><li><p>梯度消失和梯度爆炸问题。这个问题可以通过使用<code>Batch Normalization</code>来解决。</p></li><li><p><code>degradation problem</code>（退化问题）：随着网络深度增加，精确度饱和，然后快速下降。也就是添加更多层到一个合适的网络中，会导致产生更高的<code>training error</code>，如下图所示：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200719104137.png" srcset="/img/loading.gif" alt=""></p></li></ul><p>论文中，为了解决退化问题，提出了<code>residual learning framework</code>.</p><p>这种方法，主要有两个优点：</p><ul><li>深层残差网络更容易优化；</li><li>增加深度后能够提高精确度。</li></ul><p>最后设计了一个达到152层的残差网络，在ImageNet数据集上只有3.57%的错误率，并在2015年ILSVRC图像分类比赛中获得了第一名。</p><h1 id="2-残差块"><a href="#2-残差块" class="headerlink" title="2. 残差块"></a>2. 残差块</h1><p>如下图，是一个残差块的基本结构。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200719105203.png" srcset="/img/loading.gif" alt=""><br>使用<code>shortcut connection</code>来完成残差块的计算，输入为x, 则输出为：</p><script type="math/tex; mode=display">y = F(x, W_i) + x \tag{1}</script><p>在上图两层的残差块中，$F(x, W_i)$ 可以表示为 $W_2 \sigma(W_1x)$，其中$\sigma$ 是<code>ReLU</code>激活函数。运算<code>F + x</code>通过<code>shortcut connection</code>完成<code>element-wise addition</code>操作（<strong>对应元素相加</strong>），执行该运算时，<code>F</code>和<code>x</code>的维度需要一致，如果不一致，有以下两种解决办法：</p><ul><li><code>identity mapping</code>: 填充0来增加数据维度，该方式不会增加额外的参数；</li><li><code>projection shortcut</code>: 使用该公式来进行计算：$y = F(x, W_i) + W_sx$，即增加了额外的参数$W_s$。一般是使用<code>1 x 1</code>卷积来修改x的维度。</li></ul><h1 id="3-网络架构"><a href="#3-网络架构" class="headerlink" title="3. 网络架构"></a>3. 网络架构</h1><p>设计了plain nets 和 residual nets 两种模型，进行对比。</p><h2 id="3-1-Plain-Network"><a href="#3-1-Plain-Network" class="headerlink" title="3.1 Plain Network"></a>3.1 Plain Network</h2><p>卷积层大部分使用<code>3 x 3</code>卷积，主要有以下设计规则：</p><ul><li>输入和输出尺寸相同时，卷积核的数量与上一层相同；</li><li>feature map尺寸减半时，卷积核的数量加倍。下采样是直接使用stride = 2的卷积。</li></ul><h2 id="3-2-Residual-Network"><a href="#3-2-Residual-Network" class="headerlink" title="3.2 Residual Network"></a>3.2 Residual Network</h2><p>与Plain Network基本相同，只是网络中使用了<code>shortcut connection</code>，将网络变成了残差网络。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200719114200.png" srcset="/img/loading.gif" alt=""></p><h1 id="4-实现"><a href="#4-实现" class="headerlink" title="4. 实现"></a>4. 实现</h1><p>网络中在每个卷积层之后使用<code>Batch Normalization</code>，然后使用<code>ReLU</code>激活函数，即计算顺序为<code>Conv-BN-ReLU</code>。在进行<code>shortcut connection</code>时，如果维度不相同，需要增加维度，以保证维度匹配，能够执行<code>element-wise addition</code>操作。</p><p>数据增广时，先将图像缩放，缩放尺寸为$[256, 480]$，然后执行均值减法，然后对缩放图片或水平翻转的图片进行224x224的剪裁。</p><p>训练时，使用小批量梯度下降法，mini-batch size为256，学习率为0.1，当学习率不变时对其除以10，weight_decay = 0.0001, momentum = 0.9, 没有使用Dropout正则化。</p><p>测试时，对测试数据进行<code>10-crop</code>操作，并将全连接层转换为卷积层，最后对多尺度score map 取平均值。</p><h1 id="5-实验"><a href="#5-实验" class="headerlink" title="5. 实验"></a>5. 实验</h1><h2 id="5-1-Identity-vs-Projection-Shortcuts"><a href="#5-1-Identity-vs-Projection-Shortcuts" class="headerlink" title="5.1 Identity vs. Projection Shortcuts"></a>5.1 Identity vs. Projection Shortcuts</h2><p>根据<code>shortcut</code>的不同方式，设计了三种不同类型的网络：</p><ul><li>A: 使用零填充的方式增加维度；</li><li>B: 使用<code>peojection shortcut</code>的方式增加维度，维度相同的则使用<code>identity shortcut</code>;</li><li>C: 全部使用<code>projection shortcut</code>.</li></ul><p>Identity shortcuts 对下面的瓶颈结构非常重要。</p><h2 id="5-2-Deeper-Bottleneck-Architecture"><a href="#5-2-Deeper-Bottleneck-Architecture" class="headerlink" title="5.2 Deeper Bottleneck Architecture"></a>5.2 Deeper Bottleneck Architecture</h2><p>瓶颈结构如下右图所示，使用<code>1 x 1</code>、<code>3 x 3</code>、<code>1 x 1</code>三个卷积层，第一个<code>1 x 1</code>卷积用于减少维度，第二个<code>1 x 1</code>卷积用于增加维度。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200718220612.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GoogLeNet论文笔记</title>
    <link href="/2020/07/16/GoogLeNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/16/GoogLeNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>论文地址：<a href="https://research.google.com/pubs/pub43022.html" target="_blank" rel="noopener">Going Deeper with Convolutions</a></p><p>论文打破常规，设计了一种将<code>1 x 1</code>卷积、<code>3 x 3</code>卷积、<code>5 x 5</code>卷积并联组合在一起，然后将输出结果进行<code>concatenate</code>(拼接)操作的结构，该结构叫做<code>Inception</code>，Inception主要特点是改善了对计算资源的利用。论文后面利用<code>Inception</code>设计了一个有<code>22</code>层的深层神经网络——<code>GoogLeNet</code>，该网络主要用于图像分类和目标检测，网络参数比AlexNet的参数少12倍，并且在2014年的ILSVRC比赛中获得了第一名。</p><h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h1><ol><li>GoogLeNet中多次使用Inception结构；</li><li>GoogLeNet中大量使用<code>1 x 1</code>卷积，主要有两个作用：<ul><li>主要用于降维以解决计算瓶颈的问题；</li><li>增加网络的深度和宽度而不用使用惩罚项，网络的<strong>宽度</strong>是指每层的单元数，也就是卷积核的数量。</li></ul></li><li>目标检测当前技术主要是R-CNN，R-CNN可以分解成两个子问题：<ul><li>利用底层的颜色和纹理等特性初步获取物体的位置；</li><li>使用分类器判断该位置处的物体类别。</li></ul></li></ol><h1 id="3-MOtivation-and-High-Level-Consideration"><a href="#3-MOtivation-and-High-Level-Consideration" class="headerlink" title="3. MOtivation and High Level Consideration"></a>3. MOtivation and High Level Consideration</h1><p>增加网络的深度和宽度是提高性能的最直接的方法，但有两个主要的缺点：</p><ul><li>增加网络的尺寸意味着参数数量更多，导致网络更容易过拟合，特别是训练的数据集数量有限的时候。</li><li>增加计算资源。</li></ul><p>解决上述问题的基本方法是：将全连接换成稀疏连接（卷积就是一种稀疏连接）。传统网络通常使用随机稀疏连接，但AlexNet对全连接的使用，又改变了这一趋势。通常全连接是为了更好的进行并行计算，而稀疏连接是为了打破对称来改善学习。</p><h1 id="5-Inception"><a href="#5-Inception" class="headerlink" title="5. Inception"></a>5. Inception</h1><p>Inception的主要思想是：<strong>如何使用密集成分近似最优局部稀疏结构。</strong></p><h2 id="5-1-naive-version"><a href="#5-1-naive-version" class="headerlink" title="5.1 naive version"></a>5.1 naive version</h2><p>论文中Inception的初始版本如下：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200716214820.png" srcset="/img/loading.gif" alt=""></p><ul><li>使用<code>1 x 1</code>、<code>3 x 3</code>、<code>5 x 5</code>的卷积是为了方便输出结果的对齐；</li><li>最后的输出是将卷积、max pool结果进行concat操作（<strong>注意不是逐像素相加</strong>）；</li><li>使用一个并行的池化路径有额外的好处；</li><li>随着网络层数的加深，<code>3 x 3</code>和<code>5 x 5</code><strong>卷积的数量增加</strong>，因为网络越深，网络提取的特征越抽象，通过增加卷积核的数量可以将前面的特征组合起来，从而使各种特征的可能性覆盖得更全面。</li></ul><h2 id="5-2-dimension-reduction"><a href="#5-2-dimension-reduction" class="headerlink" title="5.2 dimension reduction"></a>5.2 dimension reduction</h2><p>第一个版本的Inception结构有一个明显的问题，随着网络层数加深，Inception中<code>5 x 5</code>卷积核数量增加，这将非常消耗计算资源。可以在<code>3 x 3</code>和<code>5 x 5</code>卷积之前使用一个<code>1 x 1</code>卷积用来<strong>降低数据维度</strong>，从而减少计算量，另外需要在<code>1 x 1</code>卷积之后接一个<code>ReLU</code>激活函数。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200716214948.png" srcset="/img/loading.gif" alt=""></p><h1 id="6-GoogLeNet"><a href="#6-GoogLeNet" class="headerlink" title="6. GoogLeNet"></a>6. GoogLeNet</h1><p>模型输入是一个经过0均值处理之后的<code>224 x 224</code>的RGB图像数据。</p><p>下图是GoogLeNet的一些细节，所有的卷积操作之后都有一个<code>ReLU</code>单元，<code>#3 x 3 reduce</code>表示Inception中<code>3 x 3</code>卷积之前的<code>1 x 1</code>卷积核的数量</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200716222813.png" srcset="/img/loading.gif" alt=""></p><p>下图是GoogLeNet的网络结构。网络中通过使用<strong>辅助分类器缓解梯度消失问题</strong>，辅助分类器在训练过程中，需要将其loss值添加到总的loss中（乘以权重0.3），在测试时，将辅助分类器抛弃不用。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200716222859.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VGG论文笔记</title>
    <link href="/2020/07/14/VGG%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/14/VGG%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">论文地址</a></p><p>论文主要针对卷积神经网络的深度对大规模图像集识别精度的影响，主要贡献是使用很小的卷积核(<code>3×3</code>)构建各种深度的卷积神经网络结构。</p><h2 id="1-1-特点"><a href="#1-1-特点" class="headerlink" title="1.1 特点"></a>1.1 特点</h2><ul><li>使用小卷积核，几乎全部使用<code>3 x 3</code>的卷积核；</li><li>网络层数深；</li><li>小池化核，使用的都是<code>2 x 2</code>的池化核；</li><li>前两个全连接层使用<code>dropout</code>正则化；</li><li>测试阶段，全连接层转换成卷积层。</li></ul><h1 id="2-VGG网络结构"><a href="#2-VGG网络结构" class="headerlink" title="2. VGG网络结构"></a>2. VGG网络结构</h1><p>VGG的输入是一个固定大小为<code>224 x 224 x 3</code> 的RGB图像，唯一的图像预处理是使用了均值减法。网络中大部分使用的是<code>3 x 3</code>的卷积核，其中 stride = 1， padding = 1， 即使用same卷积，只有在网络<code>C</code>中使用了<code>1 x 1</code>卷积。网络中有5个最大池化层，池化层放在几个卷积层之后，其中池化层的大小为<code>2 x 2</code>, stride = 2。卷积层之后是3个全连接层，第一个全连接层的输入大小为<code>7 x 7 x 512</code>，与AlexNet网络一样，神经元的数量分别是4096、4096、1000, 其中前两个全连接层使用<code>dropout</code>正则化（<code>keep_prob = 0.5</code> ）。最后一层是<code>softmax</code>层。</p><h2 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h2><p>设计了如下<code>A-E</code>6个网络，网络深度从11增加到19，channel数从64增加到512，channel要么不变，要么加倍。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200714210701.png" srcset="/img/loading.gif" alt=""></p><h2 id="2-2-讨论"><a href="#2-2-讨论" class="headerlink" title="2.2 讨论"></a>2.2 讨论</h2><p>AlexNet第一层使用卷积核大小为<code>7 x 7</code>， 步长为4的卷积，ZFNet第一层使用卷积核大小为<code>5 x 5</code>, 步长为2的卷积，而我们在整个网络中都是使用<code>3 x 3</code>的卷积（除了在网络C中使用了<code>1 x 1</code>卷积）。不难发现：2个<code>3 x 3</code>的卷积层的感受野为<code>5 x 5</code>; 3个<code>3 x 3</code>的卷积层的感受野是<code>7 x 7</code>。</p><p><strong>1. 为什么使用3个<code>3 x 3</code>的卷积层代替单个<code>7 x 7</code>的卷积层？</strong></p><ul><li>3个卷积层之后都有一个<code>ReLU</code>激活函数，增加了非线性程度，使决策函数更具可分性；</li><li>减少了参数数量。</li></ul><p><strong>2. 为什么使用<code>1 x 1</code>卷积？</strong></p><ul><li>增加决策函数的非线性程度但不影响感受野。</li></ul><h1 id="3-训练"><a href="#3-训练" class="headerlink" title="3. 训练"></a>3. 训练</h1><p>参数优化使用小批量梯度下降法，momentum = 0.9， batch_size = 256；使用$L_2$正则化， 正则化参数为5e-4；学习率初始化为0.01, 当验证集准确率不变时，学习率除以10。</p><h2 id="3-1-初始化参数"><a href="#3-1-初始化参数" class="headerlink" title="3.1 初始化参数"></a>3.1 初始化参数</h2><ol><li><p>随机初始化：均值为0，方差为1e-2的正态分布， biases初始为0.</p></li><li><p>先对Net-A进行训练，然后对后面的网络如Net-B,Net-C,Net-D训练时，将Net-A的权重赋给Net-B,Net-C,Net-D,其他不同的层，采用1中的随机初始化方式。</p></li></ol><h2 id="3-2-数据增广"><a href="#3-2-数据增广" class="headerlink" title="3.2 数据增广"></a>3.2 数据增广</h2><p>先对图像进行缩放(rescale)，然后进行随机水平翻转、随机RGB color shift，最后进行随机剪裁获得<code>224 x 224</code>的图像。</p><h3 id="训练集图像尺寸"><a href="#训练集图像尺寸" class="headerlink" title="训练集图像尺寸"></a>训练集图像尺寸</h3><p>假设图像缩放的尺寸为 S (training scale)，那么$ S \ge 224$。有两种设置S的方法：</p><ol><li><code>single-scale training</code>: 使用固定的S ；</li><li><code>multi-scale training</code>: 在 $[S_{min}, S_{max}]$ 中随机选择一个S （实验中$S_{min}$ = 256, $S_{max}$ = 512），也能被视作<code>scale jittering</code>。</li></ol><h1 id="4-测试"><a href="#4-测试" class="headerlink" title="4. 测试"></a>4. 测试</h1><p>测试图片缩放的尺寸为Q（test scale）。<strong>测试时，将全连接层替换成卷积层，即将第一个全连接层转换为<code>7 x 7</code>的卷积，后面两个全连接层转换为<code>1 x 1</code>的卷积, 这种方式称为dense evaluation</strong>。这样进行测试时，直接将<code>Q x Q</code>的图片数据输入即可，而不需要对测试集进行剪裁。</p><p><strong>为什么使用<code>7 x 7</code>的卷积？</strong></p><ul><li>网络中使用的same卷积，总共使用了5个池化层，则全连接层的输入为<code>7 x 7 x 512</code>（因为224 / 32 = 7, channel为512），那么第一个全连接层的参数尺寸为<code>(4096, 7 x 7 x 512)</code>。转换后参数数量不变，应该使用4096个<code>7 x 7</code>卷积（channel = 512），卷积之后的输出为<code>1 x 1 x 4096</code>。</li></ul><p><strong><code>1 x 1</code>卷积</strong></p><ul><li>第二个全连接层：参数尺寸为<code>(4096, 4096)</code>, 使用4096个<code>1 x 1</code>卷积（channel = 4096），输出为<code>1 x 1 x 4096</code>;</li><li>第三个全连接层：参数尺寸为<code>(4096, 1000)</code>, 使用1000个<code>1 x 1</code>卷积（channel = 4096），输出为<code>1 x 1 x 1000</code></li></ul><p>对测试过程进行举例说明，假如全连接层的输入为<code>8 x 8 x 512</code>（因为测试时输入图像不一定是<code>224 x 224</code>）, 三个全连接层分别替换成4096个<code>7 x 7</code>卷积、4096个<code>1 x 1</code>卷积、1000个<code>1 x 1</code>卷积，输出分别是<code>2 x 2 x 4096</code>、<code>2 x 2 x 4096</code>、<code>2 x 2 x 1000</code>, 那么最后的feature map大小为<code>2 x 2 x 1000</code>, 但只有1000个分类，所以需要对feature map求平均值，使其大小变为<code>1 x 1 x 1000</code>。</p><h2 id="4-1-单尺度评估"><a href="#4-1-单尺度评估" class="headerlink" title="4.1 单尺度评估"></a>4.1 单尺度评估</h2><p><strong>测试图像固定尺度。</strong></p><p>$Q = S$ 或者 $Q = 0.5(S_{min} + S_{max})$</p><p>单尺度评估结果如下：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200714225023.png" srcset="/img/loading.gif" alt=""></p><p>其中<code>top-5 error</code>: 预测5次，如果5次预测都错才算预测错误，以此来计算错误率。</p><ul><li>随着网络深度的加深，错误率降低，当网络层数达到19时，错误率达到饱和。</li><li>训练图像尺度抖动优于使用固定边S.</li></ul><h2 id="4-2-多尺度评估"><a href="#4-2-多尺度评估" class="headerlink" title="4.2 多尺度评估"></a>4.2 多尺度评估</h2><p><strong>测试图像的尺度抖动对性能的影响。</strong></p><p>$Q = \{S - 32, S, S + 32\}$ 或者 $Q = \{S_{min}, 0.5(S_{min} + S_{max}), S_{max}\}$</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200714225126.png" srcset="/img/loading.gif" alt=""></p><ul><li>训练图像尺度抖动优于使用固定边S；</li><li>测试阶段使用尺度抖动（scale jittering）能提高性能（与使用单尺度相比）。</li></ul><h2 id="4-3-多剪裁图像评估"><a href="#4-3-多剪裁图像评估" class="headerlink" title="4.3 多剪裁图像评估"></a>4.3 多剪裁图像评估</h2><ul><li>dense evaluation：全连接层转换成卷积层进行测试；</li><li>multi-crop evaluation： 与训练过程一样，对测试图像进行随机剪裁，将得到的多张剪裁图像输入到网络中，最后取平均值。</li></ul><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200715094536.png" srcset="/img/loading.gif" alt=""></p><p>两种方式是互补的，使用两种方式的组合优于其中任何一种方法。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习图像通道channel</title>
    <link href="/2020/07/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9B%BE%E5%83%8F%E9%80%9A%E9%81%93channel/"/>
    <url>/2020/07/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9B%BE%E5%83%8F%E9%80%9A%E9%81%93channel/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于一般的彩色图像，有RGB三个颜色通道。使用三位数组表示彩色图像数据时，默认情况下，通道维度为最后一个维度，但出于性能调整的原因，也可能是第一个维度，这两种表示方法分别叫做<code>Channels-Last</code>和<code>Channels-First</code>。比如对于一个<code>64 x 64 x 3</code>的图像，其通道为3，保存在最后一个维度，调整到第一个维度则变成<code>3 x 64 x 64</code>。</p><ul><li><strong>Channels First</strong>: 对于图像数据而言，第一个通道为颜色通道；</li><li><strong>Channels Last</strong>：最后一个通道为颜色通道。</li></ul><h1 id="如何改变通道顺序"><a href="#如何改变通道顺序" class="headerlink" title="如何改变通道顺序"></a>如何改变通道顺序</h1><p>使用numpy的<code>moveaxis</code>函数, source轴移动到destination轴，其他轴顺序不变：</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">moveaxis</span><span class="hljs-params">(a, source, destination)</span>:</span>    <span class="hljs-string">"""    Move axes of an array to new positions.    Other axes remain in their original order.    Examples    --------    &gt;&gt;&gt; x = np.zeros((3, 4, 5))    &gt;&gt;&gt; np.moveaxis(x, 0, -1).shape    (4, 5, 3)    &gt;&gt;&gt; np.moveaxis(x, -1, 0).shape    (5, 3, 4)    These all achieve the same result:    &gt;&gt;&gt; np.transpose(x).shape    (5, 4, 3)    &gt;&gt;&gt; np.swapaxes(x, 0, -1).shape    (5, 4, 3)    &gt;&gt;&gt; np.moveaxis(x, [0, 1], [-1, -2]).shape    (5, 4, 3)    &gt;&gt;&gt; np.moveaxis(x, [0, 1, 2], [-1, -2, -3]).shape    (5, 4, 3)    """</span></code></pre></div><p>比如将<code>64 x 64 x 3</code>的图像转换为<code>3 x 64 x 64</code>:</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npx = np.random.randn(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>)x = np.moveaxis(x, <span class="hljs-number">-1</span>, <span class="hljs-number">0</span>)</code></pre></div><h1 id="各框架下通道顺序"><a href="#各框架下通道顺序" class="headerlink" title="各框架下通道顺序"></a>各框架下通道顺序</h1><ul><li>Pytorch：<code>(N, C, H, W)</code>, 即Channels First；</li><li>Tensorflow: <code>(N, H, W, C)</code>，即Channels Last，也支持<code>(N, C, H, W)</code></li></ul><p>其中：</p><blockquote><p>N: 样本数量；C: channel；H: 图像高度；W: 图像宽度</p></blockquote><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p>在使用卷积时，需要填写<code>channel</code>参数。Pytorch的Conv2d函数如下：</p><div class="hljs"><pre><code class="hljs python">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-keyword">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>)</code></pre></div><p>Conv2d函数中关于channel有两个参数：in_channels表示输入图像通道数，out_channels表示输出通道数，其实就是表示<strong>卷积核的数量</strong>。</p><blockquote><ul><li><strong>in_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>) – Number of channels in the input image</li><li><strong>out_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>) – Number of channels produced by the convolution</li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet论文笔记</title>
    <link href="/2020/07/13/AlexNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/13/AlexNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>AlexNet是一个大型的深层神经网络，能够对高分辨率(high resolution)的图像进行分类。AlexNet是2012年论文<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener">ImageNet Classification with Deep ConvolutionalNeural Networks</a>中提出的一种卷积神经网络结构，并在12年的ImageNet分类赛上以大幅优势领先第二名，从而使得深度卷积神经网络CNN在图像分类上的应用掀起一波热潮，AlexNet使用了一些新的技术，比如使用ReLU激活函数加速训练，采用了Dropout防止过拟合，使用双GPU并行训练加快训练速度。</p><h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>AlexNet由5个卷积层 + 3个全连接层构成。</p><h2 id="非线性ReLU函数"><a href="#非线性ReLU函数" class="headerlink" title="非线性ReLU函数"></a>非线性ReLU函数</h2><p>使用ReLU激活函数比sigmoid或者tanh效果更好，因为sigmoid和tanh在深层神经网络的训练中容易造成梯度饱和，从而降低收敛的速度，使用ReLU函数训练速度更快。</p><h2 id="Overlapping-Pooling-重叠池化"><a href="#Overlapping-Pooling-重叠池化" class="headerlink" title="Overlapping Pooling(重叠池化)"></a>Overlapping Pooling(重叠池化)</h2><p>假设池化层的 kernel_size 为 z, 步长为 s。如果<code>z = s</code>, 则池化不会发生重合；如果<code>z &gt; s</code>，则会出现重合。AlexNet使用 z = 3, s = 2的最大池化。训练模型发现使用重叠池化更难发生过拟合现象。</p><h2 id="Local-Response-Normalization-局部响应归一化"><a href="#Local-Response-Normalization-局部响应归一化" class="headerlink" title="Local Response Normalization(局部响应归一化)"></a>Local Response Normalization(局部响应归一化)</h2><p>该方法未得到广泛应用，现在多用Batch Normalization进行归一化操作。</p><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200713140740.png" srcset="/img/loading.gif" alt=""></p><p>输入<code>224 x 224 x 3</code>的三通道图像</p><ul><li>第一个卷积层：96个大小为<code>11 x 11 x 3</code>的卷积核，卷积步长 stride = 4，输出<code>55 x 55 x 96</code>大小的数据（注意：$(224 - 11) / 4 +1= 54.25$, 卷积运算最后一次滑动一步），然后经过最大池化，输出大小为<code>27 x 27 x 96</code>；</li><li>第二个卷积层：256个大小为<code>5 x 5 x 96</code>的卷积核, same卷积，输出为<code>27 x 27 x 256</code>, 然后经过最大池化，输出为<code>13 x 13 x 256</code>;</li><li>第三个卷积层：384个大小为<code>3 x 3 x 256</code>的卷积核，same卷积，输出为<code>13 x 13 x 384</code>;</li><li>第四个卷积层：384个大小为<code>3 x 3 x 384</code>的卷积核，same卷积，输出为<code>13 x 13 x 384</code>;</li><li>第五个卷积层：256个大小为<code>3 x 3 x 384</code>的卷积核，same卷积，输出为<code>13 x 13 x 256</code>, 然后经过最大池化，输出为<code>6 x 6 x 256</code>，将数据展开传到全连接层;</li><li>三个全连接层：最后三个全连接层的神经元数量分别为4096、4096、1000.</li></ul><h1 id="降低过拟合"><a href="#降低过拟合" class="headerlink" title="降低过拟合"></a>降低过拟合</h1><h2 id="数据增广"><a href="#数据增广" class="headerlink" title="数据增广"></a>数据增广</h2><ol><li>图像平移和水平反射。通过从256×256幅图像中提取随机224×224块图像(及其水平反射的图像)，其实就是随机剪裁（crop），并在这些提取的图像上训练我们的网络。这将我们的训练集的大小增加了2048倍（因为：$(256 - 224)^2 \times 2 = 2048$）。<ul><li><strong>测试的时候</strong>：对左上、左下、右上、右下、中间这几个位置分别剪裁，然后对图像进行水平翻转，再进行剪裁，最终进行了10次剪裁，即一张图片经过数据增强获得了10张图片，这种剪裁的方式称为<strong>10-crop</strong>。然后将这10张图片输入网络中，得到10个输出，将输出进行平均，得到最后结果。</li></ul></li><li>改变了训练图像中RGB通道的强度。在整个imagenet训练集中对RGB像素值集执行PCA（主成分分析）操作。</li></ol><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>采用<code>keep_prob = 0.5</code>的Dropout正则化，主要是在全连接层前两层使用Dropout。这种技术减少神经元之间的相互适应，因为神经元不能依赖其他神经元的存在。实验发现Dropout使迭代次数加倍。</p><p>训练时使用全部神经元，但是乘上系数<code>keep_prob</code>。</p><h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><p>使用小批量梯度下降法进行参数更新，其中<code>momentum = 0.9</code>, <code>weight_decay = 0.0005</code>.参数更新公式如下：</p><script type="math/tex; mode=display">v_{i+1} = 0.9v_i - 0.0005·\epsilon·\omega_i - \epsilon·d\omega</script><script type="math/tex; mode=display">\omega_{i + 1} = \omega_{i} + v_{i + 1}</script>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Batch Normalization</title>
    <link href="/2020/07/11/Batch%20Normalization/"/>
    <url>/2020/07/11/Batch%20Normalization/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h1><p>对于深层网络的训练，调参非常困难，因为层与层之间存在高度的关联性和耦合性。当底层网络中的参数发生微弱变化时，这些微弱的变化随着网络层数的加深而被放大。对于深层网络，主要存在以下两个问题：</p><ul><li>上层网络需要不停调整来适应输入数据分布的变化，导致学习速率的降低；</li><li>网络的训练容易陷入梯度饱和区，减缓网络收敛速度：比如对于sigmoid或者tanh激活函数，网络训练过程中，随着层数的加深，输出的结果会越来越大，此时容易陷入梯度饱和区，梯度趋近于0，参数的更新速度就会减慢。</li></ul><h1 id="Batch-Normalization-批量归一化"><a href="#Batch-Normalization-批量归一化" class="headerlink" title="Batch Normalization (批量归一化)"></a>Batch Normalization (批量归一化)</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>因为在深层网络中，数据分布不同、输出数值较大对网络的训练影响较大，那么只要能解决这两个问题就能对网络有很好的优化。可以尝试将数据中的每个特征转换成符合标准正态分布的数据（即期望为0， 方差为1）。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>在一个神经网络中，对于第$l$层有如下定义：</p><ul><li>m: 样本数量；</li><li>$\mu_j$：第 j 个神经元的平均值；</li><li>$\sigma_j^2$：第 j 个神经元的方差；</li></ul><p>对数据进行batch normalizaiton操作（对Z还是对A进行norm操作没有定论，一般对Z进行norm操作）：</p><script type="math/tex; mode=display">\begin{array}{l}\mu_{j}=\frac{1}{m} \sum_{i=1}^{m} Z_{j}^{(i)} \\\sigma_{j}^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(Z_{j}^{(i)}-\mu_{j}\right)^{2} \\\hat{Z}_{j}=\frac{Z_{j}-\mu_{j}}{\sqrt{\sigma_{j}^{2}+\epsilon}}\end{array}</script><blockquote><p>$\epsilon 防止方差为0$</p></blockquote><p>上述操作可以概括为：先对数据进行0中心化操作，然后除以标准差。通过上述变换，<strong>将每个特征的分布均值为0，方差为1</strong></p><p>但这样会使数据的分布始终不变，导致数据表达能力的缺失。对norm后的数据进行线性变换：$\hat{Z_j} = \gamma\hat Z_j + \beta$. <strong>其中$\gamma$ 和 $\beta$ 也是需要学习的参数</strong>，所以反向传播时需要求的梯度有：$dZ$ 、$d\gamma$、$d\beta$。</p><h2 id="测试阶段使用Batch-Normalization"><a href="#测试阶段使用Batch-Normalization" class="headerlink" title="测试阶段使用Batch Normalization"></a>测试阶段使用Batch Normalization</h2><p>使用norm时需要求特征的平均值和方差，这个只能对训练集使用，而不能直接求测试集的平均值和方差。比如，如果测试时，只有一个样本，求的平均值和方差就会有较大偏差。</p><p>正确做法是：保留训练集的平均值和方差，然后应用在测试数据上。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>使得网络中每层输入数据的分布相对稳定，加速模型学习速度；</li><li>使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定，没有使用BN的深层网络底层参数发生细微变化，传递到深层后就会被放大。</li><li>允许网络使用饱和性激活函数，缓解梯度消失问题。</li><li>具有一定的正则化效果。</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p><strong>1. 为什么BN能够防止过拟合？</strong></p><blockquote><p>同样一个样本的输出不再仅仅取决于样本本身，也取决于跟这个样本属于同一个mini-batch的其它样本。</p></blockquote><p><strong>2. 为什么BN能够防止梯度消失？</strong></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络</title>
    <link href="/2020/07/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2020/07/09/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-基础"><a href="#1-基础" class="headerlink" title="1. 基础"></a>1. 基础</h1><p>计算机视觉面临一个挑战，就是数据的输入可能非常大。对于传统的全连接神经网络，数据庞大也就意味着需要训练的参数非常多，导致计算成本很大，效率很低。在这种情况下，难以获得足够的数据来防止过拟合，由此，出现了卷积神经网络。</p><p><em>CNN 有2大特点：</em></p><ul><li>能够有效的将大数据量的图片降维成小数据量；</li><li>能够有效的保留图片特征，符合图片处理的原则。</li></ul><h2 id="1-1-应用"><a href="#1-1-应用" class="headerlink" title="1.1 应用"></a>1.1 应用</h2><ul><li>图像分类、检索</li><li>目标定位检测</li><li>图像分割</li><li>人脸识别</li></ul><h2 id="1-2-几个常见问题"><a href="#1-2-几个常见问题" class="headerlink" title="1.2 几个常见问题"></a>1.2 几个常见问题</h2><p><strong>CNN模型所需的计算力（FLOPs：浮点运算数）如何计算？</strong></p><blockquote><p>卷积层：<img src="https://www.zhihu.com/equation?tex=%282%5Ctimes+C_%7Bi%7D+%5Ctimes+K%5E%7B2%7D-1%29%5Ctimes+H%5Ctimes+W%5Ctimes+C_%7Bo%7D" srcset="/img/loading.gif" alt="[公式]"></p><p>Ci=input channel, k=kernel size, HW=output feature map size, Co=output channel.</p></blockquote><h1 id="2-CNN的基本原理"><a href="#2-CNN的基本原理" class="headerlink" title="2. CNN的基本原理"></a>2. CNN的基本原理</h1><p>典型的卷积神经网络由3个部分组成：</p><ul><li>卷积层：提取图像中的局部特征，卷积计算后一般会使用激活函数；</li><li>池化层：降维；</li><li>全连接层：类似于传统神经网络，用来输出想要的结果。</li></ul><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200709155732.png" srcset="/img/loading.gif" alt=""> </p><h2 id="2-1-卷积"><a href="#2-1-卷积" class="headerlink" title="2.1 卷积"></a>2.1 卷积</h2><p>卷积层通过卷积核的过滤提取出图片中局部的特征，卷积层之后一般会使用激活函数进行非线性化。对于离散数据的卷积运算：首先将卷积核旋转$180^{\circ}$，然后将卷积核在图像上平滑，将卷积核与图像中对应元素相乘取和。具体的卷积操作，如下图所示（已经将卷积核旋转了$180^{\circ}$）：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/0_sxpi42l2IIpS2vuJ.gif" srcset="/img/loading.gif" alt=""><br>其中卷积核为：</p><script type="math/tex; mode=display">kernel = \begin{bmatrix}1&0&1\\0&1&0\\1&0&1\end{bmatrix}</script><p>卷积操作后输出的图像尺寸：$(n +2p -f)/s + 1$, 其中n为输入图像尺寸，padding为p, 卷积核大小为f， 步长为s。上图的卷积操作：n=5, p=0, f=3, s=1.</p><p>选择填充多少像素，将卷积分为：</p><ul><li>Valid卷积：不填充；</li><li>Same卷积：填充</li></ul><p>卷积核的大小一般为奇数：</p><ul><li>有一个中心点，便于指出过滤器的位置；</li><li>如果为偶数，需要使用不对称填充。</li></ul><p><strong>注意</strong>：按照数学中的卷积运算，需要将卷积核进行翻转操作，但在深度学习中，一般不使用翻转操作。</p><h3 id="padding（填充）"><a href="#padding（填充）" class="headerlink" title="padding（填充）"></a>padding（填充）</h3><p>卷积操作时，如果不填充，则每次运算完成后，图像将会缩小，而且图像边缘的大部分信息都丢失了。填充p个像素点后，图像大小变为<code>n+2p</code>。一般用0填充。</p><h3 id="strides（步长）"><a href="#strides（步长）" class="headerlink" title="strides（步长）"></a>strides（步长）</h3><p>步长是指平滑移动的距离。</p><h3 id="二维卷积与三维卷积"><a href="#二维卷积与三维卷积" class="headerlink" title="二维卷积与三维卷积"></a>二维卷积与三维卷积</h3><p><strong>在讨论卷积核的维度时，并不考虑channel维</strong>。<br>二维卷积核的大小实际是<code>(channel, k_h, k_w)</code>, 三维卷积核的大小是<code>(channel, k_d, k_h, k_w)</code>, k_d就是多出来的第三维，根据具体应用，在视频中就是时间维，在CT图像中就是层数维。</p><ul><li>在二维卷积中，卷积核滑动维度是2维的；</li><li>在三维卷积中，卷积核滑动维度是3维的。</li></ul><h4 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h4><p>例如，输入图像大小为<code>(3, height, weight)</code>，其中channel为3, 卷积核尺寸为<code>(3, k_h, k_w)</code>, channel与输入图像一致. 进行卷积操作时，卷积核只是在<code>(height, weight)</code>这两维上进行滑窗操作。</p><h4 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h4><p>与2D卷积不同之处在于，输入图像多了一个 <code>depth</code> 维度，故输入大小为<code>(3, depth, height, width)</code>，卷积核也多了一个k_d维度，因此卷积核在输入3D图像的空间维度（height和width维）和depth维度上均进行滑窗操作.</p><h2 id="2-2-池化"><a href="#2-2-池化" class="headerlink" title="2.2 池化"></a>2.2 池化</h2><p>池化层就是下采用，降低数据的维度，提高计算速度，同时提高提取特征的鲁棒性。池化的运算过程：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/0_JjtDg7FAhjQOrld-.gif" srcset="/img/loading.gif" alt=""></p><h3 id="最大池化"><a href="#最大池化" class="headerlink" title="最大池化"></a>最大池化</h3><p>提取过滤器范围内的最大值。</p><h3 id="平均池化"><a href="#平均池化" class="headerlink" title="平均池化"></a>平均池化</h3><p>过滤器范围内的数据取平均值，平均池化使用较少。</p><h1 id="3-反向传播"><a href="#3-反向传播" class="headerlink" title="3. 反向传播"></a>3. 反向传播</h1><h2 id="3-1-卷积层的反向传播"><a href="#3-1-卷积层的反向传播" class="headerlink" title="3.1 卷积层的反向传播"></a>3.1 卷积层的反向传播</h2><p>卷积层的反向传播比全连接神经网络的反向传播要复杂许多，现举例说明。假设第 $l$ 层的输入数据为X：</p><script type="math/tex; mode=display">X = \begin{bmatrix}x_{11}&x_{12}&x_{13} \\x_{21}&x_{22}&x_{23} \\x_{31}&x_{32}&x_{33}\end{bmatrix}</script><p>卷积核F为：</p><script type="math/tex; mode=display">F = \begin{bmatrix}f_{11}&f_{12} \\f_{21}&f_{22} \end{bmatrix}</script><p>假设步长为1，padding为0，那么经过卷积运算后的结果为 A：</p><script type="math/tex; mode=display">A = \begin{bmatrix}a_{11}&a_{12}\\a_{21}&a_{22}\end{bmatrix}</script><p>则有：</p><script type="math/tex; mode=display">\begin{array}{}\frac{\partial A_{11}}{\partial F_{11}} = x_{11}, \frac{\partial A_{11}}{\partial F_{12}} = x_{12} ,\ldots\\ \\\frac{\partial A_{12}}{\partial F_{11}} = x_{12}, \frac{\partial A_{12}}{\partial F_{12}} = x_{13} ,\ldots \\\end{array}</script><p>使用链式规则有：</p><script type="math/tex; mode=display">\frac{\partial J}{\partial F_i} = \sum_{k = 1}^{m}\frac{\partial J}{\partial A_k} \times \frac{\partial A_k}{\partial F_i}</script><p>分别对F求梯度，则有如下四个式子成立：</p><script type="math/tex; mode=display">\begin{array}{}\frac{\partial J}{\partial F_{11}} = \frac{\partial J}{\partial A_{11}} \times \frac{\partial A_{11}}{\partial F_{11}} + \frac{\partial J}{\partial A_{12}} \times \frac{\partial A_{12}}{\partial F_{11}} + \frac{\partial J}{\partial A_{21}} \times \frac{\partial A_{21}}{\partial F_{11}} + \frac{\partial J}{\partial A_{22}} \times \frac{\partial A_{22}}{\partial F_{11}}\\= \frac{\partial J}{\partial A_{11}} \times x_{11} + \frac{\partial J}{\partial A_{12}} \times  x_{12} + \frac{\partial J}{\partial A_{21}} \times x_{21} + \frac{\partial J}{\partial A_{22}} \times  x_{22}\end{array} \tag{1}</script><script type="math/tex; mode=display">\begin{array}{}\frac{\partial J}{\partial F_{12}} = \frac{\partial J}{\partial A_{11}} \times \frac{\partial A_{11}}{\partial F_{12}} + \frac{\partial J}{\partial A_{12}} \times \frac{\partial A_{12}}{\partial F_{12}} + \frac{\partial J}{\partial A_{21}} \times \frac{\partial A_{21}}{\partial F_{12}} + \frac{\partial J}{\partial A_{22}} \times \frac{\partial A_{22}}{\partial F_{12}} \\= \frac{\partial J}{\partial A_{11}} \times x_{12} + \frac{\partial J}{\partial A_{12}} \times  x_{13} + \frac{\partial J}{\partial A_{21}} \times x_{22} + \frac{\partial J}{\partial A_{22}} \times  x_{23}\end{array} \tag{2}</script><script type="math/tex; mode=display">\begin{array}{}\frac{\partial J}{\partial F_{21}} = \frac{\partial J}{\partial A_{11}} \times \frac{\partial A_{11}}{\partial F_{21}} + \frac{\partial J}{\partial A_{12}} \times \frac{\partial A_{12}}{\partial F_{21}} + \frac{\partial J}{\partial A_{21}} \times \frac{\partial A_{21}}{\partial F_{21}} + \frac{\partial J}{\partial A_{22}} \times \frac{\partial A_{22}}{\partial F_{21}} \\= \frac{\partial J}{\partial A_{11}} \times x_{21} + \frac{\partial J}{\partial A_{12}} \times  x_{22} + \frac{\partial J}{\partial A_{21}} \times x_{31} + \frac{\partial J}{\partial A_{22}} \times  x_{32}\end{array} \tag{3}</script><script type="math/tex; mode=display">\begin{array}{}\frac{\partial J}{\partial F_{22}} = \frac{\partial J}{\partial A_{11}} \times \frac{\partial A_{11}}{\partial F_{22}} + \frac{\partial J}{\partial A_{12}} \times \frac{\partial A_{12}}{\partial F_{22}} + \frac{\partial J}{\partial A_{21}} \times \frac{\partial A_{21}}{\partial F_{22}} + \frac{\partial J}{\partial A_{22}} \times \frac{\partial A_{22}}{\partial F_{22}} \\= \frac{\partial J}{\partial A_{11}} \times x_{22} + \frac{\partial J}{\partial A_{12}} \times  x_{23} + \frac{\partial J}{\partial A_{21}} \times x_{32} + \frac{\partial J}{\partial A_{22}} \times  x_{33}\end{array} \tag{4}</script><p>不难发现，对F求梯度，实际上就是X与$\frac{\partial J}{\partial A}$进行卷积运算：</p><script type="math/tex; mode=display">\frac{\partial J}{\partial F} = X \ast \frac{\partial J}{\partial A}</script><h2 id="3-2-池化层的反向传播"><a href="#3-2-池化层的反向传播" class="headerlink" title="3.2 池化层的反向传播"></a>3.2 池化层的反向传播</h2><h3 id="最大池化-1"><a href="#最大池化-1" class="headerlink" title="最大池化"></a>最大池化</h3><p>假设池化层的输入X:</p><script type="math/tex; mode=display">X = \begin{bmatrix}4&3&0&1\\1&1&3&2\\5&0&1&1\\6&4&4&7\end{bmatrix}</script><p>经过<code>2 x 2</code>的最大池化层之后，结果为A: </p><script type="math/tex; mode=display">A = \begin{bmatrix}4&3\\6&7\end{bmatrix}</script><p>则$\frac{\partial A}{\partial X}$：</p><script type="math/tex; mode=display">\frac{\partial A}{\partial X} = \begin{bmatrix}1&0&0&0\\0&0&1&0\\0&0&0&0\\1&0&0&1\end{bmatrix}</script><p>因为使用的是最大池化，则A对X求偏导时，最大值处为1，其他为0，即在进行最大池化时需要保留最大值处的位置，才能进行反向传播。</p><h3 id="平均池化-1"><a href="#平均池化-1" class="headerlink" title="平均池化"></a>平均池化</h3><p>平均池化的反向传播更加简单。如果对上述的X进行<code>2 x 2</code>的平均池化，则$\frac{\partial A}{\partial X}$为：</p><script type="math/tex; mode=display">\frac{\partial A}{\partial X} = \begin{bmatrix}\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\\\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\\\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\\\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\end{bmatrix}</script>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络</title>
    <link href="/2020/07/07/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2020/07/07/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="note note-info">最后更新于2020-07-17：添加端到端概念</p><p class="note note-info">2020-07-16：添加梯度消失问题</p><h1 id="1-神经网络基础"><a href="#1-神经网络基础" class="headerlink" title="1. 神经网络基础"></a>1. 神经网络基础</h1><p>神经网络被建模成神经元的集合，神经元之间以无环图的形式进行连接。对于普通神经网络，最普通的层的类型是全连接层。全连接层中的神经元与其前后两层的神经元是全连接的。神经网络包括输入层、隐藏层、输出层，一般说N层神经网络的时候，忽略了输入层，比如下图是一个2层神经网络。<strong>输入层神经元节点的数量就是数据feature的数量。</strong></p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200707210313.png" srcset="/img/loading.gif" alt=""></p><p>一个神经元节点首先计算线性函数（$\omega x + b$），然后计算激活函数，然后将计算的结果传递到下一层。</p><p>训练神经网络的过程：</p><p>1） 参数的随机初始化；</p><p>2） 前向传播；</p><p>3） 计算代价；</p><p>4）反向传播计算所有偏导数；</p><p>5） 利用数值检验方法检验这些偏导数；</p><p>6）使用优化来最小化代价函数。</p><p>用上图的2层神经网络举例说明<strong>前向传播</strong>的过程，输入是一个<code>3 x 1</code>的向量，第一个隐藏层的权重W1是<code>4 x 3</code>的向量,偏置b1是<code>4 x 1</code>的向量，在隐藏层中的计算为：$f(W_1 x + b_1)$，其中输出数据大小为<code>4 x 1</code>；输出层的权重W2是<code>2 x 4</code>, 偏置为<code>2 x 1</code>, 输出层通常没有激活函数，则计算为：$W_2 x + b_2$, 最后输出数据为<code>2 x 1</code>的向量。</p><h2 id="1-1-数据预处理"><a href="#1-1-数据预处理" class="headerlink" title="1.1 数据预处理"></a>1.1 数据预处理</h2><p>假设输入数据为X，大小为<code>n x m</code>，其中n指的特征的数量，m指的是样本的数量。</p><h3 id="1-1-1-均值减法（Mean-subtraction）"><a href="#1-1-1-均值减法（Mean-subtraction）" class="headerlink" title="1.1.1 均值减法（Mean subtraction）"></a>1.1.1 均值减法（Mean subtraction）</h3><p>对数据每个独立特征减去平均值（<strong>注意：平均值指的是每个样本对应特征的平均值，而不是对单个样本的数据求平均值</strong>）, 其实就是在每个维度上将数据的中心移到原点，也就是做0中心化（zero-centered）处理。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> npX -= np.mean(X, axis=<span class="hljs-number">1</span>)</code></pre></div><h3 id="1-1-2-归一化-Normalization"><a href="#1-1-2-归一化-Normalization" class="headerlink" title="1.1.2 归一化 (Normalization)"></a>1.1.2 归一化 (Normalization)</h3><p>有两种方法：</p><ul><li>先对数据做0中心化，然后每个维度都除以其标准差。</li></ul><div class="hljs"><pre><code class="hljs undefined">X <span class="hljs-string">/=</span> np.std<span class="hljs-params">(X, <span class="hljs-attr">axis</span>=1)</span></code></pre></div><ul><li>对每个维度都做归一化。</li></ul><p><strong>常见错误</strong>：<strong>数据预处理只能在训练集数据上进行计算</strong>。比如，先从训练集中求图片平均值，然后训练集、验证集、测试集中的图像再减去这个平均值。</p><h2 id="1-2-随机初始化"><a href="#1-2-随机初始化" class="headerlink" title="1.2 随机初始化"></a>1.2 随机初始化</h2><h3 id="1-2-1-权重初始化"><a href="#1-2-1-权重初始化" class="headerlink" title="1.2.1 权重初始化"></a>1.2.1 权重初始化</h3><ul><li>小随机数初始化</li></ul><div class="hljs"><pre><code class="hljs python">W = np.random.randn(D, H) * <span class="hljs-number">0.01</span></code></pre></div><ul><li>使用<code>1/sqrt(m)</code>校准方差：这样可以将神经元输出归一化到1：<code>W = np.random.randn(m) / sqrt(m)</code>， m为样本数量。针对ReLU神经元的特殊初始化：<code>w = np.random.randn(m) * sqrt(2.0 / m)</code></li></ul><h3 id="1-2-2-偏置初始化"><a href="#1-2-2-偏置初始化" class="headerlink" title="1.2.2 偏置初始化"></a>1.2.2 偏置初始化</h3><p>通常将偏置初始化为0，这是因为权重的随机初始化已经打破了对称性。</p><h2 id="1-3-学习之前的合理性检查"><a href="#1-3-学习之前的合理性检查" class="headerlink" title="1.3 学习之前的合理性检查"></a>1.3 学习之前的合理性检查</h2><ul><li>寻找特定情况下的正确损失值，比如使用一个样本，正则化强度设置为0，检查损失值是否符合预期。</li><li>提高正则化强度时导致损失值变大；</li><li>对小数据集过拟合。使用一个小数据集，正则化强度设置为0，确保训练后能够到达0的损失值。</li></ul><h2 id="1-4-检查整个学习过程"><a href="#1-4-检查整个学习过程" class="headerlink" title="1.4 检查整个学习过程"></a>1.4 检查整个学习过程</h2><ul><li>跟踪损失值；</li><li>跟踪训练集和验证集准确度的变化过程：判断是否过拟合。</li><li>第一层可视化：下图是将神经网络第一层的权重可视化的例子。左图中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。右图的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好。</li></ul><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200708160346.png" srcset="/img/loading.gif" alt=""></p><h2 id="1-5-epoch、iteration、batch-size"><a href="#1-5-epoch、iteration、batch-size" class="headerlink" title="1.5 epoch、iteration、batch_size"></a>1.5 epoch、iteration、batch_size</h2><p>神经网络中epoch与iteration是不相等的</p><ul><li>batch_size：批大小，一次训练选取的样本大小。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batch_size个样本训练；</li><li>iteration：中文翻译为迭代，1个iteration等于使用batch_size个样本训练一次；一个迭代 = 一个正向传播+一个反向传播；</li><li>epoch：迭代次数，1个epoch等于使用训练集中的全部样本训练一次；一个epoch = 所有训练样本的一个正向传递和一个反向传递。</li></ul><h2 id="1-6-感受野（receptive-field）"><a href="#1-6-感受野（receptive-field）" class="headerlink" title="1.6 感受野（receptive field）"></a>1.6 感受野（receptive field）</h2><p>感受野是用来表示网络内部的不同位置的神经元对原始图像的感受范围的大小。</p><p>如下是一个感受野计算的例子：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200714204504.png" srcset="/img/loading.gif" alt=""></p><p>Conv1层使用一个<code>3 x 3</code>的卷积核，Conv2层使用一个<code>2 x 2</code>的卷积核。可以看出，Conv1中的一个单元能够看到原始图像的范围是<code>3 x 3</code>，Conv2中一个单元能看到<code>5 x 5</code>的范围，所以Conv1的感受野是<code>3 x 3</code>, Conv2的感受野是<code>5 x 5</code>。</p><p>计算公式是：</p><script type="math/tex; mode=display">r_{n} = r_{n - 1} + (k_n - 1)\prod_{i = 1}^{n - 1}s_i</script><p>其中 $r_n$ 表示第 n 层的感受野，$k_n$ 表示第 n 层的卷积核大小， $s_i$ 表示第 i 层卷积步长。 </p><h2 id="1-7-梯度消失"><a href="#1-7-梯度消失" class="headerlink" title="1.7 梯度消失"></a>1.7 梯度消失</h2><p>对于<code>sigmoid</code>和<code>tanh</code>激活函数而言，其梯度小于1，是一个比较小的数，在反向传播的过程中，不断衰减，如果网络层次比较深，梯度传递到低层网络时非常小，也就产生了梯度消失现象，导致参数更新缓慢，学习变慢。</p><p><strong>解决办法</strong></p><ul><li>使用ReLU、LeakReLU激活函数；</li><li>Batch Normalization</li><li>残差网络</li></ul><h2 id="1-8-端到端"><a href="#1-8-端到端" class="headerlink" title="1.8 端到端"></a>1.8 端到端</h2><p>端到端就是指输入是原始数据，输出就是最后结果。</p><p>比如对于一个目标检测模型，输入原始图像，最后就能直接输出目标的位置和目标的类别，这就是<strong>端到端</strong>的。但对于R-CNN这个模型，也是进行目标检测，需要先获取可能包含目标的候选框，然后将候选框输入到CNN模型中判断是否有目标以及目标的类别，这就是<strong>非端到端</strong>的。</p><h1 id="2-激活函数（activation-function）"><a href="#2-激活函数（activation-function）" class="headerlink" title="2. 激活函数（activation function）"></a>2. 激活函数（activation function）</h1><p>在神经元节点中线性计算后，然后使用激活函数，激活函数需要是一个非线性函数。使用激活函数是为了将神经元节点输出非线性化，如果只是使用线性函数，那么最后的输出将是几个线性函数的线性组合，那么设计多层的神经网络就变得没有任何意义。</p><h2 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h2><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>sigmoid函数将输入压缩到 0 到 1 范围，主要用于二分类，比如logistics回归，如今sigmoid函数很少使用了。</p><script type="math/tex; mode=display">f(x) = \frac {1}{1 + e^{-x}}</script><p>sigmoid函数的导数为：</p><script type="math/tex; mode=display">\begin{array}{l}f^\prime(x) = \frac{e^{-x}}{(1 + e^{-x})^2} \\= f(x) - (f(x))^2\end{array}</script><p>sigmoid函数主要有以下两个缺点：</p><ul><li>输出不是0中心的。这一情况将影响梯度下降的运作。</li><li>sigmoid函数饱和使梯度消失。当激活函数的输入非常大或者非常小的时候，梯度几乎为0，那么最后相乘的结果也会接近0.</li></ul><h3 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h3><p>tanh函数将输入压缩至-1到1的范围，tanh函数是一个简单放大的sigmoid函数：$tanh(x) = 2\sigma(2x) - 1$</p><script type="math/tex; mode=display">f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}</script><p>tanh函数的导数：</p><script type="math/tex; mode=display">f(x)^{\prime}=1-(\tanh (x))^{2}</script><p>解决了sigmoid函数的0中心化问题，但梯度消失问题仍然存在。</p><h3 id="ReLU函数-Rectified-Linear-Unit"><a href="#ReLU函数-Rectified-Linear-Unit" class="headerlink" title="ReLU函数(Rectified Linear Unit)"></a>ReLU函数(Rectified Linear Unit)</h3><p>ReLU函数（校正线性单元），是目前最常用的激活函数：</p><script type="math/tex; mode=display">f(x) = \max(0, x)</script><p>优点：</p><ul><li>对于随机梯度下降的收敛有巨大的加速作用。</li><li>sigmoid和tanh含有指数运算等耗时操作，ReLU 运算简单，计算速度快。</li><li>在正区间解决梯度消失问题。</li></ul><p>缺点：</p><ul><li>输出不是0中心化；</li><li>某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。例如，learning_rate设置得太高，容易出现这种情况。合理设置learning_rate, 这种情况发生概率会降低。</li></ul><h3 id="Leaky-ReLU函数"><a href="#Leaky-ReLU函数" class="headerlink" title="Leaky ReLU函数"></a>Leaky ReLU函数</h3><p>为了解决ReLU死亡问题，ReLU函数的改进版本。</p><script type="math/tex; mode=display">f(x) = max(\alpha x, x)</script><p>其中$\alpha$ 是一个非常小的常量。</p><h1 id="3-优化"><a href="#3-优化" class="headerlink" title="3. 优化"></a>3. 优化</h1><h2 id="3-1-梯度下降法"><a href="#3-1-梯度下降法" class="headerlink" title="3.1 梯度下降法"></a>3.1 梯度下降法</h2><h3 id="批量梯度下降法（Batch-Gradient-Descent）"><a href="#批量梯度下降法（Batch-Gradient-Descent）" class="headerlink" title="批量梯度下降法（Batch Gradient Descent）"></a>批量梯度下降法（Batch Gradient Descent）</h3><p>更新参数时使用所有的样本进行更新，每迭代一步都需要用到训练集中的所有数据。</p><ul><li>缺点：样本数量很多时，训练过程很慢。</li></ul><h3 id="随机梯度下降法（Stochastic-Gradient-Descent）"><a href="#随机梯度下降法（Stochastic-Gradient-Descent）" class="headerlink" title="随机梯度下降法（Stochastic Gradient Descent）"></a>随机梯度下降法（Stochastic Gradient Descent）</h3><p>随机梯度下降法，每次训练一个样本，计算一个样本的梯度，然后进行参数更新。 </p><ul><li>优点：训练速度快；</li><li>缺点：准确度下降，并不是全局最优。</li></ul><h3 id="小批量梯度下降法（Mini-batch-Gradient-Descent）"><a href="#小批量梯度下降法（Mini-batch-Gradient-Descent）" class="headerlink" title="小批量梯度下降法（Mini-batch Gradient Descent）"></a>小批量梯度下降法（Mini-batch Gradient Descent）</h3><p>每次更新参数时使用小批量的样本。算法训练过程比较快，准确度也比较高。梯度下降会有一些震荡，但整体是下降的，因为mini-batch会出现一些噪音。</p><h2 id="3-2-梯度下降优化算法"><a href="#3-2-梯度下降优化算法" class="headerlink" title="3.2 梯度下降优化算法"></a>3.2 梯度下降优化算法</h2><p>梯度下降法的参数更新有多种方法。</p><h3 id="1-普通方法"><a href="#1-普通方法" class="headerlink" title="1. 普通方法"></a>1. 普通方法</h3><p>沿着负梯度方向改变参数。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 普通更新</span>W = W - learning_rate * dW</code></pre></div><h3 id="2-动量更新（Momentum）"><a href="#2-动量更新（Momentum）" class="headerlink" title="2. 动量更新（Momentum）"></a>2. 动量更新（Momentum）</h3><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># 动量更新</span>v = mu * v - learning_rate * dWW += v</code></pre></div><p>其中v初始化为0，mu被看作动量，一般设为0.9，通产还可以是[0.5, 0.9, 0.95, 0.99]中的一个。</p><ul><li><p>在梯度方向改变时（比如v为负，dW为负），momentum能够降低参数更新速度，从而减少震荡；</p></li><li><p>在梯度方向相同时（比如v为负，dW为正），momentum可以加速参数更新， 从而加速收敛。</p></li></ul><p>总而言之，momentum能够加速SGD收敛，抑制震荡。</p><h3 id="3-Nesterov动量"><a href="#3-Nesterov动量" class="headerlink" title="3. Nesterov动量"></a>3. Nesterov动量</h3><div class="hljs"><pre><code class="hljs python">v_pre = v <span class="hljs-comment"># 存储备份</span>v = mu * v - learning_rate * dWW += -mu * v_pre + (<span class="hljs-number">1</span> + mu) * v</code></pre></div><h3 id="4-Adagrad"><a href="#4-Adagrad" class="headerlink" title="4. Adagrad"></a>4. Adagrad</h3><p>Adagrad是一个适应性学习率算法，自适用的为不同参数分配不同的学习率。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># cache存储梯度的平方和</span>cache += dW**<span class="hljs-number">2</span><span class="hljs-comment"># eps是一个很小的常量，防止出现0, 一般1e-4到1e-8之间</span>W += -learning_rate * dW / (np.sqrt(cache) + eps)</code></pre></div><p>随着迭代的增加，cache增大，学习率变小。因为随着训练的进行，越来越接近最优解，学习率相应变小。</p><h3 id="5-RMSprop"><a href="#5-RMSprop" class="headerlink" title="5. RMSprop"></a>5. RMSprop</h3><p>适应性学习率算法，与Adagrad不同的是，不会让学习率单调变小。</p><div class="hljs"><pre><code class="hljs python">cache = decay_rate * cache + (<span class="hljs-number">1</span> - decay_rate) * dx ** <span class="hljs-number">2</span>x += -learning_rate * dx / (np.sqrt(cache) + eps)</code></pre></div><p>decay_rate常用的值[0.9, 0.99, 0.999]</p><h3 id="6-Adam"><a href="#6-Adam" class="headerlink" title="6. Adam"></a>6. Adam</h3><p>看起来像RMSprop的动量版。</p><div class="hljs"><pre><code class="hljs python">m = beta1*m + (<span class="hljs-number">1</span>‐beta1)*dxv = beta2*v + (<span class="hljs-number">1</span>‐beta2)*(dx**<span class="hljs-number">2</span>)x += ‐ learning_rate * m / (np.sqrt(v) + eps)</code></pre></div><p>推荐参数值：eps=1e-8, beta1=0.9, beta2=0.999。</p><h2 id="3-3-学习率退火"><a href="#3-3-学习率退火" class="headerlink" title="3.3 学习率退火"></a>3.3 学习率退火</h2><p>学习率可能过大，逐步衰减学习率。</p><ul><li>随步数衰减：每进行几个周期就降低学习率。典型的值是每过5个周期就将学习率减少一半，或者每20个周期减少到之前的0.1；</li><li>指数衰减：$\alpha = \alpha_0 e^{-kt}$, 其中t 为迭代次数，k是超参数；</li><li>1/t 衰减: $ \alpha = \frac{\alpha_0}{1+ kt}$.</li></ul>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聚类与降维</title>
    <link href="/2020/07/05/%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/"/>
    <url>/2020/07/05/%E8%81%9A%E7%B1%BB%E4%B8%8E%E9%99%8D%E7%BB%B4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="聚类任务"><a href="#聚类任务" class="headerlink" title="聚类任务"></a>聚类任务</h1><p>聚类算法是一个典型的无监督学习，训练的数据没有任何标签。聚类算法将数据集中的样本划分为若干个通常是不相交的子集，每个子集成为一个“簇”（cluster）。</p><h2 id="K均值算法（K-Means-Algorithm）"><a href="#K均值算法（K-Means-Algorithm）" class="headerlink" title="K均值算法（K-Means Algorithm）"></a>K均值算法（K-Means Algorithm）</h2><p>K均值算法是最普及的聚类算法，算法接受一个未标记的数据集，然后根据数据聚类成不同的组。</p><p>K均值是一个迭代算法，假设需要将数据聚类成K个簇，其方法为：</p><ul><li><ol><li>首先随机选择K个点，称为聚类中心；</li></ol></li><li><ol><li>对于数据集中的每一个数据，分别计算其到中心点的距离，并将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类；</li></ol></li><li><ol><li>计算每一个组的平均值，并将中心点移动到平均值的位置；</li></ol></li><li><ol><li>重复2-3直至中心点不再变化。</li></ol></li></ul><p>给定样本集$D=\{x_1, x_2, \ldots,x_n\}$，K均值算法所得簇划分$C=\{C_1, \ldots, C_k\}$, 最小化平方误差为：</p><script type="math/tex; mode=display">E = \sum_{i=1}^k\sum_{x \in C_i}\|x-u_i\|^2</script><p>其中$u_i$为簇$C_i$的中心点。上式其实就是求样本数据中的每一点到其中心点的距离和。</p><h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>随机初始化就是用训练集中随机选择K个数据，作为K个聚类中心。</p><p>问题在于，最后的结果可能停留在一个局部最小值处。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200705160708.png" srcset="/img/loading.gif" alt=""></p><p>为了解决这一问题，需要多次运行K均值算法，每一次都要重新进行随机初始化，最后选择代价函数最小的结果。</p><h1 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h1><p>降维也是一种无监督学习问题，降维的动机有：数据压缩、数据可视化。</p><h2 id="主成分分析（Principal-Component-Analysis）"><a href="#主成分分析（Principal-Component-Analysis）" class="headerlink" title="主成分分析（Principal Component Analysis）"></a>主成分分析（Principal Component Analysis）</h2><p>主成分分析法是最常用的一种降维方法。在PCA中，要做的是找到一个方向向量，当把所有的数据都投射到该向量上，希望平均均方误差尽可能小。投射误差是指数据点到方向向量的垂直距离。</p><p>主成分分析与线性回归对比：</p><ul><li>主成分分析最小化的是投射误差；</li><li>线性回归最小化的是预测误差。</li></ul><p>将<code>n</code>维数据降到<code>k</code>维数据，样本集$D = \{x^{(1)},\ldots, x^{(m)}\}$，处理过程如下：</p><ol><li><p>对所有样本进行中心化：$x^{(i)} \leftarrow x^{(i)} - \frac {1}{m}\sum_{i = 1}^{m}x^{(i)}$;</p></li><li><p>计算协方差：$\Sigma = \frac{1}{m} \sum_{i = 1}^{m}x^{(i)}(x^{(i)})^T$, 所得结果为<code>n x n</code>大小；</p></li><li><p>计算协方差的特征向量, 记为$U = \begin{array}{1}[u^1, u^2, \ldots, u^n]\end{array}$；</p></li><li><p>选取前k个向量，获得一个<code>n x k</code>矩阵，记为$U_{reduce}$，然后获得降维的数据：$z^{(i)} = U_{reduce}^T \ast x^{(i)}$.</p></li></ol><h3 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h3><p>协方差在某种意义上给出了两个变量线性相关性的强度以及这些变量的出度：</p><script type="math/tex; mode=display">Cov(f(x), g(y)) = E[(f(x) - E[f(x)])\times (g(y) - E[g(y)]) ]</script><p>其中<code>E</code>表示求变量的均值。均方差的绝对值很大则意味着变量值变化很大，并且它们同时距离各自的均值很远。协方差和相关性是有联系的，如果两个变量相互独立，则协方差为0，但协方差为0，不表示一定相互独立。</p><p>协方差的对角元是方差：</p><script type="math/tex; mode=display">Cov(x_i, x_i) = Var(x_i)</script><p>在上述主成分分析中，求协方差是<strong>求不同特征之间的协方差, 而不是求不同样本之间的协方差</strong>。比如：$x^{(1)} = [x_{11},x_{21}]$, $x^{(2)} = [x_{12}, x_{22}]$, 即</p><script type="math/tex; mode=display">D = \begin{bmatrix}x_{11}&x_{12}\\x_{21}&x_{22}\end{bmatrix}</script><p>那么第一维的特征$x_1 = [x_{11}, x_{12}]$, 假设其均值为$\sigma_1$；第二维的特征$x_2 = [x_{21}, x_{22}]$，假设其均值为$\sigma_2$.那么</p><script type="math/tex; mode=display">Cov(x_1, x_2) = \frac{(x_{11} - \sigma_1)(x_{21} - \sigma_2) + (x_{12} - \sigma_1)(x_{22} - \sigma2)}{2}</script>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>无监督学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>支持向量机</title>
    <link href="/2020/07/04/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <url>/2020/07/04/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>支持向量机（Support Vector Machine）是类按监督学习方式对数据进行二分类的分类器，对多分类任务要进行专门的推广，其决策边界是对学习样本求解的最大间距超平面。SVM可以通过使用核方法进行非线性分类。</p><h1 id="最大间隔分类器"><a href="#最大间隔分类器" class="headerlink" title="最大间隔分类器"></a>最大间隔分类器</h1><p>对一个数据点进行分类，当超平面离数据点的间隔越大，分类的确信度越大。<br>在样本空间中，划分超平面可通过如下线性方程来描述：</p><script type="math/tex; mode=display">\omega ^ {T}x + b = 0 \tag{1}</script><p>样本空间中任意点x到超平面的距离为：</p><script type="math/tex; mode=display">r = \frac {|\omega^{T}x + b|}{\| \omega \|} \tag{2}</script><p>其中$| \omega |$ 为：</p><script type="math/tex; mode=display">\| \omega \| = \sqrt[2]{\omega_1^2 + \omega_2^2+\ldots+\omega_n^2} \tag{3}</script><p>使用+1和-1来标记样本的正负类。</p><ul><li>对于$y_i$ = +1，有 $\omega^Tx+b$ &gt; 0；</li><li>对于$y_i$ = −1，有$\omega^Tx+b$ &lt; 0.</li></ul><p>令：</p><script type="math/tex; mode=display">\left\{\begin{array}{ll}\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \geqslant+1, & y_{i}=+1 \\\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \leqslant-1, & y_{i}=-1\end{array}\right. \tag{4}</script><p>下图虚线上的点使上式等号成立，它们被称作“支持向量”。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200704221839.png" srcset="/img/loading.gif" alt=""></p><p>找到最大间隔的划分超平面，也就是下面的优化问题：</p><script type="math/tex; mode=display">\max \frac {2}{\|\omega\|},s.t. y_i(\omega^{T}x_i+b) \geq 1 \tag{5}</script><p>可以转化为如下问题：</p><script type="math/tex; mode=display">\min \frac {1}{2}\|\omega\|^2,s.t. y_i(\omega^{T}x_i+b) \geq 1 \tag{6}</script><h1 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h1><p>硬间隔是指所有样本都必须划分正确；软间隔则是允许某些样本不满足约束条件。优化目标改写为：</p><script type="math/tex; mode=display">\min_{\omega, b} \frac{1}{2}\|\omega\|^2 + C\sum_{i = 1}^{m}\ell_{0/1}(y_i(\omega^Tx_i + b) - 1) \tag{7}</script><p>其中C &gt; 0是一个常数，$\ell_{0/1}$ 是一个“0/1 损失函数”：</p><script type="math/tex; mode=display">\ell_{0/1} = \left\{\begin{array}{ll}1,if\ z < 0 \\0, otherwise\end{array}\right. \tag{8}</script><p>但该函数非凸、不连续，数学性质不好。常用以下三种替代损失函数：</p><ul><li>hinge损失：$\max(0, 1-z)$；</li><li>指数损失：$e^{-z}$;</li><li>对率损失：$\log(1 + e^{-z})$。</li></ul><p>若使用hinge损失，则式（7）变成：</p><script type="math/tex; mode=display">\min_{\omega, b} \frac{1}{2}\|\omega\|^2 + C\sum_{i = 1}^{m}\max(0, 1-y_i(\omega^Tx_i + b)) \tag{9}</script><p>但C不是很大的时候，它可以忽略一些异常点的影响，得到更好的决策边界。</p><ul><li>C较大时，可能会导致过拟合；</li><li>C较小时，可能会导致欠拟合。</li></ul><h1 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h1><p>如果原始样本空间内并不存在一个能正确划分两类样本的超平面，可以将原始样本空间映射到一个更高维的特征空间，使得样本在这个空间线性可分。使用核函数解决非线性分类问题，可以利用核函数计算新的特征，从而映射到更高维的特征空间。常用的核函数用：</p><p>线性核 ：$k(x_i, x_j) = x_i^Tx_j$ ；</p><p>高斯核 ：$k(x_i, x_j)=exp(-\frac{|x_i-x_j|^2}{2\sigma^2})$，其中$\sigma &gt;0$为高斯核的带宽；</p><p>拉普拉斯核：$k(x_i, x_j) = exp(-\frac{|x_i - x_j|}{\sigma})$，其中$\sigma &gt; 0$.</p><h2 id="使用范例"><a href="#使用范例" class="headerlink" title="使用范例"></a>使用范例</h2><p>从x的各个特征中预先选定三个landmarks $l^{(1)},l^{(2)},l^{(3)}$，则有：</p><script type="math/tex; mode=display">\begin{array}{l}f_1^{(1)} = k(x^{(1)}, l^{(1)})\\f_2^{(1)} = k(x^{(1)}, l^{(2)})\\ f_3^{(1)} = k(x^{(1)}, l^{(3)})\end{array} \tag{10}</script><p>其中$f_1^{(1)},f_2^{(1)},f_3^{(1)}$是利用核函数计算出来的关于$x^{(1)}$的新特征。以此类推可以计算$f^{(2)}, \ldots, f^{(n)}$.则决策边界可以表示为：</p><script type="math/tex; mode=display">\omega_0 + \omega_1 f_1 + \omega_2 f_2 + \omega_3 f_3 = 0 \tag{11}</script>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>监督学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux用户</title>
    <link href="/2020/07/04/Linux%E7%94%A8%E6%88%B7/"/>
    <url>/2020/07/04/Linux%E7%94%A8%E6%88%B7/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h1><h2 id="passwd文件"><a href="#passwd文件" class="headerlink" title="passwd文件"></a>passwd文件</h2><p>passwd文件位于<code>/etc/passwd</code>, 各字段含义如下：</p><ul><li>1、账户名称：用来对应UID</li><li>2、密码：早起Unix系统的密码就是防止这个字段上，但是英文这个档案的特性是所有程序都能读取，容易造成密码数据被窃取应此后来就将这个字段的密码数据放到了/etc/shadow中了，所以这里使用【X】，</li><li>3、UID：用户ID，当UID为0时，用户拥有root权限，但该用户不一定是root；1-499保留给系统使用的ID；500~ ，一般使用者。</li><li>4、GID：这个与/etc/group有关！其实/etc/group的观念与/etc/passwd差不多，应用来规范组名</li><li>5、用户信息说明栏：</li><li>6、家目录：root的家目录在/root，所以当root登陆的之后，就会立刻跑到/root目录里头，如果坏、这个账号需要使用特别大的空间，就可以对这个字段进行修改，已移动到其他同硬盘。默认的用户家目录在/home/youIdname, home目录即<code>~</code>。</li><li>7、Shell:定义用户登陆系统使用什么shell，这里需要注意，有一个shell可以用来特带成让账户无法取得shell环境的登陆动作！那就是/sbin/nologin这个特殊东西，也可以用来制作pop邮件账号者的数据。<div class="hljs"><pre><code class="hljs undefined"><span class="hljs-symbol">:/etc</span><span class="hljs-variable">$ </span>cat /etc/passwd<span class="hljs-symbol">root:</span><span class="hljs-symbol">x:</span><span class="hljs-number">0</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span><span class="hljs-symbol">:root</span><span class="hljs-symbol">:/root</span><span class="hljs-symbol">:/bin/bash</span><span class="hljs-symbol">xinger:</span><span class="hljs-symbol">x:</span><span class="hljs-number">1000</span><span class="hljs-symbol">:</span><span class="hljs-number">1000</span><span class="hljs-symbol">:</span>,,,<span class="hljs-symbol">:/home/xinger</span><span class="hljs-symbol">:/bin/bash</span><span class="hljs-symbol">mongodb:</span><span class="hljs-symbol">x:</span><span class="hljs-number">111</span><span class="hljs-symbol">:</span><span class="hljs-number">116</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:/var/lib/mongodb</span><span class="hljs-symbol">:/usr/sbin/nologin</span><span class="hljs-symbol">redis:</span><span class="hljs-symbol">x:</span><span class="hljs-number">112</span><span class="hljs-symbol">:</span><span class="hljs-number">117</span><span class="hljs-symbol">:</span><span class="hljs-symbol">:/var/lib/redis</span><span class="hljs-symbol">:/usr/sbin/nologin</span></code></pre></div></li></ul><h3 id="禁止用户shell登录权限"><a href="#禁止用户shell登录权限" class="headerlink" title="禁止用户shell登录权限"></a>禁止用户shell登录权限</h3><p>比如禁止git用户shell登录权限</p><div class="hljs"><pre><code class="hljs undefined">- <span class="hljs-symbol">git:</span><span class="hljs-symbol">x:</span><span class="hljs-number">1001</span><span class="hljs-symbol">:</span><span class="hljs-number">1001</span><span class="hljs-symbol">:</span>,,,<span class="hljs-symbol">:/home/git</span><span class="hljs-symbol">:/bin/bash</span><span class="hljs-comment"># 修改成如下</span>+ <span class="hljs-symbol">git:</span><span class="hljs-symbol">x:</span><span class="hljs-number">1001</span><span class="hljs-symbol">:</span><span class="hljs-number">1001</span><span class="hljs-symbol">:</span>,,,<span class="hljs-symbol">:/home/git</span><span class="hljs-symbol">:/usr/bin/git-shell</span></code></pre></div><h2 id="用户相关操作"><a href="#用户相关操作" class="headerlink" title="用户相关操作"></a>用户相关操作</h2><h3 id="新建用户"><a href="#新建用户" class="headerlink" title="新建用户"></a>新建用户</h3><p>有以下两种方式：<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-keyword">adduser </span>username<span class="hljs-symbol">useradd</span> username</code></pre></div></p><h3 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h3><p>对应不同的创建有不同的删除方式：<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">deluser usernameuserdel username</span></code></pre></div></p><h3 id="切换用户"><a href="#切换用户" class="headerlink" title="切换用户"></a>切换用户</h3><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">su username</span></code></pre></div><h3 id="改变文件用户"><a href="#改变文件用户" class="headerlink" title="改变文件用户"></a>改变文件用户</h3><div class="hljs"><pre><code class="hljs undefined">chown -R username <span class="hljs-keyword">dir </span><span class="hljs-comment"># 用户</span>chgrp -R grpname <span class="hljs-keyword">dir </span><span class="hljs-comment"># 用户组</span></code></pre></div><h3 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h3><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">passwd</span> username <span class="hljs-comment"># 修改密码</span>passwd username -d <span class="hljs-comment"># 删除密码</span></code></pre></div><h2 id="etc-sudoers文件"><a href="#etc-sudoers文件" class="headerlink" title="/etc/sudoers文件"></a>/etc/sudoers文件</h2><p>修改sudoers文件让用户获得sudo的使用权, 避免出现如下错误：</p><blockquote><p>xinger is not in the sudoers file.  This incident will be reported.</p></blockquote><p>比如创建了一个git用户，sudoers文件中添加<code>git   ALL=(ALL) ALL</code>让git用户获得sudo使用权。<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-comment"># User privilege specification</span><span class="hljs-attribute">root</span>    <span class="hljs-literal">ALL</span>=(<span class="hljs-literal">ALL</span>:<span class="hljs-literal">ALL</span>) <span class="hljs-literal">ALL</span><span class="hljs-comment"># </span><span class="hljs-attribute">git</span>     <span class="hljs-literal">ALL</span>=(<span class="hljs-literal">ALL</span>) <span class="hljs-literal">ALL</span></code></pre></div></p><ul><li>第一个ALL是指网络中的主机，我们后面把它改成了主机名，它指明jack可以在此主机上执行后面的命令。</li><li>第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。</li><li>最后一个ALL当然就是指命令名了。</li></ul><p>修改sudoers文件需要修改文件的读写权限, 注意要在在修改后将权限改回：<br><div class="hljs"><pre><code class="hljs undefined">sudo chmod +<span class="hljs-number">777</span> <span class="hljs-regexp">/etc/</span>sudoers<span class="hljs-comment"># 修改后将权限改回</span>sudo chmod <span class="hljs-number">440</span> <span class="hljs-regexp">/etc/</span>sudoers</code></pre></div></p><h1 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h1><ul><li>Linux文件的权限类型一般包括读、写、执行，对应字母为r、w、x，对应数字为4、2、1。对于一个文件夹而言，可写就意味着可以在这个文件夹下创建文件或文件夹；</li><li>Linux下权限的粒度分为拥有者、群组、其他组三种；</li><li>使用<code>chmod</code>命令修改文件权限，使用<code>chown</code>修改拥有者或群组，使用<code>chgrp</code>修改群组。</li><li>chown：一般来说，这个指令只有是由系统管理者(root)所使用，一般使用者没有权限可以改变别人的文件拥有者，也没有权限把自己的文件拥有者改设为别人。只有系统管理者(root)才有这样的权限。</li></ul><h2 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h2><h3 id="一般使用"><a href="#一般使用" class="headerlink" title="一般使用"></a>一般使用</h3><div class="hljs"><pre><code class="hljs shell">chmod [ugoa] [[+-=][rwx]]其中：[ugoa] u表示拥有者，g表示拥有群组，o表示其他，a表示全部[+-=] + 表示增加权限，- 表示取消权限，= 表示唯一设定权限。[rwxX] r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该档案是个子目录或者该档案已经被设定过为可执行。</code></pre></div><h3 id="数字权限"><a href="#数字权限" class="headerlink" title="数字权限"></a>数字权限</h3><p>r = 4, w = 2, x = 1.</p><ul><li><p>rwx则表示为：4 + 2 + 1 = 7；</p></li><li><p>r—则表示为：4 + 0 + 0 = 4；</p></li></ul><p>如果设置所有人都有rwx权限, 则用数字表示的权限为777，使用如下命令更改权限：</p><div class="hljs"><pre><code class="hljs undefined">chmod <span class="hljs-number">777</span> <span class="hljs-built_in">file</span></code></pre></div>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习基础</title>
    <link href="/2020/07/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/07/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-监督学习和非监督学习"><a href="#1-监督学习和非监督学习" class="headerlink" title="1. 监督学习和非监督学习"></a>1. 监督学习和非监督学习</h1><h2 id="1-1-监督学习"><a href="#1-1-监督学习" class="headerlink" title="1.1 监督学习"></a>1.1 监督学习</h2><p>定义：监督学习中，训练的数据集中既有特征（feature）又有标签（label），通过训练，可以让机器找到特征与标签之间的联系。</p><p><strong>ground truth：</strong>监督学习中，数据正确的标注即为ground truth。</p><p>监督学习分为回归（Regression）、分类（Classification）</p><h3 id="1-1-1-回归"><a href="#1-1-1-回归" class="headerlink" title="1.1.1 回归"></a>1.1.1 回归</h3><p>回归问题是针对连续型变量的。</p><h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><h5 id="（1）单变量线性回归"><a href="#（1）单变量线性回归" class="headerlink" title="（1）单变量线性回归"></a>（1）单变量线性回归</h5><p>单变量线性回归只给出一个特征，比如预测房屋价格问题，样本中只给出房屋尺寸这一个特征，通过回归算法，找出房价与房屋尺寸的线性关系。</p><script type="math/tex; mode=display">h_{\theta}(x) = {\theta}_{0} + {\theta}_{1} x</script><h5 id="（2）多变量线性回归"><a href="#（2）多变量线性回归" class="headerlink" title="（2）多变量线性回归"></a>（2）多变量线性回归</h5><p>多变量线性回归提供多个特征。比如预测房屋价格，给出房屋尺寸、房屋楼层等特征。<br>代价函数：</p><script type="math/tex; mode=display">J({\theta}_0, {\theta}_1, \ldots, {\theta}_n) = \frac {1}{2m} {\sum}_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2</script><p>其中：</p><script type="math/tex; mode=display">h_{\theta}(x) = {\theta}_0 + {\theta}_{1}x + ··· + {\theta}_{n}x</script><h4 id="逻辑回归（Logistics-Regression）"><a href="#逻辑回归（Logistics-Regression）" class="headerlink" title="逻辑回归（Logistics Regression）"></a>逻辑回归（Logistics Regression）</h4><p>适用于二分类问题，逻辑回归的输出是如下形式：</p><script type="math/tex; mode=display">a = \sigma(\omega^{T}x + b)</script><p>$\sigma()$是指<code>sigmoid</code>函数：</p><script type="math/tex; mode=display">\sigma(x) = \frac{1}{1 + e^{-x}}</script><p>使用<code>sigmoid</code>函数将线性函数转变成非线性，这也就是逻辑回归与线性回归的根本区别所在。</p><p>逻辑回归使用二分类交叉熵函数作为代价函数，使用梯度下降法进行优化。</p><h3 id="1-1-2-分类"><a href="#1-1-2-分类" class="headerlink" title="1.1.2 分类"></a>1.1.2 分类</h3><p>分类是针对离散型变量的。</p><h2 id="1-2-无监督学习"><a href="#1-2-无监督学习" class="headerlink" title="1.2 无监督学习"></a>1.2 无监督学习</h2><p>定义：训练数据集中没有标签，与监督学习相比更像是自学。</p><h1 id="2-代价函数"><a href="#2-代价函数" class="headerlink" title="2. 代价函数"></a>2. 代价函数</h1><p>机器学习中，训练模型的过程就是优化代价函数的过程。一个好的代价函数需要满足两个基本的要求：</p><ul><li>能够评价模型的准确性；</li><li>对参数可微。</li></ul><p>代价函数与损失函数的区别：损失函数是计算单个样本的损失值，而代价函数是计算总代价。</p><h2 id="2-1-均方误差"><a href="#2-1-均方误差" class="headerlink" title="2.1 均方误差"></a>2.1 均方误差</h2><p>线性回归中，常使用均方误差（Mean squared error）作为代价函数。</p><script type="math/tex; mode=display">J({\theta}_0, {\theta}_1, \ldots, {\theta}_n) = \frac {1}{2m} {\sum}_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2</script><h2 id="2-2-交叉熵"><a href="#2-2-交叉熵" class="headerlink" title="2.2 交叉熵"></a>2.2 交叉熵</h2><p>交叉熵代价函数常常用于分类问题，分类问题又分为二分类和多分类。</p><h3 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h3><p>逻辑回归是一个典型的二分类模型，使用如下代价函数进行参数优化。</p><script type="math/tex; mode=display">J({y}, {a}) = - \frac{1}{m}{\sum}_{i=1}^{m}(y^{(i)}\log(a^{(i)}) + (1-y^{(i)})\log(1-a^{(i)}))</script><p>其中y是指实际结果，a是指预期结果。</p><h3 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h3><script type="math/tex; mode=display">J(y, a) = - \frac{1}{m} \sum_{i=1}^{m}y^{(i)}\log(a^{(i)})</script><p>手写数字识别是一个多分类问题（识别0-9共10种数字），可以对labels进行one-hot编码，one-hot编码是指正确解的标签为1，其余为0，比如一个手写数字样本标签为3，则编码表示为$[0,0,0, 1, 0, 0, 0, 0, 0, 0]$, 如果计算的预期结果为$[2.2, 3.1, 1.2, 4.4, 0.1, 0.9, 3.5, 0.5, 0.9, 0.1]$，则单个样本的损失值为$-log(4.4)$</p><h1 id="3-神经网络"><a href="#3-神经网络" class="headerlink" title="3. 神经网络"></a>3. 神经网络</h1><p>训练神经网络的过程：</p><p>1） 参数的随机初始化；</p><p>2） 正向传播；</p><p>3） 计算代价；</p><p>4）反向传播计算所有偏导数；</p><p>5） 利用数值检验方法检验这些偏导数；</p><p>6）使用优化来最小化代价函数。</p><h2 id="3-1-随机初始化"><a href="#3-1-随机初始化" class="headerlink" title="3.1 随机初始化"></a>3.1 随机初始化</h2><p>参数初始化一般采用随机初始化，而不应该将所有参数都初始化为0，对于逻辑回归来说，全部初始化为0是可行的，因为逻辑回归是一层的神经网络，且只有一个神经元。对于复杂的神经网络来说，如果参数全部初始化为0，则对于同一层的所有神经元而言，其计算结果都是一样的，反向传播求的梯度也是一样的。</p><h2 id="3-2-反向传播"><a href="#3-2-反向传播" class="headerlink" title="3.2 反向传播"></a>3.2 反向传播</h2><p><strong>反向传播</strong>（Back Propagation）是“误差反向传播”的简称，是一种与<a href="https://zh.wikipedia.org/wiki/最优化" target="_blank" rel="noopener">最优化方法</a>（如<a href="https://zh.wikipedia.org/wiki/梯度下降法" target="_blank" rel="noopener">梯度下降法</a>）结合使用的，用来训练<a href="https://zh.wikipedia.org/wiki/人工神经网络" target="_blank" rel="noopener">人工神经网络</a>的常见方法。该方法使用链式法则对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。</p><p>反向传播算法（BP 算法）主要由两个阶段组成：激励传播与权重更新。</p><h3 id="第1阶段：激励传播"><a href="#第1阶段：激励传播" class="headerlink" title="第1阶段：激励传播"></a>第1阶段：激励传播</h3><p>每次迭代中的传播环节包含两步：</p><ol><li>（前向传播阶段）将训练输入送入网络以获得激励响应；</li><li>（反向传播阶段）将激励响应同训练输入对应的目标输出求差，从而获得输出层和隐藏层的响应误差。</li></ol><h3 id="第2阶段：权重更新"><a href="#第2阶段：权重更新" class="headerlink" title="第2阶段：权重更新"></a>第2阶段：权重更新</h3><p>对于每个突触上的权重，按照以下步骤进行更新：</p><ol><li>将输入激励和响应误差相乘，从而获得权重的梯度；</li><li>将这个梯度乘上一个比例并取反后加到权重上。</li></ol><p>这个比例（百分比）将会影响到训练过程的速度和效果，因此成为<strong>“学习率”</strong>。梯度的方向指明了误差扩大的方向，因此在更新权重的时候需要对其取反，从而减小权重引起的误差。</p><p>第 1 和第 2 阶段可以反复循环迭代，直到网络对输入的响应达到满意的预定的目标范围为止。</p><h2 id="3-3-梯度检验"><a href="#3-3-梯度检验" class="headerlink" title="3.3 梯度检验"></a>3.3 梯度检验</h2><p>通过估计梯度值来检验计算得到的导数值是否是正确的。下面对$\theta_1$进行检验：</p><script type="math/tex; mode=display">\frac {\partial {J}}{\partial \theta_1} = \frac {J(\theta_1+\epsilon, \theta_2,\ldots, \theta_n)-J(\theta_1-\epsilon, \theta_2,\ldots, \theta_n)}{2\epsilon}</script><p>其中$\epsilon$是一个非常小的常量。将上式计算得到的梯度与反向传播的梯度进行比较，若相差很小，则梯度是正确的。</p><h1 id="4-应用机器学习的建议"><a href="#4-应用机器学习的建议" class="headerlink" title="4. 应用机器学习的建议"></a>4. 应用机器学习的建议</h1><h2 id="4-1-模型选择"><a href="#4-1-模型选择" class="headerlink" title="4.1 模型选择"></a>4.1 模型选择</h2><p>使用<strong>验证集</strong>来选择模型，验证集并不参与学习参数的确定，而是用来选择超参数，比如多项式次数、网络层数、网络节点数、迭代次数、学习率等。</p><ul><li>训练集：用来训练模型内的参数的数据集；</li><li>验证集：验证集集是从训练集中取出来的一部分，用来选择模型，超参数调优；</li><li>测试集：用来评价模型泛化能力。训练过程不能使用测试集。</li></ul><p><strong>注意</strong>：绝对不能使用测试集用来调优，测试集只能在训练完成后评价最终模型时使用。如果使用测试集进行调优，测试结果可能不错，可实际性能会远低于预期，这种情况称之为对测试集过拟合。</p><h3 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h3><p>数据量较小（传统机器学习）</p><ul><li>没有验证集，训练集：测试集=7：3</li><li>有验证集，训练集：验证集：测试集=6：2：2</li></ul><p>数据量较大，比如100万条数据：</p><ul><li>训练集：验证集：测试集 = 98: 1: 1<h3 id="交叉验证（cross-validation）"><a href="#交叉验证（cross-validation）" class="headerlink" title="交叉验证（cross validation）"></a>交叉验证（cross validation）</h3></li></ul><p>交叉验证的做法就是先将数据集分出一个测试集，然后将剩下的数据分为比较均等不相交的k份，然后选择其中一份验证，另外的k-1份进行训练，最后求得error的平均值作为最终的评价。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200703174015.png" srcset="/img/loading.gif" alt=""></p><h1 id="5-过拟合与欠拟合"><a href="#5-过拟合与欠拟合" class="headerlink" title="5. 过拟合与欠拟合"></a>5. 过拟合与欠拟合</h1><p><strong>过拟合（Over-Fitting）</strong></p><p>在训练集上误差小，但在测试集上误差大，我们将这种情况称为高方差（high variance）</p><p><strong>欠拟合（Under-Fitting）</strong></p><p>在训练集上训练结果不好，准确率不高，我们将这种情况称为高偏差（high bias), 也叫欠拟合。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200702165139.png" srcset="/img/loading.gif" alt=""></p><h2 id="5-1-偏差与方差"><a href="#5-1-偏差与方差" class="headerlink" title="5.1 偏差与方差"></a>5.1 偏差与方差</h2><p><strong>偏差：</strong>描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。</p><p><strong>方差：</strong>描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200702170430.png" srcset="/img/loading.gif" alt=""></p><p>通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在一张图表上分析偏差和方差问题。</p><ul><li>训练集误差较大，且验证集误差与训练集误差相近：高偏差；</li><li>验证集误差远大于训练集误差：高方差。</li></ul><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200703175526.png" srcset="/img/loading.gif" alt=""></p><h2 id="5-2-如何防止过拟合"><a href="#5-2-如何防止过拟合" class="headerlink" title="5.2 如何防止过拟合"></a>5.2 如何防止过拟合</h2><ul><li>增加数据集</li><li>减少不能帮助正确预测的特征</li><li>正则化，增加正则化程度 $\lambda$</li><li>Dropout(随机失活)</li><li>Early Stopping</li><li>简化模型</li><li>增加噪声</li><li>Bagging</li><li>贝叶斯方法</li><li>决策树剪枝</li><li>集成方法，随机森林</li><li>Batch Normalization</li></ul><h3 id="5-2-1-正则化"><a href="#5-2-1-正则化" class="headerlink" title="5.2.1 正则化"></a>5.2.1 正则化</h3><p>正则化就是对最小化经验误差函数上加约束，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。</p><h4 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h4><p>$l_p$范数定义为：    </p><script type="math/tex; mode=display">\|{x}\|_{p}=\sqrt[p]{\sum_{i}\left|x_{i}\right|^{p}}</script><p>其中$x$ 表示一个向量。</p><h5 id="l-0-范数"><a href="#l-0-范数" class="headerlink" title="$l_0$范数"></a>$l_0$范数</h5><p>$l_0$范数表示向量中非0元素的个数，其优化模型是一个NP难问题，难以求解。</p><h5 id="l-1-范数"><a href="#l-1-范数" class="headerlink" title="$l_1$范数"></a>$l_1$范数</h5><p>$l_1$范数等于向量中所有哦元素绝对值之和。</p><script type="math/tex; mode=display">\|{x}\|_{1}=\sum_{i}|x_{i}|</script><h5 id="l-2-范数"><a href="#l-2-范数" class="headerlink" title="$l_2$范数"></a>$l_2$范数</h5><p>$l_2$范数即欧氏距离。</p><script type="math/tex; mode=display">\|{x}\|_{2}=\sqrt[2]{\sum_{i}\left|x_{i}\right|^{2}}</script><h4 id="L-1-和-L-2-正则化"><a href="#L-1-和-L-2-正则化" class="headerlink" title="$L_1$和$L_2$正则化"></a>$L_1$和$L_2$正则化</h4><p>$L_1$正则化：正则化项是参数向量的$L_1$范数。</p><script type="math/tex; mode=display">J(\omega, b) = \frac{1}{m} \sum_{i=1}^{m}L(y,a) + \frac {\lambda} {m} \sum \omega</script><p>$L_2$正则化：正则化项是参数向量的$L_2$范数的平方。</p><script type="math/tex; mode=display">J(\omega, b) = \frac{1}{m} \sum_{i=1}^{m}L(y,a) + \frac {\lambda} {2m} \sum \omega ^2</script><p>注意：可以不正则化参数$b$，$\frac{\lambda}{2m}$只是一个常数项，除以2是为了后面求导方便。</p><p><strong>为什么L2正则化可以防止过拟合？</strong></p><blockquote><p>L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量。由于输入和权重之间的乘法操作，这样就有了一个优良的特性：<strong>使网络更倾向于使用所有输入特征，而不是严重依赖输入特征中某些小部分特征。</strong> <strong>L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。</strong>。这样做可以提高模型的泛化能力，降低过拟合的风险。</p></blockquote><h3 id="5-2-2-Dropout（随机失活）"><a href="#5-2-2-Dropout（随机失活）" class="headerlink" title="5.2.2 Dropout（随机失活）"></a>5.2.2 Dropout（随机失活）</h3><p>dropout会遍历网络中的每一层，并设置消除神经元节点的概率，消除的本质就是让该节点的值变为0. 这种方式可以减少特征检测器间的相互作用，明显减少过拟合现象。Dropout被大量用于全连接网络，但在卷积神经网络中使用较少。</p><p>如下GIF所示，网络的第二层随机删除节点，设置keep_prob = 0.5，其中keep_prob表示保留某个隐藏神经元的概率.</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20180408162931222.gif" srcset="/img/loading.gif" alt=""></p><h4 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h4><div class="hljs"><pre><code class="hljs python">D1 = np.random.rand(A1.shape[<span class="hljs-number">0</span>],A1.shape[<span class="hljs-number">1</span>])     D1 = D1 &lt; keep_prob<span class="hljs-comment"># 步骤2：将D1的值转换为0或1（使用keep_prob作为阈值）</span>A1 = A1 * D1        <span class="hljs-comment"># 步骤3：舍弃A1的一些节点（将它的值变为0或False）</span>A1 = A1 / keep_prob<span class="hljs-comment"># 进行缩放，使A1的期望值没有太大变化</span></code></pre></div><p>反向传播时：</p><div class="hljs"><pre><code class="hljs python">dA1 = dA1 * D1 / keep_prob</code></pre></div><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p><strong>1. 为什么能防止过拟合？</strong></p><p>每个参数都有可能被随机的Drop掉，所以参数不会过分的依赖某一个特征的数据，而且不同参数之间的相互关联性也大大减弱，这些操作都可以增加泛化能力。</p><p><strong>2. 训练和测试有什么不同？</strong></p><p>测试时，所有神经元都要保留下来，乘上系数<code>keep_prob</code>。</p><h2 id="5-3-如何防止欠拟合"><a href="#5-3-如何防止欠拟合" class="headerlink" title="5.3 如何防止欠拟合"></a>5.3 如何防止欠拟合</h2><ul><li>添加新特征</li><li>添加多项式特征</li><li>减少正则化参数, 减少正则化程度 $\lambda$</li><li>增加网络复杂度</li><li>使用集成学习方法，如Bagging</li></ul><h1 id="6-符号约定"><a href="#6-符号约定" class="headerlink" title="6. 符号约定"></a>6. 符号约定</h1><h2 id="数据标记与上下标"><a href="#数据标记与上下标" class="headerlink" title="数据标记与上下标"></a>数据标记与上下标</h2><ul><li>上标： $^{(i)}$ 表示第i个样本；</li><li>上标：$^{[i]}$ 代表第i层；</li><li>m: 数据集的样本数； </li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LaTeX数学公式</title>
    <link href="/2020/07/03/LaTeX%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"/>
    <url>/2020/07/03/LaTeX%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="常用符号"><a href="#常用符号" class="headerlink" title="常用符号"></a>常用符号</h2><div class="table-container"><table><thead><tr><th>符号</th><th>示例</th><th>显示</th></tr></thead><tbody><tr><td>偏导</td><td>\partial y</td><td>$\partial y$</td></tr><tr><td>上下标</td><td>S=a_{1}^2+a_{2}^2+a_{3}^2</td><td>$S=a_{1}^2+a_{2}^2+a_{3}^2$</td></tr><tr><td>分数</td><td>\frac{1}{3}</td><td>$\frac{1}{3}$</td></tr><tr><td>开方</td><td>\sqrt[3]{X}</td><td>$\sqrt[3]{X}$</td></tr><tr><td></td><td>\bar x</td><td>$\bar x$</td></tr><tr><td>求导</td><td>\mathrm{d}y</td><td>$\mathrm{d}y$</td></tr><tr><td>向量</td><td>\vec x</td><td>$\vec{x}$</td></tr><tr><td>X帽</td><td>\hat X 或者\widehat X</td><td>$\hat X$ 或者$\widehat X$或者$\tilde{X}$</td></tr><tr><td>大括号</td><td><code>\left\{\begin{array}{l}1\\0\end{array}\right.</code>，用法：<code>\begin{array}[{垂直对齐}]{（列格式说明）} &lt;表项&gt; &amp; &lt;表项&gt; &amp;...&amp; \\ \end{array}</code>, 列格式说明有：l（左对齐）、r（右对齐）、c（中间对齐）三种</td><td>$\left\{\begin{array}{l}1\\0\end{array}\right.$</td></tr><tr><td>矩阵</td><td>pmatrix, bmatrix</td><td>$\begin{pmatrix}1&amp;1\\ 1&amp;1 \end{pmatrix}$</td></tr><tr><td></td><td>^{\circ}</td><td>$45^{\circ}$</td></tr></tbody></table></div><h2 id="其他字符"><a href="#其他字符" class="headerlink" title="其他字符"></a>其他字符</h2><h3 id="箭头"><a href="#箭头" class="headerlink" title="箭头"></a>箭头</h3><div class="table-container"><table><thead><tr><th>代码</th><th>符号</th></tr></thead><tbody><tr><td>\uparrow</td><td>$\uparrow$</td></tr><tr><td>\Uparrow</td><td>$\Uparrow$</td></tr><tr><td>\leftarrow</td><td>$\leftarrow$</td></tr><tr><td>\longleftarrow</td><td>$\longleftarrow$</td></tr><tr><td>X \stackrel{F} \rightarrow Y</td><td>$X \stackrel{F} \rightarrow Y$</td></tr></tbody></table></div><h3 id="关系运算符"><a href="#关系运算符" class="headerlink" title="关系运算符"></a>关系运算符</h3><div class="table-container"><table><thead><tr><th>代码</th><th>符号</th></tr></thead><tbody><tr><td>\pm</td><td>$\pm$</td></tr><tr><td>\times</td><td>$\times$</td></tr><tr><td>\div</td><td>$\div$</td></tr><tr><td>\mid</td><td>$\mid$</td></tr><tr><td>\nmid</td><td>$\nmid$</td></tr><tr><td>\cdot</td><td>$\cdot$</td></tr><tr><td>\ldots</td><td>$\ldots$</td></tr><tr><td>\circ</td><td>$\circ$</td></tr><tr><td>\ast</td><td>$\ast$</td></tr><tr><td>\bigodot</td><td>$\bigodot$</td></tr><tr><td>\bigotimes</td><td>$\bigotimes$</td></tr><tr><td>\bigoplus</td><td>$\bigoplus$</td></tr><tr><td>\leq</td><td>$\leq$</td></tr><tr><td>\geq</td><td>$\geq$</td></tr><tr><td>\neq</td><td>$\neq$</td></tr><tr><td>\approx</td><td>$\approx$</td></tr><tr><td>\equiv</td><td>$\equiv$</td></tr><tr><td>\sum</td><td>$\sum$</td></tr><tr><td>\prod</td><td>$\prod$</td></tr></tbody></table></div><h3 id="微积分运算符"><a href="#微积分运算符" class="headerlink" title="微积分运算符"></a>微积分运算符</h3><div class="table-container"><table><thead><tr><th>代码</th><th>符号</th></tr></thead><tbody><tr><td>\prime</td><td>$\prime$</td></tr><tr><td>\int</td><td>$\int$</td></tr><tr><td>\iint</td><td>$\iint$</td></tr><tr><td>\iiint</td><td>$\iiint$</td></tr><tr><td>\oint</td><td>$\oint$</td></tr><tr><td>\lim</td><td>$\lim$</td></tr><tr><td>\infty</td><td>$\infty$</td></tr><tr><td>\nabla</td><td>$\nabla$</td></tr><tr><td>\mathrm{d}</td><td>$\mathrm{d}$</td></tr></tbody></table></div><h3 id="集合运算符"><a href="#集合运算符" class="headerlink" title="集合运算符"></a>集合运算符</h3><div class="table-container"><table><thead><tr><th>代码</th><th>符号</th></tr></thead><tbody><tr><td>\emptyset</td><td>$\emptyset$</td></tr><tr><td>\in</td><td>$\in$</td></tr><tr><td>\notin</td><td>$\notin$</td></tr><tr><td>\subset</td><td>$\subset$</td></tr><tr><td>\cap</td><td>$\cap$</td></tr><tr><td>\subseteq</td><td>$\subseteq$</td></tr><tr><td>\cup</td><td>$\cup$</td></tr><tr><td>\supseteq</td><td>$\supseteq$</td></tr></tbody></table></div><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><div class="table-container"><table><thead><tr><th>代码</th><th>大写</th><th>代码</th><th>小写</th></tr></thead><tbody><tr><td>A</td><td>$A$</td><td>\alpha</td><td>$\alpha$</td></tr><tr><td>B</td><td>$B$</td><td>\beta</td><td>$\beta$</td></tr><tr><td>\Gamma</td><td>$\Gamma$</td><td>\gamma</td><td>$\gamma$</td></tr><tr><td>\Delta</td><td>$\Delta$</td><td>\delta</td><td>$\delta$</td></tr><tr><td>E</td><td>$E$</td><td>\epsilon</td><td>$\epsilon$</td></tr><tr><td>Z</td><td>$Z$</td><td>\zeta</td><td>$\zeta$</td></tr><tr><td>H</td><td>$H$</td><td>\eta</td><td>$\eta$</td></tr><tr><td>\Theta</td><td>$\Theta$</td><td>\theta</td><td>$\theta$</td></tr><tr><td>I</td><td>$I$</td><td>\iota</td><td>$\iota$</td></tr><tr><td>K</td><td>$K$</td><td>\kappa</td><td>$\kappa$</td></tr><tr><td>Lambda</td><td>$\Lambda$</td><td>\lambda</td><td>$\lambda$</td></tr><tr><td>M</td><td>$M$</td><td>\mu</td><td>$\mu$</td></tr><tr><td>N</td><td>$N$</td><td>\nu</td><td>$\nu$</td></tr><tr><td>Xi</td><td>$Xi$</td><td>\xi</td><td>$\xi$</td></tr><tr><td>O</td><td>$O$</td><td>\omicron</td><td>$\omicron$</td></tr><tr><td>\Pi</td><td>$\Pi$</td><td>\pi</td><td>$\pi$</td></tr><tr><td>P</td><td>$P$</td><td>\rho</td><td>$\rho$</td></tr><tr><td>\Sigma</td><td>$\Sigma$</td><td>\sigma</td><td>$\sigma$</td></tr><tr><td>T</td><td>$T$</td><td>\tau</td><td>$\tau$</td></tr><tr><td>\Upsilon</td><td>$\Upsilon$</td><td>\upsilon</td><td>$\upsilon$</td></tr><tr><td>\Phi</td><td>$\Phi$</td><td>\phi</td><td>$\phi$</td></tr><tr><td>X</td><td>$X$</td><td>\chi</td><td>$\chi$</td></tr><tr><td>\Psi</td><td>$\Psi$</td><td>\psi</td><td>$\psi$</td></tr><tr><td>\Omega</td><td>$\Omega$</td><td>\omega</td><td>$\omega$</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>LaTeX</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LaTex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>手写数字识别</title>
    <link href="/2020/07/02/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <url>/2020/07/02/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>手写数字识别需要完成识别0-9这10类数字的任务，数据集使用的是MNIST（<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">下载链接</a>）。</p><h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>如下图所示，构建了一个3层的神经网络（不包括输入层），第一个隐藏层包括128个神经元，第二个隐藏层包括64个神经元，输出层包括10个神经元。隐藏层中每个神经元进行两项运算：先进行线性运算，然后使用<code>tanh</code>激励函数；输出层也是先进行线性运算，但激励函数使用的是<code>softmax</code>。</p><p><img src="http://image.ningxin.site/神经网络模型图.png" srcset="/img/loading.gif" alt="网络结构图" style="zoom: 67%;"></p><h1 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h1><p>使用MNIST数据集，都是<code>28 x 28</code>大小的图片，一共有60000个训练样本和10000个测试样本。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-keyword">import</span> struct<span class="hljs-comment"># 训练集文件</span>train_images_idx3_ubyte_file = <span class="hljs-string">'data/MNIST/raw/train-images-idx3-ubyte'</span><span class="hljs-comment"># 训练集标签文件</span>train_labels_idx1_ubyte_file = <span class="hljs-string">'data/MNIST/raw/train-labels-idx1-ubyte'</span><span class="hljs-comment"># 测试集文件</span>test_images_idx3_ubyte_file = <span class="hljs-string">'data/MNIST/raw/t10k-images-idx3-ubyte'</span><span class="hljs-comment"># 测试集标签文件</span>test_labels_idx1_ubyte_file = <span class="hljs-string">'data/MNIST/raw/t10k-labels-idx1-ubyte'</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decode_idx3_ubyte</span><span class="hljs-params">(idx3_ubyte_file)</span>:</span>    <span class="hljs-string">"""    解析idx3文件的通用函数    :param idx3_ubyte_file: idx3文件路径    :return: 数据集    """</span>    <span class="hljs-comment"># 读取二进制数据</span>    bin_data = open(idx3_ubyte_file, <span class="hljs-string">'rb'</span>).read()    <span class="hljs-comment"># 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽</span>    offset = <span class="hljs-number">0</span>    fmt_header = <span class="hljs-string">'&gt;iiii'</span>  <span class="hljs-comment"># 因为数据结构中前4行的数据类型都是32位整型，所以采用i格式，但我们需要读取前4行数据，所以需要4个i。我们后面会看到标签集中，只使用2个ii。</span>    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)    <span class="hljs-comment"># print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))</span>    <span class="hljs-comment"># 解析数据集</span>    image_size = num_rows * num_cols    offset += struct.calcsize(fmt_header)  <span class="hljs-comment"># 获得数据在缓存中的指针位置，从前面介绍的数据结构可以看出，读取了前4行之后，指针位置（即偏移位置offset）指向0016。</span>    print(offset)    fmt_image = <span class="hljs-string">'&gt;'</span> + str(        image_size) + <span class="hljs-string">'B'</span>  <span class="hljs-comment"># 图像数据像素值的类型为unsigned char型，对应的format格式为B。这里还有加上图像大小784，是为了读取784个B格式数据，如果没有则只会读取一个值（即一副图像中的一个像素值）</span>    print(fmt_image, offset, struct.calcsize(fmt_image))    images = np.empty((num_images, num_rows, num_cols))    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_images):        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))        offset += struct.calcsize(fmt_image)    <span class="hljs-keyword">return</span> images<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decode_idx1_ubyte</span><span class="hljs-params">(idx1_ubyte_file)</span>:</span>    <span class="hljs-string">"""    解析idx1文件的通用函数    :param idx1_ubyte_file: idx1文件路径    :return: 数据集    """</span>    <span class="hljs-comment"># 读取二进制数据</span>    bin_data = open(idx1_ubyte_file, <span class="hljs-string">'rb'</span>).read()    <span class="hljs-comment"># 解析文件头信息，依次为魔数和标签数</span>    offset = <span class="hljs-number">0</span>    fmt_header = <span class="hljs-string">'&gt;ii'</span>    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)    <span class="hljs-comment"># print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))</span>    <span class="hljs-comment"># 解析数据集</span>    offset += struct.calcsize(fmt_header)    fmt_image = <span class="hljs-string">'&gt;B'</span>    labels = np.empty(num_images, dtype=np.int64)    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_images):        <span class="hljs-comment"># if (i + 1) % 10000 == 0:</span>        <span class="hljs-comment">#     print('已解析 %d' % (i + 1) + '张')</span>        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[<span class="hljs-number">0</span>]        offset += struct.calcsize(fmt_image)    <span class="hljs-keyword">return</span> labels<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_train_images</span><span class="hljs-params">(idx_ubyte_file=train_images_idx3_ubyte_file)</span>:</span>    <span class="hljs-keyword">return</span> decode_idx3_ubyte(idx_ubyte_file)<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_train_labels</span><span class="hljs-params">(idx_ubyte_file=train_labels_idx1_ubyte_file)</span>:</span>    <span class="hljs-keyword">return</span> decode_idx1_ubyte(idx_ubyte_file)<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_test_images</span><span class="hljs-params">(idx_ubyte_file=test_images_idx3_ubyte_file)</span>:</span>    <span class="hljs-keyword">return</span> decode_idx3_ubyte(idx_ubyte_file)<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_test_labels</span><span class="hljs-params">(idx_ubyte_file=test_labels_idx1_ubyte_file)</span>:</span>    <span class="hljs-keyword">return</span> decode_idx1_ubyte(idx_ubyte_file)<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_data</span><span class="hljs-params">()</span>:</span>    train_img = load_train_images()    train_img = train_img.reshape(train_img.shape[<span class="hljs-number">0</span>], train_img.shape[<span class="hljs-number">1</span>] * train_img.shape[<span class="hljs-number">2</span>]).T / <span class="hljs-number">255</span>    test_img = load_test_images()    test_img = test_img.reshape(test_img.shape[<span class="hljs-number">0</span>], test_img.shape[<span class="hljs-number">1</span>] * test_img.shape[<span class="hljs-number">2</span>]).T / <span class="hljs-number">255</span>    train_label = load_train_labels()    test_label = load_test_labels()    <span class="hljs-keyword">return</span> train_img, train_label, test_img, test_label</code></pre></div><p>数据处理后训练样本和测试样本的维度：<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">train_img</span>: (784, 60000)<span class="hljs-attribute">train_label</span>: (60000, )<span class="avrasm"><span class="hljs-symbol">test_img:</span> (<span class="hljs-number">784</span>, <span class="hljs-number">10000</span>)<span class="hljs-symbol">test_label:</span> (<span class="hljs-number">10000</span>, )</span></code></pre></div></p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>在读取数据之后，为了程序能够正常运行，需要对数据进行预处理。</p><ul><li>对图像数据进行归一化操作，因为每个像素点的值是在0-255范围内，进行归一化可以减少运算量，同时避免运算结果溢出；</li><li>对labels进行one-hot编码，这一步骤主要是为了计算交叉熵损失函数时能够正常运行。one-hot编码指的是正确解的标签为1，其余为0，比如3表示为”0010000000“。</li></ul><p>one-hot编码的python实现如下：</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dense_to_one_hot</span><span class="hljs-params">(labels_dense, num_classes)</span>:</span>    <span class="hljs-string">"""    Convert class labels from scalars to one-hot vectors.    num_classes: 总共的类别数    """</span>    num_labels = labels_dense.shape[<span class="hljs-number">0</span>]    <span class="hljs-comment"># 偏移量，arange函数产生0，1，num_labels-1之间的数</span>    index_offset = np.arange(num_labels) * num_classes    labels_one_hot = np.zeros((num_labels, num_classes))    <span class="hljs-comment"># flat返回一个一维迭代器，ravel()函数将多维数组转化为一维数组</span>    labels_one_hot.flat[index_offset + labels_dense.ravel()] = <span class="hljs-number">1</span>    <span class="hljs-keyword">return</span> labels_one_hot</code></pre></div><h1 id="初始化参数"><a href="#初始化参数" class="headerlink" title="初始化参数"></a>初始化参数</h1><p>首先需要初始化参数，b直接全部初始化为0，W使用<code>randn</code>生成随机数，注意b和W不能全部都一样，否则任意一层中的每个神经元输出都一样，最后反向传播也一样，就没有任何意义了。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-comment"># x: 784*60000, 784*1000</span><span class="hljs-comment"># # y: 10*60000, 10*1000</span><span class="hljs-comment"># # W1: 128*784</span><span class="hljs-comment"># # b1: 128*1</span><span class="hljs-comment"># # W2: 64*128</span><span class="hljs-comment"># # b2: 64*1</span><span class="hljs-comment"># # W3: 10*64</span><span class="hljs-comment"># # b3: 10*1</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_parameters</span><span class="hljs-params">(layers_dim=<span class="hljs-params">(<span class="hljs-number">784</span>, <span class="hljs-number">25</span>, <span class="hljs-number">12</span>, <span class="hljs-number">10</span>)</span>)</span>:</span>    <span class="hljs-string">"""    初始化参数    :return:    """</span>    m = len(layers_dim)    parameters = &#123;&#125;    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m - <span class="hljs-number">1</span>):        <span class="hljs-comment"># randn生成的随机数符合标准高斯分布，期望为0，方差为1</span>        parameters[<span class="hljs-string">'W'</span> + str(i + <span class="hljs-number">1</span>)] = np.random.randn(layers_dim[i + <span class="hljs-number">1</span>], layers_dim[i]) * <span class="hljs-number">0.001</span>        parameters[<span class="hljs-string">'b'</span> + str(i + <span class="hljs-number">1</span>)] = np.zeros((layers_dim[i + <span class="hljs-number">1</span>], <span class="hljs-number">1</span>))    <span class="hljs-keyword">return</span> parameters</code></pre></div><h1 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h1><p>前向传播的基本步骤是先使用一个线性函数，然后使用激励函数将结果非线性化。可以如下表示：</p><div class="hljs"><pre><code class="hljs python">y = Wx + ba = activation(y) <span class="hljs-comment"># 使用时用具体的激励函数替换</span></code></pre></div><p>实验中主要使用了<code>tanh</code>和<code>softmax</code>这两个激励函数。<code>tanh</code>函数公式及python实现如下：</p><script type="math/tex; mode=display">y = \frac{e^x - e^{-x}}{e^x + e^{-x}} \tag{1}</script><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tanh</span><span class="hljs-params">(x)</span>:</span>    <span class="hljs-keyword">return</span> (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))</code></pre></div><p><code>softmax</code>函数公式及python实现如下, </p><script type="math/tex; mode=display">\operatorname{Softmax}\left(x_{i}\right)=\frac{e^{x_i}}{\sum_{j} e^{x_{j}}} \tag{2}</script><p>需要注意的是，在python实现<code>softmax</code>时，为了避免计算溢出，可以减去一个最大值之后，再进行指数运算。</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax</span><span class="hljs-params">(z)</span>:</span>    <span class="hljs-comment"># 实现softmax分类器输出转化</span>    c = np.max(z)    z_exp = np.exp(z - c) <span class="hljs-comment"># 避免指数运算产生溢出</span>    z_sum_column = z_exp.sum(axis=<span class="hljs-number">0</span>).T    <span class="hljs-keyword">return</span> z_exp / z_sum_column</code></pre></div><h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p>反向传播过程主要根据链式规则求解各个参数的关于损失函数的梯度，以便对参数进行优化，从而使损失值减小。实验中损失函数使用的是交叉熵损失函数，可以表示为：</p><script type="math/tex; mode=display">L = -\frac{1}{m}{\sum_{i} {y_i \log{a_i}}} \tag{3}</script><p>其中 为样本数量，$y_i$ 表示实际值，$a_i$ 表示预测值, 而 $a_i$ 是经过softmax函数得到的结果，即 $a_i$ 可以表示为：</p><script type="math/tex; mode=display">a_i = \frac{e^{z_i}}{\sum_{j} e^{z_{j}}} \tag{4}</script><p>则 $a_j$ 对 $z_i$ 求偏导数，可得：</p><script type="math/tex; mode=display">\frac{\partial a_{j}}{\partial z_{i}}=\left\{\begin{array}{ll}a_{i}\left(1-a_{i}\right), & i=j \\-a_{i} a_{j} & i \neq j\end{array}\right. \tag{5}</script><p>使用上式，L 对 $z_i$ 求偏导数得： </p><script type="math/tex; mode=display">\begin{array}{l}\quad \frac{\partial L}{\partial z_{i}}=\frac{\partial L}{\partial a_j} \frac{\partial a_j}{\partial z_i}=\sum_{j}-\frac{y i}{a_{j}} \frac{\partial a_{j}}{\partial z_{i}} \\=\frac{-y_{i}}{a_{i}} a_{i}\left(1-a_{i}\right)+\sum_{j}^{j \neq i}-\frac{y_{i}}{a_{j}}\left(-a_{i} a_{j}\right) \\=-y_{i}\left(1 - a_{i}\right)+\sum_{j=1}^{j \neq i} a_{i} y_{j} \\=a_{i} y_{i}-y_{i}+a_{i} \sum_{i \neq j} y_{j} \\=a_{i} \sum_{j} y_{j}-y_{i}=a_{i}-y_{i}\end{array}</script><p>记上式为$dZ$ , 然后计算 $\frac{\partial L}{\partial W}$，其中X为上一层传进来的数据。:</p><script type="math/tex; mode=display">\frac{\partial L}{\partial W} = \frac{\partial L}{\partial Z} \frac{\partial Z}{\partial W} \\= dZX</script><p>实验中还是用了<code>tanh</code>函数，其导数为：</p><script type="math/tex; mode=display">f(x)^{\prime}=1-(\tanh (x))^{2} \tag{6}</script><p>反向传播各个过程的偏导数都求出来之后，就可以编码实现了，具体代码如下：</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward_propagation</span><span class="hljs-params">(x, y, cache, parameters)</span>:</span>    <span class="hljs-string">"""    x: 网络中的输入数据    y: 网络的输出数据    cache：缓存各阶段计算的结果    """</span>    W2 = parameters[<span class="hljs-string">'W2'</span>]    W3 = parameters[<span class="hljs-string">'W3'</span>]    m = y.shape[<span class="hljs-number">0</span>]    (Z1, A1, Z2, A2, Z3, A3) = cache    dz3 = (A3 - y) / m    dW3 = np.dot(dz3, A2.T)    db3 = np.mean(dz3, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)    da2 = np.dot(W3.T, dz3)    dz2 = np.multiply(da2, <span class="hljs-number">1</span> - np.multiply(A2, A2))    dW2 = np.dot(dz2, A1.T) / m    db2 = np.mean(dz2, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)    da1 = np.dot(W2.T, dz2)    dz1 = np.multiply(da1, <span class="hljs-number">1</span> - np.multiply(A1, A1))    dW1 = np.dot(dz1, x.T) / m    db1 = np.mean(dz1, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-keyword">True</span>)    gradients = &#123;<span class="hljs-string">"dz3"</span>: dz3, <span class="hljs-string">"dW3"</span>: dW3, <span class="hljs-string">"db3"</span>: db3,                 <span class="hljs-string">"da2"</span>: da2, <span class="hljs-string">"dz2"</span>: dz2, <span class="hljs-string">"dW2"</span>: dW2, <span class="hljs-string">"db2"</span>: db2,                 <span class="hljs-string">"da1"</span>: da1, <span class="hljs-string">"dz1"</span>: dz1, <span class="hljs-string">"dW1"</span>: dW1, <span class="hljs-string">"db1"</span>: db1&#125;    <span class="hljs-keyword">return</span> gradients</code></pre></div><h1 id="损失函数和优化器"><a href="#损失函数和优化器" class="headerlink" title="损失函数和优化器"></a>损失函数和优化器</h1><p>损失函数使用的是交叉熵损失函数，交叉熵函数的公式见公式(3), 具体实现如下：</p><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cross_entropy_loss</span><span class="hljs-params">(a, y)</span>:</span>    <span class="hljs-string">"""    交叉熵损失函数    :param a: 预测值    :param y: 实际值    :return:    """</span>    m = a.shape[<span class="hljs-number">1</span>]    <span class="hljs-comment"># 对数操作加1e-7防止出现0</span>    loss = -np.multiply(np.log(a + <span class="hljs-number">1e-7</span>), y).sum(axis=<span class="hljs-number">0</span>)    cost = loss.sum() / m    <span class="hljs-keyword">return</span> cost</code></pre></div><p>使用上述的实现需要注意两点：对实际的label值需要使用<code>one-hot</code>编码；实现中使用了对数运算，为了防止出现0，需要加上一个偏置值。</p><p>梯度下降法根据计算得到的梯度更新参数，从而达到减小损失值的效果，可以表示成如下形式为：</p><script type="math/tex; mode=display">x_{n}^{(i+1)}=x_{n}^{(i)}-\eta \cdot \frac{\partial f}{\partial x_{n}}\left(\mathbf{x}^{(i)}\right)</script><p>其中$\eta$ 指的就是学习率，python实现如下：</p><div class="hljs"><pre><code class="hljs python">ef gradient_descent(parameters, grads, learning_rate):    <span class="hljs-string">"""    使用梯度下降法更新参数    :param parameters:    :param grads:    :param learning_rate:    :return:    """</span>    length = len(parameters) // <span class="hljs-number">2</span>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(length):        parameters[<span class="hljs-string">"W"</span> + str(i + <span class="hljs-number">1</span>)] = parameters[<span class="hljs-string">"W"</span> + str(i + <span class="hljs-number">1</span>)] - learning_rate * grads[<span class="hljs-string">"dW"</span> + str(i + <span class="hljs-number">1</span>)]        parameters[<span class="hljs-string">"b"</span> + str(i + <span class="hljs-number">1</span>)] = parameters[<span class="hljs-string">"b"</span> + str(i + <span class="hljs-number">1</span>)] - learning_rate * grads[<span class="hljs-string">"db"</span> + str(i + <span class="hljs-number">1</span>)]    <span class="hljs-keyword">return</span> parameters</code></pre></div><h1 id="训练及预测"><a href="#训练及预测" class="headerlink" title="训练及预测"></a>训练及预测</h1><p>训练过程：初始化参数—&gt;前向传播—&gt;反向传播—&gt;参数优化。</p><p>训练过程的参数设置如下：</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attr">epochs</span> = <span class="hljs-number">100</span><span class="hljs-attr">BATCH_SIZE</span> = <span class="hljs-number">100</span><span class="hljs-attr">learning_rate</span> = <span class="hljs-number">0.005</span></code></pre></div><p>实验时，把训练和预测两部分放到了一起运行，执行过程如下，其中正确率达到了97.83%</p><p><img src="http://image.ningxin.site/20200615153942.png" srcset="/img/loading.gif" alt=""></p><p>loss值下降过程如下： </p><p><img src="http://image.ningxin.site/20200615161053.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚拟机搭建Hadoop过程记录</title>
    <link href="/2020/06/07/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%90%AD%E5%BB%BAHadoop%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/06/07/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%90%AD%E5%BB%BAHadoop%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-搭建Hadoop分布式集群环境"><a href="#1-搭建Hadoop分布式集群环境" class="headerlink" title="1. 搭建Hadoop分布式集群环境"></a>1. 搭建Hadoop分布式集群环境</h1><h2 id="1-1-安装Linux虚拟机"><a href="#1-1-安装Linux虚拟机" class="headerlink" title="1.1 安装Linux虚拟机"></a>1.1 安装Linux虚拟机</h2><p>首先下载并安装VirtualBox 6.1.8，然后准备安装Linux虚拟机，需要提前下载好镜像文件，我下载的是<code>ubuntu-16.04.6-server-amd64.iso</code>。然后新建一个虚拟机，分配1G内存，10G虚拟空间。在新建虚拟机之后，需要注意以下设置：</p><ul><li>设置启动顺序：如下图所示，将光驱启动调到最前面。</li></ul><a id="more"></a><p><img src="http://image.ningxin.site/20200603230721.png" srcset="/img/loading.gif" alt=""></p><ul><li>如下选择镜像文件的存放位置：</li></ul><p><img src="http://image.ningxin.site/20200603230506.png" srcset="/img/loading.gif" alt=""></p><p>完成上述操作后，点击运行进行虚拟机的安装。重复操作，安装如下四台虚拟机，其中ubuntu作为master，slave1、slave2、slave3作为slave。</p><p><img src="http://image.ningxin.site/20200603231706.png" srcset="/img/loading.gif" alt=""></p><h2 id="1-2-配置Hadoop环境"><a href="#1-2-配置Hadoop环境" class="headerlink" title="1.2 配置Hadoop环境"></a>1.2 配置Hadoop环境</h2><h3 id="1-2-3-前置条件"><a href="#1-2-3-前置条件" class="headerlink" title="1.2.3 前置条件"></a>1.2.3 前置条件</h3><h4 id="1-2-3-1-编辑hostname文件"><a href="#1-2-3-1-编辑hostname文件" class="headerlink" title="1.2.3.1 编辑hostname文件"></a>1.2.3.1 编辑hostname文件</h4><p>使用<code>hostnamectl set-hostname</code>命令设置hostname分别为master、slave1、slave2、slave3</p><p><img src="http://image.ningxin.site/20200603232421.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-2-3-2-编辑hosts文件"><a href="#1-2-3-2-编辑hosts文件" class="headerlink" title="1.2.3.2 编辑hosts文件"></a>1.2.3.2 编辑hosts文件</h4><p>hosts文件用来记录IP和hostname之间的对应关系。使用<code>ifconfig</code>命令来查看IP地址，最后发现4台虚拟机的IP地址是一样的，需要修改网线连接方式，如下选择<code>桥接网卡</code>即可：<br><img src="http://image.ningxin.site/20200603232752.png" srcset="/img/loading.gif" alt=""></p><p>然后修改<code>/etc/hosts</code>文件，如下所示：</p><p><img src="http://image.ningxin.site/20200603232949.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-2-3-3-配置ssh免密登录"><a href="#1-2-3-3-配置ssh免密登录" class="headerlink" title="1.2.3.3 配置ssh免密登录"></a>1.2.3.3 配置ssh免密登录</h4><p>在master上使用<code>ssh-keygen -t rsa</code>命令生成密钥（保存在<code>~/.ssh</code>目录下），然后将公钥上传到slave的<code>~/.ssh/authorized_keys</code>中即可。</p><h2 id="1-2-安装并配置jdk"><a href="#1-2-安装并配置jdk" class="headerlink" title="1.2 安装并配置jdk"></a>1.2 安装并配置jdk</h2><p>首先在Windows上下载<code>jdk-8u251-linux-x64.tar.gz</code>，然后使用pscp工具上传到Linux虚拟机上。</p><p><img src="http://image.ningxin.site/20200602154744.png" srcset="/img/loading.gif" alt=""></p><p>将jdk解压在<code>/usr/java/</code>目录下，然后配置java环境变量，在<code>/etc/profile</code>文件中添加如下内容，然后运行<code>source /etc/profile</code>命令使环境变量生效：</p><div class="hljs"><pre><code class="hljs undefined">export JAVA_HOME=<span class="hljs-regexp">/usr/java</span><span class="hljs-regexp">/jdk1.8.0_251export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/</span><span class="hljs-symbol">LIB:</span>$JAVA_HOME/jre/<span class="hljs-class"><span class="hljs-keyword">lib</span></span>export PATH=$<span class="hljs-symbol">PATH:</span>$JAVA_HOME/<span class="hljs-symbol">bin:</span>$JAVA_HOME/jre/bin</code></pre></div><h2 id="1-3-安装并配置Hadoop"><a href="#1-3-安装并配置Hadoop" class="headerlink" title="1.3 安装并配置Hadoop"></a>1.3 安装并配置Hadoop</h2><h3 id="1-3-1-配置环境变量"><a href="#1-3-1-配置环境变量" class="headerlink" title="1.3.1 配置环境变量"></a>1.3.1 配置环境变量</h3><p>先从Windows上下载Hadoop2.10.0并上传到Linux虚拟机上，解压到<code>/usr/hadoop/</code>目录下，然后添加如下环境变量：</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-builtin-name">export</span> <span class="hljs-attribute">HADOOP_HOME</span>=/usr/hadoop/hadoop-2.10.0<span class="hljs-builtin-name">export</span> <span class="hljs-attribute">PATH</span>=<span class="hljs-variable">$PATH</span>:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></pre></div><h3 id="1-3-2-配置相关配置文件"><a href="#1-3-2-配置相关配置文件" class="headerlink" title="1.3.2 配置相关配置文件"></a>1.3.2 配置相关配置文件</h3><p>以下提到的配置文件都位于<code>etc/hadoop/</code>目录下。</p><p><img src="http://image.ningxin.site/20200604105619.png" srcset="/img/loading.gif" alt=""></p><p>注意：只需要修改master中的Hadoop配置文件，然后将配置好的Hadoop上传到slave中去即可，避免重复配置的麻烦。</p><h4 id="1-3-2-1-hadoop-env-sh-和-yarn-env-sh"><a href="#1-3-2-1-hadoop-env-sh-和-yarn-env-sh" class="headerlink" title="1.3.2.1 hadoop-env.sh 和 yarn-env.sh"></a>1.3.2.1 hadoop-env.sh 和 yarn-env.sh</h4><p>两个文件都是修改<code>JAVA_HOME</code>的值，需要使用实际的路径，而不是环境变量。<br><img src="http://image.ningxin.site/20200602161801.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-3-2-2-core-site-xml"><a href="#1-3-2-2-core-site-xml" class="headerlink" title="1.3.2.2 core-site.xml"></a>1.3.2.2 core-site.xml</h4><p>配置监听端口和缓存目录，缓存目录不存在则需要创建。</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-params">&lt;configuration&gt;</span><span class="hljs-meta"># HDFS Web UI 监听端口配置</span><span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>fs.defaultFS<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span>hdfs:<span class="hljs-comment">//master:8020&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span><span class="hljs-meta"># hadoop 缓存目录，更改为自己的目录（从根目录开始，不存在需创建）</span><span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>hadoop.tmp.dir<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span>file:<span class="hljs-meta-keyword">/root/</span>software/hadooptmp<span class="hljs-params">&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span><span class="hljs-params">&lt;/configuration&gt;</span></code></pre></div><h4 id="1-3-2-3-hdfs-site-xml"><a href="#1-3-2-3-hdfs-site-xml" class="headerlink" title="1.3.2.3 hdfs-site.xml"></a>1.3.2.3 hdfs-site.xml</h4><p>需要创建HDFS存储目录，namenode用来存储namenode文件，data存储datanode数据，tmp存储临时文件。</p><div class="hljs"><pre><code class="hljs undefined">usr<span class="hljs-regexp">/hadoop/</span>hadoop-<span class="hljs-number">2.10</span>.<span class="hljs-number">0</span><span class="hljs-regexp">/hdfs/</span>namenodeusr<span class="hljs-regexp">/hadoop/</span>hadoop-<span class="hljs-number">2.10</span>.<span class="hljs-number">0</span><span class="hljs-regexp">/hdfs/</span>datausr<span class="hljs-regexp">/hadoop/</span>hadoop-<span class="hljs-number">2.10</span>.<span class="hljs-number">0</span><span class="hljs-regexp">/hdfs/</span>tmp</code></pre></div><p><img src="http://image.ningxin.site/20200602164047.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-3-2-4-mapred-site-xml"><a href="#1-3-2-4-mapred-site-xml" class="headerlink" title="1.3.2.4 mapred-site.xml"></a>1.3.2.4 mapred-site.xml</h4><p><code>mapred-site.xml</code>文件需要从<code>mapred-site.xml.template</code>使用cp命令生成：<br><code>cp mapred-site.xml.template mapred-site.xml</code>。然后设置MapReduce运行于yarn上：</p><p><img src="http://image.ningxin.site/20200602164356.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-3-2-5-yarn-site-xml"><a href="#1-3-2-5-yarn-site-xml" class="headerlink" title="1.3.2.5 yarn-site.xml"></a>1.3.2.5 yarn-site.xml</h4><p><img src="http://image.ningxin.site/20200602164735.png" srcset="/img/loading.gif" alt=""></p><p>上面<code>yarn-site.xml</code>文件中将<code>hostname</code>错打成<code>hostnane</code>，最后导致Hadoop运行wordcount时，不能结束，修改后如下：</p><p><img src="http://image.ningxin.site/20200603095221.png" srcset="/img/loading.gif" alt=""></p><h4 id="1-3-2-6-slaves"><a href="#1-3-2-6-slaves" class="headerlink" title="1.3.2.6 slaves"></a>1.3.2.6 slaves</h4><p>在slaves文件中添加如下内容来设置slave：</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">slave1</span>slave2slave3</code></pre></div><h3 id="1-3-3-启动Hadoop"><a href="#1-3-3-启动Hadoop" class="headerlink" title="1.3.3 启动Hadoop"></a>1.3.3 启动Hadoop</h3><p>第一次启动需要使用<code>hdfs namenode -format</code>格式化文件系统，出现“Cannot create directory /usr/hadoop/hadoop-2.10.0/hdfs/namenode/current”错误，显示无法创建current文件。无法创建目录的原因是因为<code>hadoop-2.10.0</code>的文件拥有者是<code>root</code>，直接使用<code>sudo hdfs namenode -format</code>会出现找不到命令的错误，两种解决方法：1. 使用<code>sudo su</code>切换到管理员身份；2. 修改<code>hadoop-2.10.0</code>的文件拥有者为普通用户。</p><ul><li>启动: 使用<code>start-dfs.sh</code>启动分布式文件系统。</li></ul><p><img src="http://image.ningxin.site/20200602213020.png" srcset="/img/loading.gif" alt=""></p><ul><li>jps: 使用jps命令验证HDFS是否启动成功</li></ul><p><img src="http://image.ningxin.site/20200602213149.png" srcset="/img/loading.gif" alt=""></p><ul><li>启动yarn: 使用<code>start-yarn.sh</code>启动yarn</li></ul><p><img src="http://image.ningxin.site/20200602214232.png" srcset="/img/loading.gif" alt=""></p><ul><li>浏览器: 在浏览器中输入<code>http:master:50070</code>查看UI界面</li></ul><p><img src="http://image.ningxin.site/20200602214338.png" srcset="/img/loading.gif" alt=""></p><h1 id="2-HDFS文件上传"><a href="#2-HDFS文件上传" class="headerlink" title="2. HDFS文件上传"></a>2. HDFS文件上传</h1><p>创建<code>input.txt</code>文件并输入以下内容：</p><p><img src="http://image.ningxin.site/20200604001324.png" srcset="/img/loading.gif" alt=""></p><p>使用<code>hdfs dfs -put</code>命令将文件上传到hdfs中，然后使用<code>hdfs dfs -cat</code>命令查看文件中的具体内容。</p><p><img src="http://image.ningxin.site/20200604001901.png" srcset="/img/loading.gif" alt=""></p><h1 id="3-运行wordcount程序"><a href="#3-运行wordcount程序" class="headerlink" title="3. 运行wordcount程序"></a>3. 运行wordcount程序</h1><p>wordcount程序在<code>share/hadoop/hadoop-mapreduce-examples-2.10.0.jar</code>包中, 运行该程序之前需要提前创建输入文件,输出文件不需要创建， 输入输出文件如下：</p><div class="hljs"><pre><code class="hljs undefined">/wordcount/input/<span class="hljs-selector-tag">input</span><span class="hljs-selector-class">.txt</span>/wordcount/output（不要创建）</code></pre></div><p>其中<code>input.txt</code>文件中的内容如下：</p><p><img src="http://image.ningxin.site/20200603100517.png" srcset="/img/loading.gif" alt=""></p><p>然后使用命令<code>hadoop jar hadoop-mapreduce-examples-2.10.0.jar wordcount /wordcount/input/input.txt /wordcount/output</code>运行wordcount程序，结果如下：<br><img src="http://image.ningxin.site/20200603100155.png" srcset="/img/loading.gif" alt=""></p><p>使用命令<code>hdfs dfs -cat /wordcount/output/part-r-00000</code>查看输出结果：<br><img src="http://image.ningxin.site/20200603100430.png" srcset="/img/loading.gif" alt=""></p><h1 id="4-编写wordcount程序"><a href="#4-编写wordcount程序" class="headerlink" title="4. 编写wordcount程序"></a>4. 编写wordcount程序</h1><p>wordcount程序见附件<code>WordCount.java</code>。</p><p>master中创建如下目录, 其中src存放java文件，classes存放class文件：</p><div class="hljs"><pre><code class="hljs undefined">~<span class="hljs-regexp">/wordcount/</span>src~<span class="hljs-regexp">/wordcount/</span>classes</code></pre></div><h2 id="4-1-编译"><a href="#4-1-编译" class="headerlink" title="4.1 编译"></a>4.1 编译</h2><p>编译时需要引入的包如下：</p><div class="hljs"><pre><code class="hljs undefined">share/hadoop/common/hadoop-common-<span class="hljs-number">2.10</span>.<span class="hljs-number">0</span>.jarshare/hadoop/mapreduce/hadoop-mapreduce-client-core-<span class="hljs-number">2.10</span>.<span class="hljs-number">0</span>.jarshare/hadoop/common/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">commons</span>-<span class="hljs-title">cli</span>.1.2.<span class="hljs-title">jar</span></span></code></pre></div><p>使用javac命令进行编译，并用<code>-classpath</code>指定引入的包，<code>-d</code>指定输出目录：</p><p><img src="http://image.ningxin.site/20200603213806.png" srcset="/img/loading.gif" alt=""></p><h2 id="4-2-打包"><a href="#4-2-打包" class="headerlink" title="4.2 打包"></a>4.2 打包</h2><p>使用命令<code>jar -cvf wordcount.jar classes/</code>进行打包：</p><p><img src="http://image.ningxin.site/20200603213924.png" srcset="/img/loading.gif" alt=""></p><h2 id="4-3-运行"><a href="#4-3-运行" class="headerlink" title="4.3 运行"></a>4.3 运行</h2><p>使用如下命令运行wordcount.jar</p><p><code>hadoop jar wordcount.jar WordCount /wordcount/input/input.txt /output</code></p><p>然后出现<code>Class WordCount$Reduce not found</code>的错误，最后使用如下打包命令，解决问题：</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-selector-tag">jar</span> <span class="hljs-selector-tag">cf</span> <span class="hljs-selector-tag">wordcount</span><span class="hljs-selector-class">.jar</span> <span class="hljs-selector-tag">WordCount</span>*<span class="hljs-selector-class">.class</span></code></pre></div><p>运行界面如下：<br><img src="http://image.ningxin.site/20200603221301.png" srcset="/img/loading.gif" alt=""></p><p>运行后的输出结果如下：<br><img src="http://image.ningxin.site/20200603221509.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>大数据</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3D-UNet笔记</title>
    <link href="/2020/06/03/3D-UNet%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/06/03/3D-UNet%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://arxiv.org/pdf/1606.06650.pdf" target="_blank" rel="noopener">论文地址</a></p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>医学图像通常是由多个2D切片构成一整张图，对这样的数据进行标注比较困难,只能一张一张地标注2D图像，并将2D图像送进模型进行训练，但相邻的切片几乎一样，因此这样的做法效率很低。<br>论文的作者提出了3D U-Net模型，该模型主要有两种应用：</p><ul><li>semi-automated setup:  可以对只进行了稀疏标注的数据集进行训练；</li><li>fully-automated setup:  假设稀疏标注集存在，对该数据集进行训练。</li></ul><a id="more"></a><h1 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2. 网络结构"></a>2. 网络结构</h1><p><img src="http://image.ningxin.site/20200603160416.png" srcset="/img/loading.gif" alt="网络结构"><br>该模型分为<code>analysis path</code> 和 <code>synthesis path</code>两个部分，主要结构和<code>U-Net</code>一样。</p><p><code>analysis path</code> 主要包括以下操作：该部分有4层，每一层都包含两个<code>3 x 3 x 3</code>的卷积，每次卷积之后进行<code>batch normalizetion</code>(BN) 操作和<code>ReLu</code>操作，然后进行strides为2的<code>2 x 2 x 2</code>的最大池化操作。</p><p><code>synthesis path</code> 主要包括以下操作：该部分有3层，每一层首先使用一个strides为2、卷积核为<code>2 x 2 x 2</code>的反卷积操作，然后与<code>analysis path</code>中对应的<code>fature map</code>进行cat操作，再然后是两个<code>3 x 3 x 3</code>的卷积操作，每次卷积之后进行<code>batch normalizetion</code>(BN) 操作和<code>ReLu</code>操作，然后进行strides为2的<code>2 x 2 x 2</code>的最大池化操作。</p><p>在最后一层输出时使用<code>1 x 1 x 1</code>的卷积来减少通道数。</p><p>论文中提到的一个亮点就是，3D U-Net使用了<code>weighted softmax loss function</code>将未标记的像素点设置为0以至于可以让网络可以更多地仅仅学习标注到的像素点，从而达到普适性地特点。</p><h1 id="3-训练"><a href="#3-训练" class="headerlink" title="3. 训练"></a>3. 训练</h1><p>3D U-Net采用了数据增广（data augmentation），主要是rotation、scaling和将图像设置为gray，于此同时在训练数据上和真实标注的数据上运用平滑的密集变形场(smooth dense deformation field)。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>V-Net笔记</title>
    <link href="/2020/05/24/V-Net%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/05/24/V-Net%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>V-Net用于3D图像分割（基于3D卷积），引入了新的目标函数（<code>Dice coefficient</code>）,采用<code>random non-linear transformation</code>和<code>histogram matching</code>的数据扩充方法。</p><h1 id="2-网络结构"><a href="#2-网络结构" class="headerlink" title="2. 网络结构"></a>2. 网络结构</h1><p><img src="https://gitee.com/huster_ning/image/raw/master/image/Snipaste_2020-05-27_21-15-06.jpg" srcset="/img/loading.gif" alt="Snipaste_2020-05-27_21-15-06"></p><a id="more"></a><p>网络的左侧部分由压缩路径组成，而右侧部分解压缩直到达到其原始大小。</p><h2 id="2-1-压缩路径"><a href="#2-1-压缩路径" class="headerlink" title="2.1 压缩路径"></a>2.1 压缩路径</h2><p>压缩路径中每个阶段中执行几次<code>5 x 5 x 5</code>大小的卷积操作，卷积之后使用<code>PReLU</code>函数进行非线性化操作，然后执行<code>element-wise sum</code>操作，再执行步幅为2的<code>2 x 2 x 2</code>的卷积（该步骤是使用卷积代替池化操作），将分辨率变为原来的一半。每个阶段执行完后，通道数变为原来的两倍。</p><ul><li>卷积代替池化：能够有更小的内存占用，网络性能更好</li><li>element-wise sum操作：如下图所示，首先16个x执行cat操作得到x16, 得到的x16的维度与out一致，<code>element-wise sum</code>操作就是将x16和out的对应像素点执行相加操作。</li></ul><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>    <span class="hljs-comment"># do we want a PRELU here as well?</span>    out = self.bn1(self.conv1(x))    <span class="hljs-comment"># split input in to 16 channels</span>    <span class="hljs-comment"># 增加通道数与out一致</span>    x16 = torch.cat((x, x, x, x, x, x, x, x,                     x, x, x, x, x, x, x, x), <span class="hljs-number">0</span>)    <span class="hljs-comment"># 执行element-wise sum操作之后在执行relu1</span>    out = self.relu1(torch.add(out, x16))    <span class="hljs-keyword">return</span> out</code></pre></div><h2 id="2-2-解压缩路径"><a href="#2-2-解压缩路径" class="headerlink" title="2.2 解压缩路径"></a>2.2 解压缩路径</h2><p>在解压缩路径中，与<code>U-Net</code>类似，将网络左侧部分的早期阶段提取的特征转发到右侧部分，即网络结构图中的<code>Fine-grained features forwarding</code>操作。通过这种方式，可以收集在压缩路径中丢失的细粒度细节，并且可以提高最终轮廓预测的质量。每个阶段采用反卷积操作，将分辨率提高到原来的两倍，并且通道数变为原来的一半。最后使用一个<code>1 x 1 x 1</code>的卷积得到与输入大小相同的结果，并使用softmax函数得到概率分割图。</p><ul><li><code>Fine-grained features fowarding</code>: 左侧特征图与右侧对应特征图执行拼接操作。 </li></ul><h1 id="3-Dice-loss-layer"><a href="#3-Dice-loss-layer" class="headerlink" title="3. Dice loss layer"></a>3. Dice loss layer</h1><h2 id="3-1-Dice系数"><a href="#3-1-Dice系数" class="headerlink" title="3.1 Dice系数"></a>3.1 Dice系数</h2><p>参考博客<a href="https://www.aiuai.cn/aifarm1159.html" target="_blank" rel="noopener">医学图像分割之 Dice Loss</a></p><p>Dice系数，是一种集合相似度度量函数，通常用于计算两个样本的相似度（值范围为[0, 1]）:</p><script type="math/tex; mode=display">s=\frac{2|X \bigcap Y|}{|X|+|Y|}</script><p> $|X \bigcap Y|$ 表示X 和 Y 之间的交集；|X| 和 |Y| 分别表示 X 和 Y 的元素个数. 其中，分子中的系数 2，是因为分母存在重复计算 X 和 Y 之间的共同元素的原因.</p><p>在真正计算时可以将 |X⋂Y| 近似为预测图与 GT 分割图之间的点乘，并将点乘的元素结果相加求和：</p><script type="math/tex; mode=display">|X \bigcap Y|=\left[\begin{array}{cccc}0.01 & 0.03 & 0.02 & 0.02 \\0.05 & 0.12 & 0.09 & 0.07 \\0.89 & 0.85 & 0.88 & 0.91 \\0.99 & 0.97 & 0.95 & 0.97\end{array}\right] *\left[\begin{array}{cccc}0 & 0 & 0 & 0 \\0 & 0 & 0 & 0 \\1 & 1 & 1 & 1 \\1 & 1 & 1 & 1\end{array}\right]</script><h2 id="3-2-Dice系数在医学图像分割中的应用"><a href="#3-2-Dice系数在医学图像分割中的应用" class="headerlink" title="3.2 Dice系数在医学图像分割中的应用"></a>3.2 Dice系数在医学图像分割中的应用</h2><p>在以前的损失函数中，前景区域在学习期间比背景区域更重要。在V-Net中提出了一个基于Dice系数的新的目标函数，目标是求最大值。</p><script type="math/tex; mode=display">D=\frac{2 \sum_{i}^{N} p_{i} g_{i}}{\sum_{i}^{N} p_{i}^{2}+\sum_{i}^{N} g_{i}^{2}}</script><p>其中pi为预测结果，gi为实际结果。Dice系数的梯度为：</p><script type="math/tex; mode=display">\frac{\partial D}{\partial p_{j}}=2\left[\frac{g_{j}\left(\sum_{i}^{N} p_{i}^{2}+\sum_{i}^{N} g_{i}^{2}\right)-2 p_{j}\left(\sum_{i}^{N} p_{i} g_{i}\right)}{\left(\sum_{i}^{N} p_{i}^{2}+\sum_{i}^{N} g_{i}^{2}\right)^{2}}\right]</script><h2 id="3-3-Dice系数的Pytorch实现"><a href="#3-3-Dice系数的Pytorch实现" class="headerlink" title="3.3 Dice系数的Pytorch实现"></a>3.3 Dice系数的Pytorch实现</h2><div class="hljs"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dice_loss</span><span class="hljs-params">(pred, target)</span>:</span>    <span class="hljs-string">"""This definition generalize to real valued pred and target vector.This should be differentiable.    pred: tensor with first dimension as batch    target: tensor with first dimension as batch    """</span>smooth = <span class="hljs-number">1.</span><span class="hljs-comment"># have to use contiguous since they may from a torch.view op</span>iflat = pred.contiguous().view(<span class="hljs-number">-1</span>)tflat = target.contiguous().view(<span class="hljs-number">-1</span>)intersection = (iflat * tflat).sum()A_sum = torch.sum(iflat * iflat)B_sum = torch.sum(tflat * tflat)<span class="hljs-keyword">return</span> (<span class="hljs-number">2.</span> * intersection + smooth) / (A_sum + B_sum + smooth)</code></pre></div><h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4. 训练"></a>4. 训练</h1><p>训练时主要采用下面的数据增广方法：</p><ul><li>使用<code>2 x 2 x 2</code>的网格控制点和<code>B-spline interpolation</code>(B样条插值)来获得稠密的形变场对图像进行非线性形变；</li><li>使用直方图匹配来获得不同的灰度分布的图像。 </li></ul>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>U-net笔记</title>
    <link href="/2020/05/21/U-net%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/05/21/U-net%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="U-net"><a href="#U-net" class="headerlink" title="U-net"></a>U-net</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>U-net是对FCN的改进，主要应用于医学图像分割。</p><p>U-net的网络结构如下所示：</p><p><img src="https://gitee.com/huster_ning/image/raw/master/image/v2-96f5e828c1e83c930aa4a2bb91e64c10_r.jpg" srcset="/img/loading.gif" alt="preview"></p><a id="more"></a><p>U-net包括<code>Contracting Path</code> 和 <code>Expanding Path</code> 两个部分，所有卷积层的<code>padding = 0</code>. U-net的计算过程如下：</p><ul><li><p><code>Contracting Path</code>部分进行下采样操作：2个<code>3 x 3</code>的卷积层 + 1个 <code>2 x 2 的 max pool</code>，重复四次以上操作；</p></li><li><p><code>Expanding Path</code>部分：2个<code>3 x 3</code>卷积层 + 1个<code>2 x 2</code>反卷积操作，然后与前面对应的层使用 <strong>拼接操作</strong> 进行特征融合，重复四次以上操作；</p></li><li><p>最后经过2个<code>3 x 3</code>卷积， 1个<code>1 x 1</code>卷积(类似于残差网络，用来降维)，然后使用softmax进行输出。</p></li></ul><h3 id="特征融合"><a href="#特征融合" class="headerlink" title="特征融合"></a>特征融合</h3><p>使用concat操作进行特征融合，而不是使用相加操作进行特征融合</p><p><img src="https://gitee.com/huster_ning/image/raw/master/image/image-20200520160912870.png" srcset="/img/loading.gif" alt="image-20200520160912870"></p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>U-net使用的是带权损失函数：</p><script type="math/tex; mode=display">E = \sum_{x\in\Omega}{\omega(x)\log(p_{l(x)}(x))}</script><p>其中 $w(x)$ 指的是权重，其实就是相当于交叉熵乘了一个权重，有点不解的是我看的代码中都是直接使用<code>CrossEntropyLoss</code>进行计算loss，如下代码所示：</p><div class="hljs"><pre><code class="hljs python">unet = Unet(in_channel=<span class="hljs-number">1</span>,out_channel=<span class="hljs-number">2</span>)<span class="hljs-comment">#out_channel represents number of segments desired</span>criterion = torch.nn.CrossEntropyLoss()optimizer = torch.optim.SGD(unet.parameters(), lr = <span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.99</span>)optimizer.zero_grad()       outputs = unet(inputs)<span class="hljs-comment"># permute such that number of desired segments would be on 4th dimension</span>outputs = outputs.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)m = outputs.shape[<span class="hljs-number">0</span>]<span class="hljs-comment"># Resizing the outputs and label to caculate pixel wise softmax loss</span>outputs = outputs.resize(m*width_out*height_out, <span class="hljs-number">2</span>)labels = labels.resize(m*width_out*height_out)loss = criterion(outputs, labels)loss.backward()optimizer.step()</code></pre></div><p>U-net的输入是<code>572 x 572</code>, 而输出是<code>388 x 388</code>，两者不一致，不能直接求损失函数，有两种方法：</p><ul><li>对预期输出从中心crop，使其与输出大小一致;</li><li>对输出结果进行padding操作，使其与输入大小一致。</li></ul><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>使用梯度下降法（SGD）进行优化。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阿里云服务器发送邮件</title>
    <link href="/2019/07/18/%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/"/>
    <url>/2019/07/18/%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="1-在邮箱设置中开启SMTP"><a href="#1-在邮箱设置中开启SMTP" class="headerlink" title="1. 在邮箱设置中开启SMTP"></a>1. 在邮箱设置中开启SMTP</h3><p>SMTP:简单文件传输协议</p><h3 id="2-具体过程参考如下博客"><a href="#2-具体过程参考如下博客" class="headerlink" title="2. 具体过程参考如下博客"></a>2. 具体过程参考如下博客</h3><p><a href="https://yq.aliyun.com/articles/644134" target="_blank" rel="noopener">参考链接</a></p><a id="more"></a><h3 id="3-发送邮件"><a href="#3-发送邮件" class="headerlink" title="3. 发送邮件"></a>3. 发送邮件</h3><ul><li>直接输入正文<blockquote><p>echo “邮件正文” | mail -s “邮件主题(subject)” 邮箱地址</p></blockquote></li><li>正文在文件中<blockquote><p>mail -s “邮件主题(subject)” 邮箱地址 &lt; 邮件正文所在文件<br>cat file | mail -s “邮件主题(subject)” 邮箱地址</p></blockquote></li><li>发送附件<blockquote><p>mail -s “邮件主题(subject)” 邮箱地址 -a 附件</p></blockquote></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>阿里云服务器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客添加评论功能</title>
    <link href="/2019/07/17/%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"/>
    <url>/2019/07/17/%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="yilia主题：gitment评论功能"><a href="#yilia主题：gitment评论功能" class="headerlink" title="yilia主题：gitment评论功能"></a>yilia主题：gitment评论功能</h1><p>下面主要讲述如何使用gitment给yilia主题添加评论功能</p><h2 id="1-Register-a-new-OAuth-application"><a href="#1-Register-a-new-OAuth-application" class="headerlink" title="1. Register a new OAuth application"></a>1. Register a new OAuth application</h2><p><a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">注册OAuth</a><br><a id="more"></a></p><p><img src="https://gitee.com/huster_ning/image/raw/master/image/%E6%B3%A8%E5%86%8C.png" srcset="/img/loading.gif" alt="注册"></p><p>注册完成后能够得到<code>Client ID</code>和<code>Client Serect</code></p><h2 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2. 修改配置文件"></a>2. 修改配置文件</h2><p>修改<code>themes/hexo-theme-yilia/_config.yml</code>下的配置文件（注意不是修改根目录下的_config.yml文件）<br>如下图所示<br><img src="https://gitee.com/huster_ning/image/raw/master/image/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.png" srcset="/img/loading.gif" alt="配置文件"><br>最后如果不出问题的话<code>hexo g</code> 、<code>hexo d</code>应该就行了</p><h2 id="3-解决一些遇到的bug"><a href="#3-解决一些遇到的bug" class="headerlink" title="3. 解决一些遇到的bug"></a>3. 解决一些遇到的bug</h2><h3 id="bug：github-api-error-redirect-uri-mismatch"><a href="#bug：github-api-error-redirect-uri-mismatch" class="headerlink" title="bug：github-api-error-redirect-uri-mismatch"></a>bug：github-api-error-redirect-uri-mismatch</h3><p><a href="https://stackoverflow.com/questions/34730153/github-api-error-redirect-uri-mismatch" target="_blank" rel="noopener">参考Stack Overflow</a></p><h3 id="bug：object-ProgressEvent"><a href="#bug：object-ProgressEvent" class="headerlink" title="bug：object ProgressEvent"></a>bug：object ProgressEvent</h3><p>由于服务器认证域名过期，修改服务器即可，<br>修改<code>themes/hexo-theme-yilia/layout/_partial/post/gitment.ejs</code>文件<br>将如下代码<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">"stylesheet"</span> <span class="hljs-attr">href</span>=<span class="hljs-string">"//imsun.github.io/gitment/style/default.css"</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">"//imsun.github.io/gitment/dist/gitment.browser.js"</span>&gt;</span><span class="undefined"></span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></code></pre></div></p><p>修改成如下：<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-tag">&lt;<span class="hljs-name">link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">"stylesheet"</span> <span class="hljs-attr">href</span>=<span class="hljs-string">"https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.css"</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">"https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.js"</span>&gt;</span><span class="undefined"></span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span></code></pre></div></p><p><a href="https://sjq597.github.io/2018/05/18/Hexo-%E4%BD%BF%E7%94%A8Gitment%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/" target="_blank" rel="noopener">参考</a></p><h1 id="fluid主题：valine评论"><a href="#fluid主题：valine评论" class="headerlink" title="fluid主题：valine评论"></a>fluid主题：valine评论</h1><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>修改fluid主题目录下的<code>_config.yml</code>文件，如下所示开启评论并选择使用的评论模块为<code>valine</code></p><div class="hljs"><pre><code class="hljs yml"><span class="hljs-attr">comments:</span>  <span class="hljs-comment"># 评论</span><span class="hljs-attr">    enable:</span> <span class="hljs-literal">true</span>  <span class="hljs-comment"># 开启评论</span><span class="hljs-attr">    type:</span> <span class="hljs-string">valine</span></code></pre></div><p>然后修改<code>valine</code>模块中中的配置信息, 主要是修改appid、appkey、serverURLS这三处信息, 需要 <a href="https://leancloud.cn/dashboard/login.html#/signup" target="_blank" rel="noopener">注册LeanCloud</a>才能获取appid、appkey, 具体操作可参考<a href="https://valine.js.org/quickstart.html" target="_blank" rel="noopener">文档</a><br><div class="hljs"><pre><code class="hljs yml"><span class="hljs-comment"># Valine</span><span class="hljs-comment"># 完整文档 https://valine.js.org/configuration.html</span><span class="hljs-comment"># 注意：下列配置项中的 true/false 不要用引号括起来</span><span class="hljs-attr">valine:</span><span class="hljs-attr">  appid:</span> <span class="hljs-string">xxx</span>  <span class="hljs-comment"># 从 LeanCloud 的应用中得到的 appId</span><span class="hljs-attr">  appkey:</span> <span class="hljs-string">xxx</span>  <span class="hljs-comment"># 从 LeanCloud 的应用中得到的 APP Key</span><span class="hljs-attr">  placeholder:</span> <span class="hljs-string">说点什么</span> <span class="hljs-comment"># 评论框占位提示符</span><span class="hljs-attr">  path:</span> <span class="hljs-string">window.location.pathname</span> <span class="hljs-comment"># 当前文章页路径，用于区分不同的文章页，以保证正确读取该文章页下的评论列表</span><span class="hljs-attr">  avatar:</span> <span class="hljs-string">retro</span> <span class="hljs-comment"># Gravatar 头像展示方式</span><span class="hljs-attr">  meta:</span> <span class="hljs-string">['nick',</span> <span class="hljs-string">'mail'</span><span class="hljs-string">,</span> <span class="hljs-string">'link'</span><span class="hljs-string">]</span>  <span class="hljs-comment"># 评论者相关属性</span><span class="hljs-attr">  pageSize:</span> <span class="hljs-number">10</span> <span class="hljs-comment"># 评论列表分页，每页条数</span><span class="hljs-attr">  lang:</span> <span class="hljs-string">zh-CN</span> <span class="hljs-comment"># zh-CN | zh-TW | en | ja</span><span class="hljs-attr">  highlight:</span> <span class="hljs-literal">false</span> <span class="hljs-comment"># 代码高亮</span><span class="hljs-attr">  recordIP:</span> <span class="hljs-literal">false</span> <span class="hljs-comment"># 是否记录评论者IP</span><span class="hljs-attr">  serverURLs:</span>  <span class="hljs-string">xxx</span> <span class="hljs-comment"># REST API 服务器地址，国际版不填</span></code></pre></div></p><h2 id="评论邮件提醒功能"><a href="#评论邮件提醒功能" class="headerlink" title="评论邮件提醒功能"></a>评论邮件提醒功能</h2><p>邮件提醒我使用的是<a href="https://github.com/zhaojun1998/Valine-Admin" target="_blank" rel="noopener">Valine-Admin</a>，参考文档进行Git部署即可。但我在部署时出现了如下错误：</p><p><img src="https://gitee.com/huster_ning/image/raw/master//image/20200701132034.png" srcset="/img/loading.gif" alt=""></p><p>主要是因为Node版本太低了的缘故，需要修改项目中<code>package.json</code>文件中的Node版本，可以将项目fork到自己的仓库中，然后进行修改, 将<code>6.x</code>修改成<code>12.x</code>即可。</p><div class="hljs"><pre><code class="hljs json">"engines": &#123;    "node": "12.x"  &#125;</code></pre></div><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>如果fluid主题使用了覆盖配置，一定记得修改配置时是在<code>source/_data</code>目录下修改，不然配置会无效。</p>]]></content>
    
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>博客搭建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java复习笔记</title>
    <link href="/2018/10/28/java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2018/10/28/java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容."><div class="hbe-input-container"><input type="password" id="hbePass" placeholder="您好, 这里需要密码." /><label>您好, 这里需要密码.</label><div class="bottom-line"></div></div><script id="hbeData" type="hbeData" data-hmacdigest="d763951ed02538d0c0477ac98a141ce710b711de88fff47b2fccfefd4d137733">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</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Map的遍历与排序</title>
    <link href="/2018/10/16/Map%E7%9A%84%E9%81%8D%E5%8E%86%E4%B8%8E%E6%8E%92%E5%BA%8F/"/>
    <url>/2018/10/16/Map%E7%9A%84%E9%81%8D%E5%8E%86%E4%B8%8E%E6%8E%92%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>引言：集合是java比较重要的一个知识点，而集合的遍历尤为重要。<br>  相对来说，Map又是集合中比较难懂的一部分，故今天来讲一下Map的<br>  遍历与排序。</p></blockquote><h2 id="Map的遍历"><a href="#Map的遍历" class="headerlink" title="Map的遍历"></a>Map的遍历</h2><ul><li><p>较为简单的遍历方法可以通过<code>keySet()</code>方法获取Map中的所有的<code>key</code>,<br>然后使用<code>get(key)</code>获取<code>key</code>对应的<code>value</code>,代码如下：</p><div class="hljs"><pre><code class="hljs java"> Map&lt;String, String&gt; map = <span class="hljs-keyword">new</span> HashMap&lt;String, String&gt;(); map.put(<span class="hljs-string">"1"</span>,<span class="hljs-string">"xinger"</span>); <span class="hljs-comment">//······省略部分代码</span><span class="hljs-keyword">for</span>(String s : map.keySet())&#123;System.out.println(<span class="hljs-string">"key:"</span>+s+<span class="hljs-string">","</span>+<span class="hljs-string">"value:"</span>+map.get(s));&#125;</code></pre></div></li></ul><a id="more"></a><ul><li><p>通过Map.entrySet()遍历map：Map.entrySet()方法返回该地图的集合视图(<code>Set(Map.Entry&lt;K,V&gt;)</code>)</p><div class="hljs"><pre><code class="hljs java"><span class="hljs-keyword">for</span>(Map.Entry&lt;String, String&gt; entry : map.entrySet())&#123;  <span class="hljs-comment">//参数类型请灵活处理</span>System.out.println(<span class="hljs-string">"key:"</span>+entry.getKey()+<span class="hljs-string">","</span>+<span class="hljs-string">"value:"</span>+entry.getValue());&#125;</code></pre></div></li><li><p>通过迭代器遍历Map:</p><div class="hljs"><pre><code class="hljs java">Iterator(Map.Entry&lt;String, String&gt;) ite = map.entrySet().iterator();<span class="hljs-keyword">while</span>(ite.hasNext())&#123;Map.Entry&lt;String, String&gt; entry = ite.next();System.out.println(<span class="hljs-string">"key:"</span>+entry.getKey()+<span class="hljs-string">","</span>+<span class="hljs-string">"value:"</span>+entry.getValue());z&#125;</code></pre></div></li></ul><h2 id="Map的排序"><a href="#Map的排序" class="headerlink" title="Map的排序"></a>Map的排序</h2><ul><li><p>利用TreeMap类进行排序：<code>TreeMap</code>是默认按<code>key</code>的升序排序，若要改变排序方式，需要使用<strong>比较器</strong>：<code>Comparator</code><br>并使用构造器<code>TreeMap(Comparator&lt;? super K&gt; comparator)</code>,注意到泛型<code>? super K</code>,故本质还是进行按<code>key</code>排序。</p><div class="hljs"><pre><code class="hljs java">Map&lt;String,String&gt; map = <span class="hljs-keyword">new</span> TreeMap&lt;String, String&gt;(<span class="hljs-keyword">new</span> Comparator&lt;String&gt;()&#123;                <span class="hljs-meta">@Override</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compare</span><span class="hljs-params">(String o1, String o2)</span> </span>&#123;<span class="hljs-keyword">return</span>  o2.compareTo(p1);&#125;);</code></pre></div></li><li><p>Map按value排序：实现Comparator接口，并重写<code>compare(Object o1, Object o2)</code>方法</p><div class="hljs"><pre><code class="hljs java">List&lt;Map.Entry&lt;String, Integer&gt;&gt; list = <span class="hljs-keyword">new</span> ArrayList&lt;Map.Entry&lt;String, Integer&gt;&gt;(map.entrySet());   <span class="hljs-comment">//排序</span>   Collections.sort(list, <span class="hljs-keyword">new</span> Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt;()&#123;<span class="hljs-comment">//内部类</span><span class="hljs-meta">@Override</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compare</span><span class="hljs-params">(Entry&lt;String, Integer&gt; o1, Entry&lt;String, Integer&gt; o2)</span> </span>&#123;<span class="hljs-keyword">return</span> o2.getValue() - o1.getValue();&#125;      &#125;);</code></pre></div></li></ul>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>Collection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jdbc</title>
    <link href="/2018/10/05/jdbc/"/>
    <url>/2018/10/05/jdbc/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-JDBC连接MySql"><a href="#1-JDBC连接MySql" class="headerlink" title="1.JDBC连接MySql"></a>1.JDBC连接MySql</h1><p>首先新建一个数据库，<code>create database new_database</code>,<code>use new_database</code>,<code>create new_table(.....)</code>,注意mysql命令<br>要有冒号作为一个语句的结束，然后需要下载驱动包，<a href="http://downloads.mysql.com/archives/c-j/" target="_blank" rel="noopener">http://downloads.mysql.com/archives/c-j/</a>, 解压导入到项目中即可</p><p><font color="#DC1818">注意：下面的代码中的<code>Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;)</code>    注册驱动文件 ，与网上的教程<code>Class.forName(&quot;com.mysql.jdbc.Driver&quot;)</code>有所区别，是由于驱动包版本不同所致，请注意区分</font><br><a id="more"></a><br><div class="hljs"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.sql.*;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySql</span> </span>&#123;    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String url = <span class="hljs-string">"jdbc:mysql://localhost:3306/database_name?useSSL=false"</span>;    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String user = <span class="hljs-string">"root"</span>;    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String password = <span class="hljs-string">"xxxxxxx"</span>;<span class="hljs-comment">//the password of your mysql;</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;Connection con = <span class="hljs-keyword">null</span>; Statement statement = <span class="hljs-keyword">null</span>; <span class="hljs-keyword">try</span> &#123; <span class="hljs-comment">//注册驱动文件</span> Class.forName(<span class="hljs-string">"com.mysql.cj.jdbc.Driver"</span>);  <span class="hljs-comment">//连接数据库</span> con = DriverManager.getConnection(url, user, password);<span class="hljs-comment">//查询</span> statement = con.createStatement(); String sql = <span class="hljs-string">"update websites set name='xinger' where id=6;"</span>; <span class="hljs-comment">//update</span> System.out.println(statement.executeUpdate(sql));  <span class="hljs-comment">//System.out.println(ret.toString());</span> sql = <span class="hljs-string">"select * from websites"</span>; ResultSet rs = statement.executeQuery(sql); <span class="hljs-keyword">while</span>(rs.next())&#123;         <span class="hljs-comment">//Retrieve by column name</span>         <span class="hljs-keyword">int</span> id  = rs.getInt(<span class="hljs-string">"id"</span>);         String name = rs.getString(<span class="hljs-string">"name"</span>);         String url = rs.getString(<span class="hljs-string">"url"</span>);         String country = rs.getString(<span class="hljs-string">"country"</span>);         <span class="hljs-comment">//Display values</span>         System.out.print(<span class="hljs-string">"id: "</span> + id);         System.out.print(<span class="hljs-string">",name:"</span> + name);         System.out.print(<span class="hljs-string">", url: "</span> + url);         System.out.println(<span class="hljs-string">", country: "</span> + country);      &#125; rs.close(); statement.close(); con.close();  &#125; <span class="hljs-keyword">catch</span> (ClassNotFoundException e) &#123; System.out.println(e); &#125;  <span class="hljs-keyword">catch</span> (SQLException e) &#123; e.printStackTrace();&#125; &#125;&#125;</code></pre></div></p><h1 id="2-Statement接口"><a href="#2-Statement接口" class="headerlink" title="2.Statement接口"></a>2.Statement接口</h1><p>   需要使用<code>Connection</code>对象的<code>createStatement()</code>方法创建一个<code>Statement</code>对象；<br>   <code>Statement</code>中的方法：</p><p> <font color="#1EE4F1">boolean execute (String SQL)</font> 如果可以检索到ResultSet对象，则返回一个布尔值true; 否则返回false。使用此方法执行SQLDDL语句或需要使用真正的动态SQL，可使用于执行创建数据库，创建表的SQL语句等等。</p><p><font color="#1EE4F1">int executeUpdate (String SQL)</font>:返回受SQL语句执行影响的行数。使用此方法执行预期会影响多行的SQL语句，例如:INSERT，<br>UPDATE或DELETE语句。</p><p><font color="#1EE4F1">ResultSet executeQuery(String SQL)</font>：返回一个ResultSet对象。 当您希望获得结果集时，请使用此方法，就像使用SELECT语<br>句一样。</p>]]></content>
    
    
    
    <tags>
      
      <tag>SQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo搭建个人博客系统</title>
    <link href="/2018/10/05/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/"/>
    <url>/2018/10/05/Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Hexo-GitHub搭建个人博客"><a href="#Hexo-GitHub搭建个人博客" class="headerlink" title="Hexo+GitHub搭建个人博客"></a>Hexo+GitHub搭建个人博客</h1><h2 id="1-Hexo搭建GitHub-Pages"><a href="#1-Hexo搭建GitHub-Pages" class="headerlink" title="1.Hexo搭建GitHub Pages"></a>1.Hexo搭建GitHub Pages</h2><p>由于大部分过程官方文档中都有详细说明，本文不在讲述。我主要讲述一下如何搭建GitHub Pages:<br>首先在Hexo目录下找到配置文件_config.yml,然后修改deploy中的内容:</p><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-attribute">deploy</span>:  <span class="hljs-attribute">type</span>: git  <span class="hljs-attribute">repo</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//github.com/your_github_name/your_github_name.github.io.git</span>  <span class="hljs-attribute">branch</span>: master</code></pre></div><p>其中repo是你的github仓库网址<br>最后使用命令hexo s 生成静态文件，hexo d 发布博客</p><a id="more"></a><h2 id="2-更换博客主题"><a href="#2-更换博客主题" class="headerlink" title="2.更换博客主题"></a>2.更换博客主题</h2><p>   <a href="https://hexo.io/themes/" target="_blank" rel="noopener">themes</a>这个是官网提供的主题，而本人使用的主题是华科大佬写的<br><a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="noopener">hexo-theme-yilia</a>,比较美观，使用也比较方便。<br>    首先<code>git clone</code>到<code>themes</code>文件夹中，然后在主目录的<code>_config.yml</code><br>中找到theme,改成你说下载的theme名字即可，如图：<br><div class="hljs"><pre><code class="hljs undefined"><span class="hljs-built_in">theme</span>: hexo-<span class="hljs-built_in">theme</span>-yilia</code></pre></div></p><p>最后<code>git pull</code>就好了</p><h2 id="3-在博客中加载图片"><a href="#3-在博客中加载图片" class="headerlink" title="3.在博客中加载图片"></a>3.在博客中加载图片</h2><p> 在<code>_config.yml</code>中找到<code>Writing</code>部分，将<code>post_asset_folder</code>改为<code>true</code>,<br> 这样每次<code>hexo new &quot;blog name&quot;</code>时都会自动新建一个同名的资源文件夹，将需<br> 要加载的图片放到该文件夹中,在博客中引用该图片就行了</p> <div class="hljs"><pre><code class="hljs undefined">&#123;% img [class names] image.jpg [width] [height] [title text [alt text]] %&#125;</code></pre></div><p>也可以这样引用<code>![](image.jpg)</code>(直接输入图片文件名即可)，但这个无法在首页中显示</p><h2 id="4-更换博客域名"><a href="#4-更换博客域名" class="headerlink" title="4.更换博客域名"></a>4.更换博客域名</h2><p> 作为一个学生党，直接买域名对我来说还是有点小贵，但GitHub给学生提供了一个开发大礼包，学生可以用学校的邮箱进行认证，<br><a href="https://education.github.com/" target="_blank" rel="noopener">申请网址</a>。这个开发大礼包中，对我来说主要有两个比较有用的东西，第一个就是学生可以<br>无限创建私有仓库，另外，可以使用<code>namaCheap</code>申请一个一年的免费域名(<code>.me</code>的顶级域名)，<a href="https://nc.me/" target="_blank" rel="noopener">申请网址</a>，<br>申请到域名后，就可以自定义设置<code>github pages</code>的域名了(代替<code>github.io</code>的域名)，具体操作参考<a href="https://help.github.com/articles/using-a-custom-domain-with-github-pages/" target="_blank" rel="noopener">git pages 官方文档</a> </p><h3 id="4-1-github-pages-with-https"><a href="#4-1-github-pages-with-https" class="headerlink" title="4.1 github pages with https"></a>4.1 github pages with https</h3><p>官方说明：<a href="https://help.github.com/en/github/working-with-github-pages/securing-your-github-pages-site-with-https" target="_blank" rel="noopener">github-pages=with-https</a></p><p>在repository的设置中勾选<code>Enforce HTTPS</code>即可，如果不能勾选，等一段时间即可。</p><p><img src="https://gitee.com/huster_ning/image/raw/master/image/Snipaste_2020-05-22_13-55-31.jpg" srcset="/img/loading.gif" alt="Snipaste_2020-05-22_13-55-31"></p><h3 id="4-2-更换域名的一些坑"><a href="#4-2-更换域名的一些坑" class="headerlink" title="4.2 更换域名的一些坑"></a>4.2 更换域名的一些坑</h3><ul><li><p>域名解析添加CNAME记录：</p><p><img src="https://gitee.com/huster_ning/image/raw/master/image/Snipaste_2020-05-22_13-15-10.jpg" srcset="/img/loading.gif" alt="Snipaste_2020-05-22_13-15-10"></p><p> CNAME:规范名字，允许将多个名字映射到同一台计算机上，即你可以使用多个域名指向同一服务器IP，在这里就是你既可以通过<br>‘github.io’这个域名，又可以通过<code>.me</code>域名访问你的博客。为了保证可以用两个域名访问同一个博客，应该新建一个<code>CNAME</code>文件<br>我新建文件的位置：<br><img src="https://gitee.com/huster_ning/image/raw/master/image/CNAME.PNG" srcset="/img/loading.gif" alt="CNAME"></p></li></ul><p>并写入你的域名，然后提交到github上去，如果直接在github中新建，之后提交博客可能<code>覆盖</code>该文件，导致博客无法访问</p><h2 id="5-插入视频"><a href="#5-插入视频" class="headerlink" title="5.插入视频"></a>5.插入视频</h2><div class="hljs"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">iframe</span> <span class="hljs-attr">width</span>=<span class="hljs-string">"560"</span> <span class="hljs-attr">height</span>=<span class="hljs-string">"315"</span> <span class="hljs-attr">src</span>=<span class="hljs-string">"https://www.youtube.com/embed/Ilg3gGewQ5U"</span> <span class="hljs-attr">frameborder</span>=<span class="hljs-string">"0"</span> <span class="hljs-attr">allowfullscreen</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">iframe</span>&gt;</span></code></pre></div><iframe width="60%" height="315" display="block" src="https://www.youtube.com/embed/Ilg3gGewQ5U" frameborder="0" allowfullscreen></iframe><h2 id="6-写博客"><a href="#6-写博客" class="headerlink" title="6.写博客"></a>6.写博客</h2><p>使用如下命令创建一篇新的文章：<br><div class="hljs"><pre><code class="hljs undefined">hexo <span class="hljs-keyword">new</span> [layout] &lt;<span class="hljs-built_in">title</span>&gt;</code></pre></div></p><p>文章有三种布局：post、page、draft，默认布局是post，draft布局在部署时不发布，可以使用<code>hexo public</code>进行发布，不同的布局保存在不同的文件夹下。</p><div class="table-container"><table><thead><tr><th>布局</th><th>目录</th></tr></thead><tbody><tr><td>post</td><td>source/_posts</td></tr><tr><td>draft</td><td>source/_drafts</td></tr><tr><td>page</td><td>source</td></tr></tbody></table></div><p>本文主要参考了<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">hexo 文档</a><code>&amp;</code><a href="https://github.com/litten/BlogBackup" target="_blank" rel="noopener">BlogBackup</a></p><h1 id="服务器部署Hexo博客系统"><a href="#服务器部署Hexo博客系统" class="headerlink" title="服务器部署Hexo博客系统"></a>服务器部署Hexo博客系统</h1><p>部署原理很简单，实际上就是将Hexo生成的public目录上传到了服务器上。在服务器上面需要完成的工作：创建一个git用户、创建git裸仓库、配置钩子函数、nginx配置；在本地需要完成的工作：修改配置文件的部署信息、配置免密登录。</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>创建一个名为<code>git</code>的普通用户，而不是使用root用户，是为了限制用户的权限。创建用户的过程可以<a href="https://www.ningxin.site/2020/07/04/Linux用户" target="_blank" rel="noopener">参考</a></p><h2 id="创建git裸仓库配置钩子函数"><a href="#创建git裸仓库配置钩子函数" class="headerlink" title="创建git裸仓库配置钩子函数"></a>创建git裸仓库配置钩子函数</h2><p>裸仓库只包括<code>.git</code>文件，主要是关于仓库的修改信息，而不包括工作树。如下创建一个<code>blog.git</code>的仓库</p><div class="hljs"><pre><code class="hljs undefined">git init <span class="hljs-comment">--bare blog.git</span></code></pre></div><p>使用钩子函数是为了从裸仓库中恢复工作树。在<code>blog.git/hooks/</code>目录下创建<code>post-receive</code>文件, 即使用<code>post-receive</code>钩子，<code>post-receive</code>钩子是服务端钩子，在整个过程完成后运行，具体可以参考<a href="[https://www.git-scm.com/book/zh/v2/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git-%E9%92%A9%E5%AD%90](https://www.git-scm.com/book/zh/v2/自定义-Git-Git-钩子">git钩子</a>)。然后在<code>post-receive</code>文件中写入以下内容：</p><div class="hljs"><pre><code class="hljs undefined">git <span class="hljs-attribute">--work-tree</span>=blog <span class="hljs-attribute">--git-dir</span>=blog.git checkout -f</code></pre></div><h2 id="修改配置信息"><a href="#修改配置信息" class="headerlink" title="修改配置信息"></a>修改配置信息</h2><p>在<code>_config.yml</code>文件中修改deploy中的信息：</p><div class="hljs"><pre><code class="hljs yml"><span class="hljs-attr">deploy:</span><span class="hljs-attr">  type:</span> <span class="hljs-string">git</span><span class="hljs-attr">  repo:</span> <span class="hljs-string">git@服务器IP地址:仓库地址</span><span class="hljs-attr">  branch:</span> <span class="hljs-string">master</span></code></pre></div><h2 id="ssh免密登录"><a href="#ssh免密登录" class="headerlink" title="ssh免密登录"></a>ssh免密登录</h2><p>在本地<code>Git Bash</code>中使用<code>ssh-keygen</code>命令生成密钥，默认保存在<code>C:/users/username/.ssh/id_rsa</code>目录中。使用<code>ssh-copy-id -i</code>将<code>id_rsa.pub</code>（即公钥）添加到服务器。</p><div class="hljs"><pre><code class="hljs powershell">ssh-copy-id -i ~/.ssh/id_rsa.pub your_user_name@HostIP  //添加公钥ssh your_user_name@HostIP //验证是否添加成功</code></pre></div>]]></content>
    
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>github</tag>
      
      <tag>博客搭建</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
